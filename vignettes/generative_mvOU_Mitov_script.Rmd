---
title: "Generative mvOUOU Mitov Approach Script"
output: html_notebook
editor_options: 
  chunk_output_type: console
---
########################################################################################################################
# Generate OUOU data with known parameter values and then use to test mvBlouchOUOU Mitov stan code
```{r}
rm(list=ls())
library(MASS)
library(rstan)
library(ggplot2)
library(dplyr)
library(tidybayes) # For spread_draws, median_qi
library(tidyr)     # For crossing, pivot_longer
library(ggsci)     # For AAAS colors
library(truncnorm)
library(matrixcalc)
library(phytools)
#library(blouch)

#install.packages("cmdstanr", repos = c('https://stan-dev.r-universe.dev', getOption("repos")))
#install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
#devtools::install_github("rmcelreath/rethinking")
#remotes::install_github("uyedaj/treeplyr")

#install.packages("expm")
#install.packages("matrixcalc")
library(expm)

tree.10K<-read.tree('/Users/markgrabowski/Documents/Academic/Research/Data Sets/Other Data Sets/Phylogenies/10K Trees Primate Phylogeny/10KPrimateTree.tre')
######################################################################################################################
#source('/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch Project/Blouch Github Site/blouch/R/root_trace.R')
#source('/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch Project/Blouch Github Site/blouch/R/sim_mvOU.R')
#source('/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch Project/Blouch Github Site/blouch/R/set.converge.regimes.redux.R')
#source('/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch Project/Blouch Github Site/blouch/R/root_trace_redux.R')

######################################################################################################################
#For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores())
#options(mc.cores = 8)
rstan::rstan_options(auto_write = TRUE)

dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
arch <- ifelse(R.version$arch == "aarch64", "arm64", "x86_64")
cat(paste("\nCXX14FLAGS += -O3 -mtune=native -arch", arch, "-ftemplate-depth-256"),
    file = M, sep = "\n", append = FALSE)

```

Generate Phylogeny based on subset 10K Primate Phylogeny - using standard ape::phylo object first
```{r}
N<-30 #Number of species
n_traits <- 2
set.seed(10) #Set seed to get same random species each time

phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N]) 
phy<-ape::multi2di(phy)

l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1
phy$edge.length<-phy$edge.length/l.tree 

tip.label<-phy$tip.label
plot(phy)
nodelabels(frame = "n", cex = 0.8, col = "blue")
tiplabels(frame = "n", cex = 0.8, col = "blue")
#phytools::phenogram(phy,X,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data

plot(phy,no.margin=TRUE,edge.width=2,cex=0.7)
ape::nodelabels(frame="none",adj=c(1.1,-0.4))
ape::tiplabels()

#shifts<-c(56) #Location of nodes with regime shifts
#trdata<-data.frame(phy$tip.label)
#trdata<-treeplyr::make.treedata(phy,trdata)
#trdata<-set.converge.regimes.redux(trdata,shifts)

```

# Simulate Data following Mitov approach

True values - using 2 multivariate traits
```{r}
x0_true<-c(2,6) #Ancestral values for two traits
n_regs <- 2 #Two regimes

theta_mat<-data.frame(matrix(c(2,5, #Theta matrix - for optima traits are evolving towards, one value in each regime
              3,8), nrow = 2, byrow = TRUE))

colnames(theta_mat)<-c("OU1","OU2")
rownames(theta_mat)<-c("Trait1","Trait2")

H_mat_reg1<-matrix(c(2,0, #H Matrix - 
              0,2), nrow = 2, byrow = TRUE)


H_mat_reg2<-matrix(c(5,0, #H Matrix - 
              0,5), nrow = 2, byrow = TRUE)

H_mats<-list(H_mat_reg1,H_mat_reg2)


Sigma_reg1<-matrix(c(0.1,0,
              0,0.25), nrow = 2, byrow = TRUE)

Sigma_reg2<-matrix(c(0.2,0,
              0,0.5), nrow = 2, byrow = TRUE)

Sigmas<-list(Sigma_reg1,Sigma_reg2)


```


```{r}
# 1. #Get number of nodes of tree - all internal and tips
is.rooted(phy)
num_nodes<-N+Nnode(phy) #Number of tips + Number of internal nodes

#Get root node number
if(is.rooted(phy)){
  root_node_id <-N+1
}

root_node_id

# 2. Get node types (0=root, 1=tip, 2=internal)
node_types <-rep(2,num_nodes) #Default to internal for all nodes
node_types[1:N] <- 1 #Assign tips 1s
node_types[root_node_id] <- 0 #Assign root 0

```

3. Get Parent and Children indices
```{r}

parent_of_node <- rep(0, num_nodes) #Asign all 0s first, equal to number of nodes
#For each child ID, will store the parent of that child, parent_of_node[child_id] = parent_id
children_of_node_list <- vector("list", num_nodes) #Create vector of list equal to the number of nodes - this will store the children of each parent node - given a parent node id, will return all child node ids
#children_of_node_list[[parent_id]] = c(child1_id, child2_id, ...)

for(i in 1:nrow(phy$edge)){ #For all branches - parent to child nodes in order of node numbers -
  parent <- phy$edge[i, 1] #Get parent node
  child <-phy$edge[i,2] #Get child node
  parent_of_node[child] <- parent #For vector of parent ids, for element = number of child, place parent id in it - returns vector with parent ID for each child ID
  children_of_node_list[[parent]] <- c(children_of_node_list[[parent]], child) #For list of child ids, for the parent node, add on all children that come from that parent node - returns list with children IDs for each parent ID - NULL for tips. Only returns immediate children of parent
}

```

4. Grab branch lengths
```{r}

branch_lengths <- rep(0.0, num_nodes)
bl_child_node_idx<-c() #Will save the ids of th child nodes in the order of the branch length vector
for(i in 1:nrow(phy$edge)){
  child_node <- phy$edge[i,2] #Save the current child node
  bl_child_node_idx<-c(bl_child_node_idx,child_node) #Saves the child IDs in order of the original tree
  branch_lengths[child_node] <- phy$edge.length[i] #For the branch length vector, for the current child node index, save the edge length - returns vector with branch lengths in order of child_nodes
}


```

5. Set ranch Regimes
```{r}
branch_regime_idx <- rep(1,num_nodes) #Regimes for each branch in order of child node IDs

#Choose node above - using 50 here
parent_children_nodes<-getDescendants(phy,32) #Get all nodes that are descendent of the parent at position 32 - half the tree

branch_regime_idx[parent_children_nodes] <- 2 #For each node, set all children from parent 32 to regime 2

#For printing tree with painted branches
edge_regimes_for_plot <- branch_regime_idx[phy$edge[,2]] #For all children, in order of tree branches, set regimes for edges for plot
reg_colors<-ggsci::pal_npg(palette=c("nrc"),alpha=1)(2) #Set colors based on pal_mpg
plot(phy,edge.color = reg_colors[edge_regimes_for_plot], edge.width = 1, cex = 0.2) #Use regime colors based on order of regimes for edges
```

5b. Set ranch Regimes - single regime
```{r}
branch_regime_idx <- rep(1,num_nodes) #Regimes for each branch in order of child node IDs
n_regs <- 1
#Choose node above - using 50 here
#parent_children_nodes<-getDescendants(phy,32) #Get all nodes that are descendent of the parent at position 32 - half the tree

#branch_regime_idx[parent_children_nodes] <- 2 #For each node, set all children from parent 32 to regime 2

#For printing tree with painted branches
edge_regimes_for_plot <- branch_regime_idx[phy$edge[,2]] #For all children, in order of tree branches, set regimes for edges for plot
reg_colors<-ggsci::pal_npg(palette=c("nrc"),alpha=1)(2) #Set colors based on pal_mpg
plot(phy,edge.color = reg_colors[edge_regimes_for_plot], edge.width = 1, cex = 0.2) #Use regime colors based on order of regimes for edges
```


6. Setup pre-order traversal - ensures all nodes are covered and parents are before children
Versus post-order in the analysis
```{r}
# --- 5. Pre-order traversal for simulation --- parents processed before children
#1. Visit the parent node
#2. Visit its children
#Root to tips order
get_pre_order_nodes <- function(tree_edge, N_tips, N_nodes, root_id) {
  pre_order <- integer(0) #Set up blank pre_order integer vector
  queue <- c(root_id) #Start with root, load it in queue
  
  while (length(queue) > 0) { #while length of queue is greater than 0
    current <- queue[1] #place queue position 1 in current
    queue <- queue[-1] #Remove position 1 from current
    pre_order <- c(pre_order, current) #Combine current parent with existing pre_order integer vector
    current_children <- tree_edge[tree_edge[,1] == current, 2] #Find all children that derive from current parent - matches
    queue <- c(queue, current_children) #Place current children into queue - this will make all children be explored, and put them in the pre_order vector
  }
  return(pre_order)
}

pre_order_node_ids <- get_pre_order_nodes(phy$edge, N, phy$Nnode, root_node_id)

```

7. Calculate current node state based on true parameters and parent parameters
```{r}
calc_current_node_state<-function(current_node, parent_node, parent_state, branch_length, regime_id_for_branch, H_mats, Sigmas, theta_mat){ #
  #Definitions
  
  I<-diag(n_traits) 
  Sigma_sq_matrix <- Sigmas[[regime_id_for_branch]] %*% t(Sigmas[[regime_id_for_branch]])
  H_mat <- H_mats[[regime_id_for_branch]]
  thetas <- theta_mat[,regime_id_for_branch]
  
  #1. Calculate expectation at node given specific regime
  omega <- (I - expm(-H_mat * branch_length)) %*% thetas #Mean shift along branch - t_i = branch length
  phi <-  expm(-H_mat * branch_length) #Linear dependency on ancestral state
  E_x <- omega + phi  %*% parent_state #Expectation, given state of parent
  
  #2. Calculate variance at branch give specific regime - Lyapunov Equation into a Linear System
  L <- kronecker(I, H_mat) + kronecker(H_mat,I)
  s <- vec(Sigma_sq_matrix)
  v <- solve(L) %*% s
  V_stationary <- matrix(v,nrow = n_traits) #Stationary/Equlibrium V/CV Matrix
  V_i <- V_stationary - expm(-H_mat * branch_length) %*% V_stationary %*% expm(-t(H_mat) * branch_length) #Remaining variance over branch
  #For short branches, V_stationary - V_stationary, as expm(-H*ti) will be close to the identity matrix - so near 0

  node_X_state <- mvrnorm(n=1, mu = E_x,Sigma = V_i) #Simulate node state based on expectation and variance
  return(node_X_state)
}
  
```

8. Simulation loop for current node state - walk through tree from root to tips
```{r}
node_true_trait_values<-vector("list",num_nodes) #List of trait values for each node of the tree

#pre_order_node_ids - 
for (current_node in pre_order_node_ids){
  if(current_node == root_node_id){
    node_true_trait_values[[current_node]] <- x0_true
    }
  else{
    parent_node <- parent_of_node[current_node]
    parent_state <- node_true_trait_values[[parent_node]]
    branch_length <- branch_lengths[current_node]
    regime_id_for_branch <- branch_regime_idx[current_node]
    current_node_state<-calc_current_node_state(current_node, parent_node, parent_state, branch_length, regime_id_for_branch, H_mats, Sigmas, theta_mat) #All it returns is the X values at each node
    node_true_trait_values[[current_node]] <- current_node_state #Save current node state
  }
}
#node_true_trait_values

```


# Display Simulated Trait values
```{r}
simulated_tip_values<-t(as.matrix(as.data.frame(node_true_trait_values)))[1:N,]
rownames(simulated_tip_values)<-phy$tip.label
colnames(simulated_tip_values)<-c("Trait1","Trait2")

y_error_sd<-0.01
simulated_tip_values<-simulated_tip_values+rnorm(n=N,0,y_error_sd)
```


```{r}
cat("Plotting Phenogram for Trait 1...\n")
phenogram(phy, simulated_tip_values[,1], spread.labels=FALSE, fsize=0.4,
                    main = "Simulated Trait 1 Evolution"
)

```

```{r}
cat("Plotting Phenogram for Trait 2...\n")
phenogram(phy, simulated_tip_values[,2], spread.labels=FALSE, fsize=0.4,
                    main = "Simulated Trait 2 Evolution"
)
```

# Setup for Stan Analysis

1. Calculate post-order traversal - ensures all nodes are covered and children are visit before parents
```{r}
#Left - right - root
stack1 <-root_node_id
stack2 <- integer(0)

while(length(stack1)>0){ # LIFO (Last-In, First-Out) stack; https://www.naukri.com/code360/library/postorder-traversal-of-binary-tree
  current<-tail(stack1,n=1)
  stack1<-stack1[-length(stack1)]
  stack2<-c(current,stack2)
  stack1<-c(stack1,children_of_node_list[[current]])
}

post_order_path_nodes<-stack2


post_order_branch_lengths<-NULL
post_order_regime_idx<-NULL
post_order_node_types<-NULL

post_order_branch_lengths<-branch_lengths[post_order_path_nodes]
post_order_regime_idx<-branch_regime_idx[post_order_path_nodes]
post_order_node_types<-node_types[post_order_path_nodes]

for (current_node in post_order_path_nodes){
    post_order_branch_lengths <- c(post_order_branch_lengths,branch_lengths[current_node])
    post_order_regime_idx <- c(post_order_regime_idx,branch_regime_idx[current_node])
    post_order_node_types <-c(post_order_node_types,node_types[current_node])
  }



```


Setup for mvBlouchOU analysis
```{r}
#parent_of_node - get parents of all nodes
#children_of_node_list - get immediate children of all parents
children_of_node_matrix<-matrix(unlist(children_of_node_list),ncol=2,byrow=TRUE)

dat <- list(
  N = N,
  n_traits = n_traits,
  n_regs = n_regs,
  n_post_order_path_nodes = length(post_order_path_nodes), #Number Postorder path nodes
  n_parent_of_nodes = length(parent_of_node),
  #n_children_of_node_matrix = dim(children_of_node_matrix)[1],
  
  y_obs = as.matrix(simulated_tip_values),
  y_error = matrix(rep(y_error_sd,N*n_traits),nrow=N,ncol=n_traits,byrow=FALSE),
  
  post_order_path_nodes = post_order_path_nodes, 
  branch_lengths = branch_lengths,
  branch_regime_idx = branch_regime_idx,
  parent_of_node = parent_of_node,
  node_types = node_types
  #post_order_branch_lengths = post_order_branch_lengths,
  #post_order_regime_idx = post_order_regime_idx,
  #parent_of_node = parent_of_node,
  #post_order_node_types = post_order_node_types
  
  )



```

To visually explore what your priors look like, you can simulate a large number of samples from each prior distribution specified in your Stan model and then plot their densities or histograms.

This helps you:
1.  **Understand the implications of your prior choices**: Are they placing mass where you expect? Are they too broad or too narrow?
2.  **Diagnose potential issues**: For instance, if a scale parameter prior allows for extremely small values, it can lead to numerical instability.

Below is R code to do this. I'll assume `n_traits = 2` as per your simulation setup, and use standard `ggplot2` for plotting.

```{r}

# Load necessary libraries
library(ggplot2)
library(rstan) # For rlkjcorr
library(bayesplot) # Optional, but good for diagnostics later
library(dplyr)
library(tidyr)
library(ggsci) # For nice color palettes
library(rethinking)
# Set a seed for reproducibility of prior simulations
#set.seed(123)

# Define common parameters for visualization
n_traits <- 2
n_prior_samples <- 50000 # Number of samples to draw from each prior

# Define a nice color palette
mypal <- ggsci::pal_npg("nrc", alpha = 0.6)(2)
mypal_dark <- ggsci::pal_npg("nrc", alpha = 0.9)(2)

cat("--- Visualizing Priors ---\n\n")

# --- 1. y_0_ancestral ~ normal(0, 1) ---
y0_ancestral_samples<-c()
for(i in 1:n_traits){
  y0_ancestral_samples<-c(y0_ancestral_samples,rnorm(n_prior_samples * n_traits, mean = mean(y_obs[,i]), 1)) #sd = sd(y_obs[,i])))
}

y0_ancestral_df <- data.frame(
  value = y0_ancestral_samples,
  trait = rep(paste0("Trait ", 1:n_traits), each = n_prior_samples * n_traits)
)

p1 <- ggplot(y0_ancestral_df, aes(x = value, fill = trait, color = trait)) +
  geom_density(alpha = 0.5, size = 0.8) +
  geom_density(alpha = 0.5, size = 0.8) +

  scale_fill_manual(values = mypal) +
  scale_color_manual(values = mypal_dark) +
  labs(
    title = "Prior: y_0_ancestral ~ Normal(mean(y_obs[,j]), sd(y_obs[,j]))",
    x = "Value",
    y = "Density"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p1)
cat("\nPrior for y_0_ancestral: Centered at 0, unit variance. Generally a weak prior.\n")

# --- 2. lambdas 
log_lambdas_samples <- rnorm(n_prior_samples*n_traits,log(0.5),1.0)
lambdas_samples <- exp(log_lambdas_samples)

lambdas_df <- data.frame(
  value = lambdas_samples,
  trait = rep(paste0("Trait ", 1:n_traits), each = n_prior_samples)
)

p2 <- ggplot(lambdas_df, aes(x = value, fill = trait, color = trait)) +
  geom_density(alpha = 0.5, size = 0.8) +
  scale_fill_manual(values = mypal) +
  scale_color_manual(values = mypal_dark) +
  labs(
    title = "Prior: lambdas ~ exp(normal(log(0.5),1.0))",
    x = "Value",
    y = "Density"
  ) +
  xlim(0, 3) + # Extend slightly beyond 2 to show cutoff
  geom_vline(xintercept = 2, linetype = "dashed", color = "red", size = 1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p2)

# --- 2. half lives
hl_samples_df <- data.frame(
  value = log(2)/lambdas_samples,
  trait = rep(paste0("Trait ", 1:n_traits), each = n_prior_samples)
)

p2 <- ggplot(hl_samples_df, aes(x = value, fill = trait, color = trait)) +
  geom_density(alpha = 0.5, size = 0.8) +
  scale_fill_manual(values = mypal) +
  scale_color_manual(values = mypal_dark) +
  labs(
    title = "Prior: hl ~ log(2)/exp(normal(log(0.5),1.0))",
    x = "Value",
    y = "Density"
  ) +
  xlim(0, 6) + # Extend slightly beyond 2 to show cutoff
  geom_vline(xintercept = 3, linetype = "dashed", color = "red", size = 1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p2)

# --- 3. sigma_P ~ normal(0, 0.5) [implicitly half-normal due to lower=0] ---
sigma_P_samples <- abs(rnorm(n_prior_samples * n_traits, mean = 0, sd = 0.5))
sigma_P_df <- data.frame(
  value = sigma_P_samples,
  trait = rep(paste0("Trait ", 1:n_traits), each = n_prior_samples)
)

p3 <- ggplot(sigma_P_df, aes(x = value, fill = trait, color = trait)) +
  geom_density(alpha = 0.5, size = 0.8) +
  scale_fill_manual(values = mypal) +
  scale_color_manual(values = mypal_dark) +
  labs(
    title = "Prior: sigma_P ~ Half-Normal(0, 0.5)",
    x = "Value",
    y = "Density"
  ) +
  xlim(0, max(sigma_P_df$value) * 1.05) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p3)
cat("\nPrior for sigma_P: Half-Normal(0, 0.5) puts most mass near 0 but allows for larger values.\n")


# --- 4. sigma_Sigma ~ normal(0, 0.5) [implicitly half-normal due to lower=0] ---
sigma_Sigma_samples <- abs(rnorm(n_prior_samples * n_traits, mean = 0, sd = 0.5))
sigma_Sigma_df <- data.frame(
  value = sigma_Sigma_samples,
  trait = rep(paste0("Trait ", 1:n_traits), each = n_prior_samples)
)

p4 <- ggplot(sigma_Sigma_df, aes(x = value, fill = trait, color = trait)) +
  geom_density(alpha = 0.5, size = 0.8) +
  scale_fill_manual(values = mypal) +
  scale_color_manual(values = mypal_dark) +
  labs(
    title = "Prior: sigma_Sigma ~ Half-Normal(0, 0.5)",
    x = "Value",
    y = "Density"
  ) +
  xlim(0, max(sigma_Sigma_df$value) * 1.05) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p4)
cat("\nPrior for sigma_Sigma: Similar to sigma_P, a Half-Normal(0, 0.5).\n")

# --- 5. Omega_P ~ lkj_corr(20) and Omega_Sigma ~ lkj_corr(10) ---
# For n_traits = 2, a correlation matrix only has one unique correlation coefficient: rho_12
# We can plot the density of this correlation.
Omega_P_samples <- rlkjcorr(n_prior_samples, n_traits, eta = 20)
Omega_Sigma_samples <- rlkjcorr(n_prior_samples, n_traits, eta = 10)

# Extract the correlation coefficient (element [1,2])
corr_P_samples <- sapply(Omega_P_samples, function(m) m[1,2])
corr_Sigma_samples <- sapply(Omega_Sigma_samples, function(m) m[1,2])

# Combine for plotting
corr_df <- data.frame(
  value = c(corr_P_samples, corr_Sigma_samples),
  prior = factor(c(rep("Omega_P (eta=20)", n_prior_samples),
                   rep("Omega_Sigma (eta=10)", n_prior_samples)))
)

p5 <- ggplot(corr_df, aes(x = value, fill = prior, color = prior)) +
  geom_density(alpha = 0.5, size = 0.8) +
  scale_fill_manual(values = c(mypal[1], mypal[2])) +
  scale_color_manual(values = c(mypal_dark[1], mypal_dark[2])) +
  labs(
    title = "Priors: LKJ Correlation Matrices",
    subtitle = "Density of correlation coefficient (rho_12)",
    x = "Correlation Coefficient",
    y = "Density"
  ) +
  xlim(-1, 1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p5)
cat("\nPriors for Omega_P (eta=20) and Omega_Sigma (eta=10): LKJ_corr(eta) concentrates probability around identity (zero correlation) as eta increases.\n")
cat("Eta=20 is a strong prior for zero correlation, Eta=10 is slightly weaker.\n")

# --- 6. y_true_raw ~ normal(0, 1) (if using non-centered parameterization) ---
y_true_raw_samples <- rnorm(n_prior_samples, mean = 0, sd = 1)
y_true_raw_df <- data.frame(value = y_true_raw_samples)

p6 <- ggplot(y_true_raw_df, aes(x = value)) +
  geom_density(fill = mypal[1], color = mypal_dark[1], alpha = 0.6) +
  labs(
    title = "Prior: y_true_raw ~ Normal(0, 1) (Non-Centered)",
    x = "Value",
    y = "Density"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p6)
cat("\nPrior for y_true_raw: Standard Normal. This is the 'raw' component when using non-centered parameterization.\n")

cat("\n--- End of Prior Visualization ---\n")
```


Compile model
```{r}
setwd('/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch Project/Blouch Github Site/blouch/inst/stan/')
rstan::stanc('/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch Project/Blouch Github Site/blouch/inst/stan/mvBlouchOU_mitov.stan')
stan_file<-"mvBlouchOU_mitov.stan"

stan_model<-rstan::stan_model(file=stan_file) # Compile the Stan model (this takes time the first time)
```

Debug run with no initial values
```{r}
stan_fit <- rstan::sampling(
    object = stan_model,
    data = dat,
    chains = 2, # Keep at 1 for faster debugging iterations
    cores = 1,   # Keep at 1 core since you're using 1 chain
    iter = 2000, # Keep iterations lower for faster testing
    control = list(max_treedepth=15, adapt_delta=0.99))

```

# Posteriors
```{r}
print(stan_fit,
      pars = c("H_mats", "L_Omega_P", "sigma_P", "Sigma_mats", "theta_mats" 
               ), 
      probs = c(0.025, 0.25, 0.5, 0.75, 0.975), # Default quantiles
      digits_summary = 2) # Adjust number of digits if needed

#rstan::traceplot(stan_fit, pars = c("beta","alpha","theta[1]","es","sd_theta[1]","sd_e[1]"))

post<-rstan::extract(stan_fit)
```

```{r}
library(bayesplot)

# Assuming 'stan_fit' is the object from your last successful run
mcmc_pairs(stan_fit,
           pars = c("H_mats[1,1,1]", "H_mats[1,2,2]","L_Omega_P[1,1,1]", "L_Omega_P[1,2,2]", "sigma_P[1,1]", "Sigma_mats[1,1,2]", "theta_mats[1,1]","theta_mats[1,2]", 
                    "lp__" # Always include lp__ to see if divergences cluster with low likelihood
                    ),
           diag_fun = "dens", off_diag_fun = "scatter", np = nuts_params(stan_fit))
```



```{r}
init_fun <- function() {
  list(
    y_true = as.matrix(dat$y_obs),           # Start latent true values near observed
    y_root = colMeans(dat$y_obs),            # Root trait values as means of observed tips

    Omega_P = replicate(n_regs, diag(n_traits), simplify = FALSE),
    sigma_P = matrix(1, nrow = n_regs, ncol = n_traits),

    Omega_Sigma = replicate(n_regs, diag(n_traits), simplify = FALSE),
    sigma_Sigma = matrix(1, nrow = n_regs, ncol = n_traits),

    log_lambdas = matrix(log(0.5), nrow = n_regs, ncol = n_traits),

    # **Initialize theta_mats with small positive values, e.g. 0.1 instead of 0**
    theta_mats = matrix(0.1, nrow = n_regs, ncol = n_traits)
  )
}


stan_fit <- rstan::sampling(
    object = stan_model,
    data = dat,
    init = init_fun,
    chains = 1, # Keep at 1 for faster debugging iterations
    cores = 1,   # Keep at 1 core since you're using 1 chain
    iter = 500, # Keep iterations lower for faster testing
    control = list(adapt_delta = 0.999, max_treedepth = 20) # <--- IMPORTANT: KEEP THESE ENABLED
)
```



```{r}
create_init_fun <- function(stan_data_list) {
  function() {
    N_val <- stan_data_list$N
    n_traits_val <- stan_data_list$n_traits
    y_obs_val <- stan_data_list$y_obs

    # y_true_raw (continue to randomize around 0,1)
    y_true_raw_init_val <- matrix(rnorm(N_val * n_traits_val, mean = 0, sd = 1),
                                  nrow = N_val, ncol = n_traits_val, byrow = TRUE)

    # mu_y_true_param (initialize near observed mean)
    mu_y_true_param_init_val <- apply(y_obs_val, 2, mean) + rnorm(n_traits_val, 0, 0.1)

    # Fixed safe initial values for log_sigma_y_true
    log_sigma_y_true_init_val <- rep(log(0.8), n_traits_val) # log(0.8) is approx -0.22, a reasonable mid-range value

    # y_0_ancestral_raw (continue to randomize around 0,1)
    y_0_ancestral_raw_init_val <- rnorm(n_traits_val, mean = 0, sd = 1)

    # mu_y_0_ancestral (initialize near observed mean)
    mu_y_0_ancestral_init_val <- apply(y_obs_val, 2, mean) + rnorm(n_traits_val, 0, 0.1)

    # Fixed safe initial values for log_sigma_y_0_ancestral
    log_sigma_y_0_ancestral_init_val <- rep(log(0.8), n_traits_val) # log(0.8) is approx -0.22

    # CRITICAL: Fixed, safe initial values for the key matrix parameters
    #lambdas_init_val <- rep(1.0, n_traits_val)     # Fixed at 1.0 (mid-range of [0,2])
    log_lambdas_init_val <- runif(n_traits_val, log(0.5), log(1.5)) # Adjust range as needed
    Omega_P_init_val <- diag(n_traits_val)         # Identity matrix (no correlation)
    sigma_P_init_val <- rep(0.7, n_traits_val)     # Fixed at 0.7 (mid-range of 0.5-1.0)
    Omega_Sigma_init_val <- diag(n_traits_val)     # Identity matrix (no correlation)
    sigma_Sigma_init_val <- rep(0.7, n_traits_val) # Fixed at 0.7 (mid-range of 0.5-1.0)


    return(list(
      y_true_raw = y_true_raw_init_val,
      mu_y_true_param = mu_y_true_param_init_val,
      log_sigma_y_true = log_sigma_y_true_init_val,
      y_0_ancestral_raw = y_0_ancestral_raw_init_val,
      mu_y_0_ancestral = mu_y_0_ancestral_init_val,
      log_sigma_y_0_ancestral = log_sigma_y_0_ancestral_init_val,
      log_lambdas = log_lambdas_init_val,
      Omega_P = Omega_P_init_val,
      sigma_P = sigma_P_init_val,
      Omega_Sigma = Omega_Sigma_init_val,
      sigma_Sigma = sigma_Sigma_init_val
    ))
  }
}
```

Debug
```{r}
# Create the actual init function that Stan will call
my_init_fun <- create_init_fun(dat)

stan_fit <- rstan::sampling(
    object = stan_model,
    data = dat,
    init = my_init_fun,
    chains = 1, # Keep at 1 for faster debugging iterations
    cores = 1,   # Keep at 1 core since you're using 1 chain
    iter = 500, # Keep iterations lower for faster testing
    control = list(adapt_delta = 0.999, max_treedepth = 20) # <--- IMPORTANT: KEEP THESE ENABLED
)
```

```{r}
# Create the actual init function that Stan will call
my_init_fun <- create_init_fun(dat)

stan_fit <- rstan::sampling(
    object = stan_model,
    data = dat,
    init = my_init_fun,
    chains = 1, # Keep at 1 for faster debugging iterations
    cores = 1,   # Keep at 1 core since you're using 1 chain
    iter = 500, # Keep iterations lower for faster testing
    #control = list(adapt_delta = 0.999, max_treedepth = 20) # <--- IMPORTANT: KEEP THESE ENABLED
)
```



# Posteriors
```{r}
print(stan_fit,
      pars = c("F_mat", "Sigma" 
               ), 
      probs = c(0.025, 0.25, 0.5, 0.75, 0.975), # Default quantiles
      digits_summary = 2) # Adjust number of digits if needed

#rstan::traceplot(stan_fit, pars = c("beta","alpha","theta[1]","es","sd_theta[1]","sd_e[1]"))

post<-rstan::extract(stan_fit)
```


```{r}
library(bayesplot)

# Assuming 'stan_fit' is the object from your last successful run
mcmc_pairs(stan_fit,
           pars = c("y_0_ancestral[1]", "y_0_ancestral[2]",
                    "lambdas[1]", "lambdas[2]", # Now using 'lambdas' which is exp(log_lambdas)
                    "Omega_P[1,2]",
                    "sigma_P[1]", "sigma_P[2]",
                    "Omega_Sigma[1,2]",
                    "sigma_Sigma[1]", "sigma_Sigma[2]",
                    "F_mat[1,1]", "F_mat[2,2]", "F_mat[1,2]",
                    "log_sigma_y_true[1]", "log_sigma_y_true[2]",
                    "log_sigma_y_0_ancestral[1]", "log_sigma_y_0_ancestral[2]",
                    "lp__" # Always include lp__ to see if divergences cluster with low likelihood
                    ),
           diag_fun = "dens", off_diag_fun = "scatter", np = nuts_params(stan_fit))
```


```{r}
library(bayesplot)

# For n_traits = 2, you'll typically have two elements for vectors like lambdas.
# For correlation matrices (Omega_P, Omega_Sigma), you only need to plot one off-diagonal element, e.g., [1,2].
# For F_mat, plot the diagonal and one off-diagonal.

mcmc_pairs(stan_fit,
           pars = c("y_0_ancestral[1]", "y_0_ancestral[2]",
                    "lambdas[1]", "lambdas[2]",
                    "Omega_P[1,2]", # Or "Omega_P[2,1]" as it's symmetric
                    "sigma_P[1]", "sigma_P[2]",
                    "Omega_Sigma[1,2]", # Or "Omega_Sigma[2,1]"
                    "sigma_Sigma[1]", "sigma_Sigma[2]",
                    "F_mat[1,1]", "F_mat[2,2]", "F_mat[1,2]"), # Include key elements of F_mat
           diag_fun = "dens",
           off_diag_fun = "scatter",
           np = nuts_params(stan_fit))
```


Plotting posterior vs prior for R Matrix
```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(tidybayes) # For spread_draws, gather_draws, median_qi

# Assuming stan_fit is your fitted Stan model object from the previous run

# Extract posterior samples for R directly
# The `gather_draws` function from tidybayes is great for this.
# It automatically converts to a long format suitable for ggplot.
R_posterior_long <- stan_fit %>%
  gather_draws(R[i, j]) %>% #i and j are placeholders for variables
  ungroup() %>% # Remove grouping for easier manipulation
  select(-.chain, -.iteration, -.draw) # Remove internal tidybayes columns if not needed

# Rename columns for clarity
R_posterior_long <- R_posterior_long %>%
  rename(trait1 = i, trait2 = j, value = .value) %>%
  mutate(
    parameter_name = paste0("R[", trait1, ",", trait2, "]"),
    type = "Posterior"
  )

# You'll also need the values of `sigma_R` and `Omega` for the prior (if we simulate from them)
# For now, let's focus on R directly.
```

```{r}

# --- 3. Define the function to simulate R from its Prior ---
# This function simulates from the priors on sigma_R (half-normal) and Omega (correlation matrix).
# NOTE: The correlation matrix simulation (Omega_prior) here uses a heuristic
# (cov2cor(tcrossprod(Z))) because `rlkjcorr` is not available in rstan.
# This heuristic produces valid random correlation matrices, but might not
# precisely match the `lkj_corr(2)` prior for Omega as closely as a dedicated LKJ sampler.
# However, it provides a valuable visual comparison.
simulate_R_prior <- function(n_traits, sigma_prior_sd) {
  # 1. Generate a random correlation matrix (Omega_prior)
  # This method generates a random positive definite matrix and then normalizes it.
  Z <- matrix(rnorm(n_traits * n_traits), n_traits, n_traits)
  Omega_prior <- cov2cor(tcrossprod(Z))

  # 2. Simulate sigma_R from a half-normal prior (abs of normal)
  # Your Stan model uses sigma_R ~ normal(0, 1), which for a <lower=0>
  # constraint means it's a half-normal(0,1).
  sigma_R_prior <- abs(rnorm(n_traits, 0, sigma_prior_sd))

  # 3. Construct the R matrix from sigma_R and Omega
  R_mat <- diag(sigma_R_prior) %*% Omega_prior %*% diag(sigma_R_prior)
  return(R_mat)
}

# --- 4. Generate Prior Samples for R ---
n_prior_samples <- 4000 # Number of prior samples to generate for smooth density

R_prior_list <- list()
for (s in 1:n_prior_samples) {
  R_prior_list[[s]] <- simulate_R_prior(
    n_traits = dat$n_traits,      # Using n_traits from your data list
    sigma_prior_sd = sigma_R_prior_sd            #
  )
}

# Convert prior samples to a long format similar to the posterior
# This part is specifically for n_traits = 2. For larger n_traits,
# you'd need a more generic way to flatten each R_mat, e.g., using `as.vector`
# and then recreating indices.
R_prior_long <- bind_rows(lapply(1:n_prior_samples, function(s) {
  R_mat <- R_prior_list[[s]]
  tibble(
    value = c(R_mat[1,1], R_mat[1,2], R_mat[2,1], R_mat[2,2]),
    trait1 = rep(c(1,1,2,2), length.out = length(value)),
    trait2 = rep(c(1,2,1,2), length.out = length(value)),
    sample_id = s
  )
})) %>%
  mutate(
    parameter_name = paste0("R[", trait1, ",", trait2, "]"),
    type = "Prior"
  ) %>%
  select(-sample_id) # Remove sample_id once converted

# --- 5. Combine Posterior and Prior Data for Plotting ---
plot_data_R <- bind_rows(R_posterior_long, R_prior_long)
```

```{r}

# --- 6. Plotting with ggplot2 (Corrected for linewidth) ---
# Define a custom color palette for Prior and Posterior
my_colors <- c("Prior" = "skyblue", "Posterior" = "darkred")

# Order the facets for better presentation (optional: diagonals first, then off-diagonals)
plot_data_R$parameter_name <- factor(plot_data_R$parameter_name,
                                     levels = c("R[1,1]", "R[2,2]", "R[1,2]", "R[2,1]"))

# Create a data frame for true R values to add as vertical lines
true_R_values_df <- data.frame(
  parameter_name = factor(c("R[1,1]", "R[2,2]", "R[1,2]", "R[2,1]"),
                          levels = c("R[1,1]", "R[2,2]", "R[1,2]", "R[2,1]")),
  true_value = c(R_true[1,1], R_true[2,2], R_true[1,2], R_true[2,1])
)


ggplot(plot_data_R, aes(x = value, fill = type, color = type)) +
  geom_density(alpha = 0.5, linewidth = 0.8) + # CHANGED: size = 0.8 -> linewidth = 0.8
  facet_wrap(~ parameter_name, scales = "free", ncol = 2) +
  scale_fill_manual(values = my_colors) +
  scale_color_manual(values = my_colors) +
  labs(
    title = "Posterior vs. Prior Distributions for R Matrix Elements",
    x = "Value",
    y = "Density",
    fill = "Distribution",
    color = "Distribution"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom") +
  # Add vertical lines for true R values (only for simulation studies)
  geom_vline(data = true_R_values_df, aes(xintercept = true_value),
             linetype = "dashed", color = "darkgreen", linewidth = 0.8) # CHANGED: size = 0.8 -> linewidth = 0.8

```

