---
title: "Simulation-Example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simulation-Example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This example is the Simulation Example from Grabowski (in revision). Below data is simulated following the Multi-optima Adaptive Model generative model, and then Blouch uses the Multilevel Multi-optima Adaptive Model with Varying Effects and the non-multilevel version of the same model to estimate the known parameter values. Model comparison is also explored.

```{r setup}
rm(list=ls())
library(blouch)
#devtools::load_all()
```

The tree.10K phylogeny is inlcuded with the Blouch package and comes from https://10ktrees.nunn-lab.org/. This is Version 3 of their primate phylogeny with 301 tips. Here we randomly reduce the tip number to 100 for a more managable tree.
```{r Make_tree}
########################################################################################################
#Four regimes with one adaptive trait and multiple slopes per optima but single alpha parameter
set.seed(10) #Set sequence of random numbers for replicability
N<-100 #Number of species

phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N]) 
phy<-ape::multi2di(phy)

l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1
phy$edge.length<-phy$edge.length/l.tree 

```

Lets plot the tree with nodes labeled - these will be where we will be placing our regime shifts in the next step. Lets use nodes - c(164,192,104)
```{r Explore_nodes}
#Set regimes - manually - 2 regimes
#Locate nodes
plot(phy,no.margin=TRUE,edge.width=2,cex=0.7)
ape::nodelabels(frame="none",adj=c(1.1,-0.4))
ape::tiplabels()

#png("", width = 400, height = 400, type = "cairo-png")
#dev.off()

```

############################################################################################################
## Combine data and tree and paint regimes on tree.
Next we will use the treeplyr package (Uyeda and Harmon, 2014) make.treedata function to combine the data and tree based on the "species" column, which has the taxa names. See https://github.com/uyedaj/treeplyr for more on this package. Then we will place the regime shifts on the tree that were identified earlier using Blouch's set.converge.regimes() function. Finally we will plot the tree with the shifts colored to make sure we have done everything correctly.

```{r Set_regimes}
trdata<-data.frame(phy$tip.label)
trdata<-treeplyr::make.treedata(phy,trdata)

shifts<-c(164,192,104) #Location of nodes with regime shifts #100 species
trdata<-set.converge.regimes(trdata,shifts)


#Check if manual setting code worked
shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label)
edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]])
#print(edge.regimes)

#reg.colors<-ggsci::pal_aaas("default",alpha=0.7)(4)
reg.colors<-ggsci::pal_npg(palette=c("nrc"),alpha=1)(4)

print(reg.colors)
plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1,show.tip.label=FALSE)
#tiplabels(pch=19,cex=1,col=reg.colors[factor(trdata$dat$regimes)])

reg_tips<-trdata$dat$regimes
reg_tips<-as.numeric(as.factor(reg_tips))

```

############################################################################################################
## Get info on phylogeny
```{r Make_regime_data}
n<-length(trdata$phy$tip.label)

regimes_internal <-trdata$phy$node.label
regimes_tip <- trdata$dat$regimes
regimes <- concat.factor(regimes_tip, regimes_internal)
anc_maps<-"regimes"
lineages <- lapply(1:n, function(e) lineage.constructor(trdata$phy, e, anc_maps, regimes, ace)) #Trace lineage from tips (n) to root and determine regimes of each node or branch


```


Set true parameters and simulate data - using four different optima (intercepts) with four different slopes.
```{r Simulate_data}
#########################
hl<-0.1 #0.1, 0.25, 0.75 - testing options
a<-log(2)/hl
vy<-0.01 #0.25,0.5 - testing options
sigma2_y<-vy*(2*(log(2)/hl));

vX0<-0
vY0 <- 0
Sxx<-10 #Look at effects

X<-phytools::fastBM(phy,a=vX0,sig2=Sxx,internal=FALSE) #Simulate X BM variable on tree, with scaling 10
sigma2_x<-matrix(1,1,1)
Z_adaptive<-1
names(X)<-phy$tip.label
phytools::phenogram(phy,X,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data

optima_matrix<-weight.matrix(trdata$phy, a, lineages) #Slouch approach
pred_X<-calc_adaptive_dmX(phy,a,X)
optima<-c(1,2,3,4)
beta<-c(0.75,0.5,0.35,0.25) #Two Optima/Two Slopes

mu<-matrix(NA,N,1)
for(i in 1:N){
  mu[i] = optima_matrix[i,]%*%optima+beta[reg_tips[i]]%*%pred_X[i]

}

n_reg<-length(unique(regimes))
V<-calc_adaptive_V(phy,a, sigma2_y,  beta,  sigma2_x, Z_adaptive)
Y<-MASS::mvrnorm(n=1,mu,V)

df<-data.frame(Y=Y,X=X)


ggplot2::ggplot(data=df,ggplot2::aes(x=X,y=Y))+
  ggplot2::geom_point()
summary(lm(Y~X,df))


```

Simulate measurement error
```{r Simulate_ME}
##################################################################################################################
#Simulate errors - original Hansen setup
Z_X_error<-1 #Number of X traits with error
X_error<-matrix(0.01,nrow=N,ncol=Z_X_error)
X_error<-data.frame(X_error)
#names(X_error)<-c("Xd_error","Xa_error")
Y_error<-rep(0.01,N)
Y_with_error<-Y+rnorm(N,0,0.01)
X_with_error<-X+rnorm(N,0,0.01)

```

The first line below combines the existing trdata file which just has regime info for the tips with the X and Y predictor values and their errors. We will use the helper function blouch.reg.adapt.prep() to setup the dat file for Stan. This function and the other helper functions require trdata files, and then the names of the columns that contain Y and (sometimes depending on the model) X data and error data. "Z_adaptive" is the number of predictors, with "regimes" the name of the column where the tip regime data is located.
```{r Data_setup}
############################################################################################################
#Code using blouch.prep function
############################################################################################################
#Make trdata file
trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error)))
dat<-blouch.reg.adapt.prep(trdata,"Y_with_error","Y_error","X_with_error","X_error",Z_adaptive=1,"regimes")

```

Lets check out our simulated data with reasonable values for the priors shown in light grey lines. These are the ".sims" values - the priors are based on the intercept and slope of an OLS regression. See Grabowski (in revision) for more on these priors.
```{r Exploring_priors}
############################################################################################################
#Prior Exploration Plot
lm.allometric<-summary(lm(dat$Y_obs~dat$X_obs))
lm.allometric$coefficients

alpha.sims<-rnorm(100,lm.allometric$coefficients[1],1.5)
beta.sims<-rnorm(n=100,lm.allometric$coefficients[2],0.25)

df<-data.frame(Y=dat$Y_obs,X=dat$X_obs[,1])
names(df)<-c("Y","X")

slope.plot<-ggplot2::ggplot()+  
  ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=regimes_tip))+
  ggplot2::geom_abline(intercept=alpha.sims,slope=beta.sims,alpha=0.1)+
  ggplot2::theme_bw()+
  ggplot2::theme(
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank())+
  
  #ggtitle("Prior vs. Posterior for Intercept and Slope")+
  ggplot2::ylab("Y") + ggplot2::xlab("Adaptive Predictor")+
  ggsci::scale_color_npg()

slope.plot

```
First we will run the Multilevel Multi-optima Adaptive Model with Varying Effects. This will allow our intercepts (optima) and slopes to vary with the regimes. As a multilevel model, information can be shared across the regimes, resulting in possibly more accurate parameter estimates. Below are the priors used for this simulation. See Grabowski (in revision) for more on setting these priors. To change these values requires you to open the Stan function, in this case blouchOU_reg_adapt_mlm_ve, and manually edit them. Unfortunately there is no way around this at present, but trust me - it will be worth it.

For example, here are the four most important priors for the models below - these values are explored in Grabowski (in revision). Remember, always do prior predictive simulations first - in other words, look at distributions of the values and see if they are actually biologically possible.

```{r, eval=FALSE}
########################################################################################################
#Priors
#hl ~ lognormal(log(0.25),0.25);
#vy ~ exponential(20);
#optima_bar ~ normal(2.88,1.5);
#beta_bar ~ normal(0.31,0.25);
```

And here are the lines of Stan code for setting these priors. To change the values to make them appropriate for  your own analyses, you just need to change the numbers. All stan programs are in the Blouch/inst/stan folder and named according to the model they run. See Table S1 of Grabowski (in revision) for more on the model names.
```{r, eval=FALSE}
#Stan Code
target += lognormal_lpdf(hl|log(0.25),0.25);
target += exponential_lpdf(vy|20);
target += normal_lpdf(optima_bar|2.88,1.5);
target += normal_lpdf(beta_bar|0.31,0.25);

```

```{r MLM_VE_Model , results='hide'}
########################################################################################################
#Priors
#hl ~ lognormal(log(0.25),0.25);
#vy ~ exponential(20);
#optima_bar ~ normal(2.88,1.5);
#beta_bar ~ normal(0.31,0.25);
#Rho ~ lkj_corr(4);

fit.reg.adapt.mlm.ve<- rstan::sampling(blouch:::stanmodels$blouchOU_reg_adapt_mlm_ve,data = dat,chains = 1,cores=1,iter =400)
```

```{r Plot_results_MLM_VE_Model}
print(fit.reg.adapt.mlm.ve,pars = c("hl","vy","optima_bar","beta_bar","Rho","sigma","optima","beta","beta_e"))
#plot(rethinking::precis(fit.reg.adapt.mlm.ve,depth=3,pars = c("hl","vy","optima_bar","beta_bar","Rho","sigma","optima","beta","beta_e"))) #For use with rethinking package
post.mlm.ve<-rstan::extract(fit.reg.adapt.mlm.ve) #Extract posterior distribution 
```

Now let's run the non-multilevel version of the same model. We will compare these two models in terms of their predictive performance below.
```{r VE_Model , results='hide'}
########################################################################################################
#Milestone 15 - varying effects model
#Combination of regime model with adaptive model with measurement error and varying slopes
#Priors
#hl ~ lognormal(log(0.25),0.25);
#vy ~ exponential(20);
#optima ~ normal(2.88,1.5);//Original 4 regimes
#for(i in 1:(Z_adaptive)){
#  beta[,i] ~ normal(0.31,0.25);
#}

fit.reg.adapt.ve<- rstan::sampling(blouch:::stanmodels$blouchOU_reg_adapt_ve,data = dat,chains = 1,cores=1,iter =400)
```

Stan prints out a lot of info, so lets just look at the parameter estimates here and store the posterior distribution for later.

```{r Plot_results_VE_Model , results='hide'}
print(fit.reg.adapt.ve,pars = c("hl","vy","optima","beta","beta_e"))
#plot(rethinking::precis(fit.reg.adapt.ve,depth=3,pars = c("hl","vy","optima","beta","beta_e")))#For use with rethinking package
post.ve<-rstan::extract(fit.reg.adapt.ve)#Extract posterior distribution 

```

Great. Now lots plot the prior vs. the posterior for the most important parameters. Lets use theMulti-optima Adaptive Model with Varying Effects - the other model's posterior looks quite similar.
First the half-life (hl)
```{r Plot_hl}
########################################################################################################
#Hl Plot prior vs. posterior - assume posterior has been extracted using extract(model) and stored in post

hl.sims<-data.frame(rlnorm(n=1000,meanlog=log(0.25),sdlog=0.25))
names(hl.sims)<-"prior.hl.sims"

hl.post<-data.frame(post.ve$hl) #Using this model's posterior
names(hl.post)<-"post.hl.sims"

hl.plot<-ggplot2::ggplot()+
  ggplot2::geom_density(ggplot2::aes(prior.hl.sims,fill="prior.hl.sims"),alpha=0.2,data=hl.sims)+
  ggplot2::geom_density(ggplot2::aes(post.hl.sims,fill="post.hl.sims"),alpha=0.2,data=hl.post)+
  ggplot2::theme_bw()+
  ggplot2::theme(
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank())+
  
  #labs(title="Prior vs. Posterior Distribution ",x="Half-life", y = "Density")+
  ggplot2::labs(title="",x="Half-life", y = "Density")+
  
  #scale_fill_manual(labels=c("Posterior","Prior"))+
  ggplot2::geom_vline(xintercept=c(hl),linetype=2)+
  ggsci::scale_fill_npg(name="",labels=c("Posterior","Prior"))

hl.plot
########################################################################################################
```

Now the stationary variance parameter (Vy)
```{r Plot_vy}
vy.sims<-rexp(n=1000,rate=20)
vy.sims<-data.frame(vy.sims)
names(vy.sims)<-"prior.vy.sims"


vy.post<-data.frame(post.mlm.ve$vy)
names(vy.post)<-"post.vy.sims"


vy.plot<-ggplot2::ggplot()+
  ggplot2::geom_density(ggplot2::aes(prior.vy.sims,fill="prior.vy.sims"),alpha=0.2,data=vy.sims)+
  ggplot2::geom_density(ggplot2::aes(post.vy.sims,fill="post.vy.sims"),alpha=0.2,data=vy.post)+
  ggplot2::theme_bw()+
  ggplot2::theme(
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank())+
  
  #labs(title="Prior vs. Posterior Distribution ",x="vy", y = "Density")+
  ggplot2::labs(title="",x="vy", y = "Density")+
  ggplot2::geom_vline(xintercept=c(vy),linetype=2)+
  
  #scale_fill_manual(labels=c("Posterior","Prior"))+
  ggsci::scale_fill_npg(name="",labels=c("Posterior","Prior"))

vy.plot

```

Now lets plot the covariance as a function of distance from the tips - this gives an idea of the decay of covariance in the OU process. We will use Blouch's helper function, calc_multiadaptive_cov_plot.R to make these plots.
```{r Plot_cov}
########################################################################################################
#Adaptation model - multiple regimes
a.sims<-log(2)/hl.sims;
sigma2_y.sims<-vy.sims*(2*(log(2)/hl.sims));
beta.sims<-replicate(length(beta),rnorm(n=1000,0,0.25))

mypal <- ggsci::pal_npg("nrc", alpha = 0.4)(2)

plot( NULL , xlim=c(0,1) , ylim=c(0,0.3) , xlab="Time since MRCA" , ylab="Covariance" ,cex.axis=0.75, mgp=c(1.25,0.25,0),tcl=-0.25)
for (i in 1:30){
  curve(calc_multiadaptive_cov_plot(a.sims[i,],sigma2_y.sims[i,],beta.sims[i,],x,Z_adaptive,n_reg) , add=TRUE , lwd=4 ,col=mypal[2]) #Prior - blue
}

for (i in 1:30){
  curve(calc_multiadaptive_cov_plot(post.mlm.ve$a[i],post.mlm.ve$sigma2_y[i],as.numeric(data.frame(post.mlm.ve$beta)[i,]),x,Z_adaptive,n_reg) , add=TRUE , lwd=4 , col=mypal[1]) #Posterior - red
}

par(mar=c(3,3,0.25,0.25)) 
covariance.plot <- recordPlot()
dev.off()
covariance.plot
########################################################################################################

```

Finally lets plot the results - the posterior compared to the prior for the estimated regressions.
```{r Plot_regressions}
#Four regimes - Slope plots for adaptive model with measurement error
#library(ggsci)
#library(rethinking)
X<-X_with_error
Y<-Y_with_error

optima.sims<-rnorm(100,1.89,1.5)
beta.sims<-rnorm(100, 0.5,0.25)

optima.post<-post.mlm.ve$optima
beta.post<-data.frame(post.mlm.ve$beta)
names(beta.post)<-c("post.beta.1","post.beta.2","post.beta.3","post.beta.4")


mu.link.11<-function(x.seq){optima.post[,1]+x.seq*beta.post[,1]}
mu.link.12<-function(x.seq){optima.post[,2]+x.seq*beta.post[,2]}

mu.link.21<-function(x.seq){optima.post[,3]+x.seq*beta.post[,3]}
mu.link.22<-function(x.seq){optima.post[,4]+x.seq*beta.post[,4]}

x.seq <- seq(from=min(X), to=max(X) , length.out=100)
mu.11 <- sapply(x.seq , mu.link.11 )
mu.12 <- sapply(x.seq , mu.link.12 )
mu.21 <- sapply(x.seq , mu.link.21 )
mu.22 <- sapply(x.seq , mu.link.22 )


mu.mean.11<-colMeans(mu.11)
mu.mean.12<-colMeans(mu.12)
mu.mean.21<-colMeans(mu.21)
mu.mean.22<-colMeans(mu.22)


mu.mean.11<-data.frame(as.numeric(mu.mean.11))
mu.mean.12<-data.frame(as.numeric(mu.mean.12))
names(mu.mean.11)<-"mu.mean.11"
names(mu.mean.12)<-"mu.mean.12"

mu.mean.21<-data.frame(as.numeric(mu.mean.21))
mu.mean.22<-data.frame(as.numeric(mu.mean.22))
names(mu.mean.21)<-"mu.mean.21"
names(mu.mean.22)<-"mu.mean.22"



mu.CI.11 <- apply( mu.11 , MARGIN=2, FUN=rethinking::PI , prob=0.89 )
mu.CI.12 <- apply( mu.12 , MARGIN=2, FUN=rethinking::PI , prob=0.89 )


mu.CI.11<-data.frame(t(data.frame(mu.CI.11)),x.seq)
mu.CI.12<-data.frame(t(data.frame(mu.CI.12)),x.seq)

mu.CI.21 <- apply( mu.21 , MARGIN=2, FUN=rethinking::PI , prob=0.89 )
mu.CI.22 <- apply( mu.22 , MARGIN=2, FUN=rethinking::PI , prob=0.89 )

mu.CI.21<-data.frame(t(data.frame(mu.CI.21)),x.seq)
mu.CI.22<-data.frame(t(data.frame(mu.CI.22)),x.seq)


names(mu.CI.11)<-c("min.5.5","max.94.5","x.seq")
names(mu.CI.12)<-c("min.5.5","max.94.5","x.seq")
names(mu.CI.21)<-c("min.5.5","max.94.5","x.seq")
names(mu.CI.22)<-c("min.5.5","max.94.5","x.seq")

#df<-data.frame(Y=stan_sim_data$Y,X=stan_sim_data$direct_cov)
df<-data.frame(Y=dat$Y_obs,X=dat$X_obs,Regimes=regimes_tip)
df11<-data.frame(x.seq,mu.mean.11)
df12<-data.frame(x.seq,mu.mean.12)
df21<-data.frame(x.seq,mu.mean.21)
df22<-data.frame(x.seq,mu.mean.22)

mypal <- ggsci::pal_npg("nrc", alpha = 0.7)(length(beta))

#slope.prior.plot<-ggplot(data=reg.trdata$dat,aes(y=Sim1,x=X))+
slope.plot.1<-ggplot2::ggplot()+  
  ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=Regimes))+#,size=0.75)+
  ggplot2::geom_abline(intercept=optima.sims,slope=beta.sims,alpha=0.1)+ #Prior
  
  ggplot2::geom_abline(intercept=optima[1],slope=beta[1],alpha=0.5,linetype=2)+
  ggplot2::geom_abline(intercept=optima[2],slope=beta[2],alpha=0.5,linetype=2)+
  ggplot2::geom_abline(intercept=optima[3],slope=beta[3],alpha=0.5,linetype=2)+
  ggplot2::geom_abline(intercept=optima[4],slope=beta[4],alpha=0.5,linetype=2)+
  
  ggplot2::geom_line(data=df11,ggplot2::aes(x=x.seq,y=mu.mean.11),linetype=1)+
  ggplot2::geom_ribbon(data=mu.CI.11,ggplot2::aes(x=x.seq,ymin=min.5.5,ymax=max.94.5),linetype=2,alpha=0.2)+
  ggplot2::geom_line(data=df12,ggplot2::aes(x=x.seq,y=mu.mean.12),linetype=1)+
  ggplot2::geom_ribbon(data=mu.CI.12,ggplot2::aes(x=x.seq,ymin=min.5.5,ymax=max.94.5),linetype=2,alpha=0.2)+
  
  ggplot2::geom_line(data=df21,ggplot2::aes(x=x.seq,y=mu.mean.21),linetype=1)+
  ggplot2::geom_ribbon(data=mu.CI.21,ggplot2::aes(x=x.seq,ymin=min.5.5,ymax=max.94.5),linetype=2,alpha=0.2)+
  ggplot2::geom_line(data=df22,ggplot2::aes(x=x.seq,y=mu.mean.22),linetype=1)+
  ggplot2::geom_ribbon(data=mu.CI.22,ggplot2::aes(x=x.seq,ymin=min.5.5,ymax=max.94.5),linetype=2,alpha=0.2)+
  
  
  ggplot2::theme_bw()+
  ggplot2::theme(
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank())+
  
  # Right -> inside the plot area
  ggplot2::theme(
    legend.position = c(.8, .3),
    legend.justification = c("left", "top"),
    legend.box.just = "left",
    legend.margin = ggplot2::margin(6, 6, 6, 6)
  )+
  
  #ggtitle("Prior vs. Posterior for Intercept and Slope")+
  ggplot2::ylab("Y") + ggplot2::xlab("Adaptive trait")+
  ggsci::scale_color_npg()

slope.plot.1

#####
```

## Model Comparison using PSIS
Lets do some model comparison using PSIS from the R Package loo
```{r Model_comparison_PSIS}
#library(loo) 
#Mlm varying effects model
loo_mlm_ve <- loo::loo(fit.reg.adapt.mlm.ve, save_psis = TRUE)
print(loo_mlm_ve)
plot(loo_mlm_ve) #4X6
plot(loo_mlm_ve,label_points=TRUE) #Label outliers

#library(loo) #Varying effects model
loo_ve <- loo::loo(fit.reg.adapt.ve, save_psis = TRUE)
print(loo_ve)
plot(loo_ve) #4X6
plot(loo_ve,label_points=TRUE) #Label outliers

loo::loo_compare(loo_mlm_ve, loo_ve)

```
These results suggest the two models are indistinguishable - the standard error of the difference between the expected log pointwise predictive density (elpd) for the two models is larger than the difference.


## Model Comparison using Bayes Factors
Now lets compare our two models using Bayes Factors. Here we use the bridgesampling R package. Looking below, we can read the results as the data is X times more likely under a model that assumes the first mode rather than second model.
```{r Model_comparison_BF}
########################################################################################################
#Bayes Factors
lml.fit.reg.adapt.mlm.ve<-bridgesampling::bridge_sampler(fit.reg.adapt.mlm.ve,silent=TRUE,maxiter=5000)
lml.fit.reg.adapt.ve<-bridgesampling::bridge_sampler(fit.reg.adapt.ve,silent=TRUE,maxiter=5000)

bridgesampling::bf(lml.fit.reg.adapt.mlm.ve,lml.fit.reg.adapt.ve)

```


### Trace and Density Plots for estimated parameters
Let's look at traceplots of our two models, which give a visualization of degree of convergence.

```{r Traceplots}
########################################################################################################
#Traceplots #4X10
rstan::traceplot(fit.reg.adapt.mlm.ve,pars = c("hl","vy","optima_bar","beta_bar","Rho","sigma","optima","beta"))
rstan::traceplot(fit.reg.adapt.ve,pars = c(c("hl","vy","optima","beta","beta_e")))

```

##Prior predictive checks
Now lets run prior predictive checks and posterior predictive checks for our two models
```{r Prior_pc}
fit.reg.adapt.mlm.ve.priorpc<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_mlm_ve_priorpc,data = dat,chains = 2,cores=2,iter =2000, algorithm=c("Fixed_param"))
post<-rstan::extract(fit.reg.adapt.mlm.ve.priorpc)
mypal <- ggsci::pal_aaas("default", alpha = 1)(4)

df<-data.frame(Y=post$Y_sim_obs[3,],X=dat$Y_obs,Regimes=regimes_tip)

priorpc.plot<-ggplot2::ggplot()+  
  ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=as.factor(Regimes)))+
  ggplot2::geom_abline(intercept=0,slope=1,alpha=1)+ #Prior
  
  ggplot2::theme_bw()+
  ggplot2::theme(
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank())+
  
  ggplot2::ggtitle("Prior Predictive Check")+
  ggplot2::ylab("Simulated Y") + ggplot2::xlab("True Y")+
  ggplot2::scale_color_manual(name="Regimes",values=mypal,labels=c('OU1', 'OU2', 'OU3', 'OU4'))


priorpc.plot


```

##Posterior predictive checks
```{r Posterior_pc}
########################################################################################################
#stan_model <- stan_model("blouchOU_reg_adapt_mlm_ve_postpc.stan")
fit.reg.adapt.mlm.ve.postpc<-rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_mlm_ve_postpc,data = dat,chains = 2,cores=2,iter =2000, algorithm=c("Fixed_param"))
post<-rstan::extract(fit.reg.adapt.mlm.ve.postpc)

#plot(post$Y_sim_obs[1,],dat$Y_obs)

mypal <- ggsci::pal_aaas("default", alpha = 1)(4)

#plot(post$Y_sim_obs[3,],dat$Y_obs)

df<-data.frame(Y=post$Y_sim_obs[3,],X=dat$Y_obs,Regimes=regimes_tip)

postpc.plot<-ggplot2::ggplot()+  
  ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=as.factor(Regimes)))+
  ggplot2::geom_abline(intercept=0,slope=1,alpha=1)+ #Prior
  
  ggplot2::theme_bw()+
  ggplot2::theme(
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank())+
  
  ggplot2::ggtitle("Posterior Predictive Check")+
  ggplot2::ylab("Simulated Y") + ggplot2::xlab("True Y")+
  ggplot2::scale_color_manual(name="Regimes",values=mypal,labels=c('OU1', 'OU2', 'OU3', 'OU4'))


postpc.plot


########################################################################################################


```



