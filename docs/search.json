[{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://mark-grabowski.github.io/blouch/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"direct-effect-model","dir":"Articles","previous_headings":"","what":"Direct effect model","title":"Basic Models-Examples","text":"Blouch implements model constrained evolution (Hansen & Bartoszek, 2012) known direct effect model, previously implemented Grabowski et al. (2016; see also Grabowski et al. 2023), can used test allometric constraints.","code":""},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"create-phylogeny","dir":"Articles","previous_headings":"","what":"Create Phylogeny","title":"Basic Models-Examples","text":"Blouch package includes primate phylogeny 10KTrees Project (Arnold et al. 2010), used various simulations comes https://10ktrees.nunn-lab.org/. Version 3 primate phylogeny 301 tips. randomly reduce tip number 100 manageable tree using functions ape R package (Paradis et al. 2004)","code":"######################################################################################################## #Create phylogeny ######################################################################################################## N<-50 #Number of species set.seed(10) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   tip.label<-phy$tip.label"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"set-trueknown-parameter-values","dir":"Articles","previous_headings":"","what":"Set true/known parameter values","title":"Basic Models-Examples","text":"Next set true/known parameter values. half-life (hl), stationary variance (vy), simulation translate \\(\\alpha\\) () \\(\\sigma^2_y\\) (sigma2_y). set ancestral value root (vX0) 0, instantaneous variance BM process (Sxx) 10.","code":"######################################################################################################## #Direct Effect Model ######################################################################################################## #Setup parameters Z_direct<-1 #Number of traits hl<-0.1 #half life a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl));  vX0<-0 #value for ancestral state at the root node.  vY0 <- 0 #value for ancestral state at the root node.   Sxx<-10 #Variance of BM process"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"calculate-v-and-simulate-x-data","dir":"Articles","previous_headings":"","what":"Calculate V and simulate X data","title":"Basic Models-Examples","text":"use Blouch helper R function calc_direct_V calculate direct effect variance/covariance matrix, fastBM function phytools (Revell, 2011) simulate X variable following BM process.","code":"V<-calc_direct_V(phy,sigma2_y,a) #Calculate V - variance/covariance matrix X<-phytools::fastBM(phy,a=vX0,sig2=Sxx,internal=FALSE) #Simulate X BM variable on tree, with scaling 10 phytools::phenogram(phy,X,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels..."},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"simulate-y-data","dir":"Articles","previous_headings":"","what":"Simulate Y data","title":"Basic Models-Examples","text":"Next set intercept slope parameters, simulate mu using V simulate Y. Finally make quick plot results. set intercept (alpha term) 2 slope 0.25.","code":"alpha<-2 #Intecept beta<-0.25 #Slope  mu<-alpha+X*beta #Simulate mu for Y  Y<-MASS::mvrnorm(n=1,mu,V) #Simulate direct effect Y trait  df<-data.frame(Y=Y,X=X) names(df)<-c(\"Y\",\"X\")  ggplot2::ggplot(data=df,ggplot2::aes(x=X,y=Y))+   ggplot2::geom_point() summary(lm(Y~X,df)) #>  #> Call: #> lm(formula = Y ~ X, data = df) #>  #> Residuals: #>       Min        1Q    Median        3Q       Max  #> -0.244026 -0.069756  0.007519  0.073226  0.211013  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 2.012890   0.016976  118.58   <2e-16 *** #> X           0.255071   0.004838   52.72   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.1067 on 48 degrees of freedom #> Multiple R-squared:  0.983,  Adjusted R-squared:  0.9827  #> F-statistic:  2779 on 1 and 48 DF,  p-value: < 2.2e-16"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"simulating-measurement-error","dir":"Articles","previous_headings":"","what":"Simulating measurement error","title":"Basic Models-Examples","text":"Next simulate measurement error - use standard deviation measurement error 0.01, provide Blouch vector (X_error Y_error), use rnorm function add error X Y variables. words, telling Blouch estimated error X Y 0.01, providing X Y variables offset random amount error standard deviation.","code":"X_error<-rep(0.01,N) Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-X+rnorm(N,0,0.01)"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"combine-data-and-tree","dir":"Articles","previous_headings":"","what":"Combine data and tree","title":"Basic Models-Examples","text":"Next use treeplyr package (Uyeda Harmon, 2014) make.treedata function combine data tree based taxa names. See https://github.com/uyedaj/treeplyr package.","code":"############################################################################################################ #Make trdata file trait.data<-data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error)) trdata<-treeplyr::make.treedata(phy,trait.data)"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"data-setup-for-blouch","dir":"Articles","previous_headings":"","what":"Data setup for Blouch","title":"Basic Models-Examples","text":"use helper function blouch.direct.prep setup dat file Stan. name column trdata$dat contains response variable “Y_with_error”, associated error column name “Y_error,” direct effect predictor column named “X_with_error”, associated errors “X_error”. Finally, give heloper function number predictor traits, 1 .","code":"############################################################################################################ #Test Blouch prep code - direct effect model - blouch.direct.prep() dat<-blouch.direct.prep(trdata,\"Y_with_error\",\"Y_error\",\"X_with_error\",\"X_error\",Z_direct=Z_direct)"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"exploring-priors","dir":"Articles","previous_headings":"","what":"Exploring Priors","title":"Basic Models-Examples","text":"point one want explore priors appropriate - see Simulation Example article one way go .","code":""},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"running-models","dir":"Articles","previous_headings":"","what":"Running models","title":"Basic Models-Examples","text":"run direct effect model first. priors used simulation. See Grabowski (revision) setting priors. change values requires open Stan function, case blouchOU_direct, manually edit . Unfortunately way around present, trust - worth . example, four important priors model - values explored Grabowski (revision). Remember, always prior predictive simulations first - words, look distributions values see actually biologically possible - see exploring priors step . lines Stan code setting priors. change values make appropriate analyses, just need change numbers . Stan programs Blouch/inst/stan folder named according model run. See Table S1 Grabowski (revision) models. Remember, priors based know biological processes underlying research question prior predictive simulations (see McElreath 2020) Now let’s run direct effect model blouchOU_direct. Now let’s look results posteriors explored, compared priors, etc. See Simulation Example one example .","code":"######################################################################################################## #Priors #hl ~ lognormal(log(0.25),0.25); #vy ~ exponential(10); #alpha ~ normal(2.0,0,75); #beta ~ normal(0.25,1.5); #Stan Code   target += lognormal_lpdf(hl|log(0.25),0.25);   target += exponential_lpdf(vy|10);   target += normal_lpdf(alpha|2.0,0.75);   target += normal_lpdf(beta|0.25,1.5); fit.direct<- rstan::sampling(object = blouch:::stanmodels$blouchOU_direct,data = dat,chains = 1,cores=1,iter =400) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.direct,pars = c(\"hl\",\"vy\",\"alpha\",\"beta\")) #> Inference for Stan model: blouchOU_direct. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>         mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl      0.24       0 0.06 0.15 0.20 0.23 0.27  0.35   312    1 #> vy      0.02       0 0.00 0.01 0.01 0.02 0.02  0.03   303    1 #> alpha   1.99       0 0.04 1.91 1.97 1.99 2.02  2.08   460    1 #> beta[1] 0.26       0 0.01 0.24 0.25 0.26 0.26  0.27   460    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:00:42 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.direct,depth=3,pars = c(\"hl\",\"vy\",\"alpha\",\"beta\"))) #For use with rethinking package post<-rstan::extract(fit.direct) #Extract posterior distribution rm(list=ls())"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"adaptive-model","dir":"Articles","previous_headings":"","what":"Adaptive Model","title":"Basic Models-Examples","text":"Blouch also implements model adaptive evolution introduced Hansen et al. (2008). response variable evolves according Ornstein-Uhlenbeck process towards optimal state modeled function predictor variable. steps similar direct effect model go fully. , create phylogeny randomly sampling 10K Trees phylogeny.","code":"######################################################################################################## #Create phylogeny ######################################################################################################## N<-50 #Number of species set.seed(10) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   tip.label<-phy$tip.label"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"set-trueknown-parameter-values-1","dir":"Articles","previous_headings":"","what":"Set true/known parameter values","title":"Basic Models-Examples","text":"First simulate X Y data using generative model adaptive model. set true/known parameter values. half-life (hl), stationary variance (vy), simulation translate \\(\\alpha\\) () \\(\\sigma^2_y\\) (sigma2_y). set ancestral value root (vX0) 0, instantaneous variance BM process (Sxx) 10. use fastBM function phytools (Revell, 2011) simulate X variable following BM process. simulation setting instantaneous variance BM process (sigma2_x) 1, needs matrix format. Normally Blouch estimates part blouch.adapt.prep helper function.","code":"######################################################################################################## #Adaptive Model ######################################################################################################## #Setup parameters Z_adaptive<-1 #Number of traits hl<-0.1 a<-log(2)/hl vy<-0.1 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl)); vX0<-0 #value for ancestral state at the root node.  vY0<-0#value for ancestral state at the root node. sigma2_x<-matrix(1,1,1) #Variance of BM Process X<-phytools::fastBM(phy,a=vX0,sig2=sigma2_x[1,1],internal=FALSE) #Simulate X BM variable on tree, with scaling 10 phytools::phenogram(phy,X,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels..."},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"calculate-v-and-simulate-y-data","dir":"Articles","previous_headings":"","what":"Calculate V and simulate Y data","title":"Basic Models-Examples","text":"set intercept (alpha) 2 slope 0.25. use Blouch helper functions calc_adaptive_dmX calculate design matrix calc_adaptive_V calculate variance/covariance matrix. simulate mu using V simulate Y. Finally make quick plot results.","code":"alpha<-2 #Intecept beta<-0.25 #Slope  dmX<-calc_adaptive_dmX(phy,a,X) #Calculate the design matrix V<-calc_adaptive_V(phy,a, sigma2_y, beta,  sigma2_x, Z_adaptive) #Calculate adaptive variance/covariance matrix  mu<-alpha+dmX%*%beta #Simulate mu for Y Y<-MASS::mvrnorm(n=1,mu,V) #Simulate adaptive model Y trait  df<-data.frame(Y=Y,X=X) names(df)<-c(\"Y\",\"X\")  ggplot2::ggplot(data=df,ggplot2::aes(x=X,y=Y))+   ggplot2::geom_point() summary(lm(Y~X,df)) #>  #> Call: #> lm(formula = Y ~ X, data = df) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.77740 -0.27795 -0.00472  0.26880  0.79108  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  1.91334    0.05316  35.993  < 2e-16 *** #> X            0.17356    0.04791   3.623 0.000702 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.334 on 48 degrees of freedom #> Multiple R-squared:  0.2147, Adjusted R-squared:  0.1983  #> F-statistic: 13.12 on 1 and 48 DF,  p-value: 0.0007023"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"simulating-measurement-error-1","dir":"Articles","previous_headings":"","what":"Simulating measurement error","title":"Basic Models-Examples","text":"Next simulate measurement error - use standard deviation measurement error 0.01, provide Blouch vector (X_error Y_error), use rnorm function add error X Y variables. words, telling Blouch estimated error X Y 0.01, providing X Y variables offset random amount error standard deviation.","code":"######################################################################################################## #Simulate errors X_error<-rep(0.01,N) Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-X+rnorm(N,0,0.01)"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"data-setup-for-blouch-1","dir":"Articles","previous_headings":"","what":"Data setup for Blouch","title":"Basic Models-Examples","text":"Next use treeplyr package (Uyeda Harmon, 2014) make.treedata function combine data tree based taxa names. See https://github.com/uyedaj/treeplyr package. use helper function blouch.adapt.prep() setup dat file Stan. name column trdata$dat contains response variable “Y_with_error”, associated error column name “Y_error,” direct effect predictor column named “X_with_error”, associated errors “X_error”. Finally, give helper function number predictor traits, 1 .","code":"############################################################################################################ #Make trdata file trait.data<-data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error)) trdata<-treeplyr::make.treedata(phy,trait.data)  ############################################################################################################ #Test Blouch prep code - adaptive model dat<-blouch.adapt.prep(trdata,\"Y_with_error\",\"Y_error\",\"X_with_error\",\"X_error\",Z_adaptive=Z_adaptive)"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"exploring-priors-1","dir":"Articles","previous_headings":"","what":"Exploring Priors","title":"Basic Models-Examples","text":"point one want explore priors appropriate - see Simulation Example article one way go .","code":""},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"running-models-1","dir":"Articles","previous_headings":"","what":"Running models","title":"Basic Models-Examples","text":"priors used simulation. See Grabowski (revision) setting priors. change values requires open Stan function, case blouchOU_direct, manually edit . Unfortunately way around present, trust - worth . example, four important priors model - values explored Grabowski (revision). Remember, always prior predictive simulations first - words, look distributions values see actually biologically possible - see exploring priors step . lines Stan code setting priors. change values make appropriate analyses, just need change numbers . Stan programs Blouch/inst/stan folder named according model run. See Table S1 Grabowski (revision) models. Remember, priors based know biological processes underlying research question prior predictive simulations (see McElreath 2020). Now let’s run adaptive model blouchOU_adapt results include optimal regression, beta, evolutionary regression, beta_e, following Hansen et al. (2008) posteriors explored, compared priors, etc. See Simulation Example one example .","code":"######################################################################################################## #Priors #hl ~ lognormal(log(0.25),0.25); #vy ~ exponential(5); #alpha ~ normal(2.0,0,2); #beta ~ normal(0.25,0.1); #Stan Code   target += lognormal_lpdf(hl|log(0.25),0.25);   target += exponential_lpdf(vy|5);   target += normal_lpdf(alpha|2,0.2);   target += normal_lpdf(beta|0.25,0.1); fit.adapt<- rstan::sampling(object = blouch:::stanmodels$blouchOU_adapt,data = dat,chains = 1,cores=1,iter =400) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.adapt,pars = c(\"hl\",\"vy\",\"alpha\",\"beta\",\"beta_e\")) #> Inference for Stan model: blouchOU_adapt. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.22    0.00 0.05 0.14 0.18 0.21 0.24  0.33   100 1.01 #> vy        0.17    0.00 0.04 0.11 0.15 0.17 0.20  0.27   169 1.00 #> alpha     1.97    0.01 0.10 1.80 1.90 1.98 2.04  2.16    56 1.01 #> beta[1]   0.18    0.02 0.08 0.05 0.12 0.16 0.23  0.35    16 1.00 #> beta_e[1] 0.12    0.01 0.06 0.03 0.08 0.11 0.16  0.27    17 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:00:55 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.adapt,depth=2,pars = c(\"hl\",\"vy\",\"alpha\",\"beta\"))) post<-rstan::extract(fit.adapt) rm(list=ls())"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"direct-effect-and-adaptive-models","dir":"Articles","previous_headings":"","what":"Direct effect and adaptive models","title":"Basic Models-Examples","text":"Finally, can look models combination direct effect adaptive traits. Setup similar except two predictors. First create phylogeny randomly sampling 10K Trees phylogeny","code":"######################################################################################################## #Create phylogeny ######################################################################################################## N<-50 #Number of species set.seed(10) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   tip.label<-phy$tip.label"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"set-trueknown-parameter-values-2","dir":"Articles","previous_headings":"","what":"Set true/known parameter values","title":"Basic Models-Examples","text":"simulate X Y data using generative model direct effect adaptive model. 1 direct effect trait, Xd, one adaptive trait, Xa. object Z always refers number traits, case Z_direct = number direct effect traits, Z_adaptive = number adaptive traits. simulation setting instantaneous variance BM process (sigma2_x) 1, needs matrix format. Normally Blouch estimates part blouch.direct.adapt.prep helper function.   one intercept term , two slopes - order Blouch always direct effect predictors first, followed adaptive predictors. Thus direct effect slope 0.35 adaptive slope 0.25. Except Blouch helper function calc_mixed_dmX, used mixed design matrices, functions adaptive model . One complication beta term calc_adaptive_V function call - sending function adaptive slope line beta[(Z_direct+1):(Z_adaptive+Z_direct)] one way specifying term. Finally make quick plot results.   Next simulate measurement error - use standard deviation measurement error 0.01, provide Blouch vector (X_error Y_error), use rnorm function add error X Y variables. words, telling Blouch estimated error X Y 0.01, providing X Y variables offset random amount error standard deviation. complication simulating error one trait - adaptive direct effect trait - extra lines code .","code":"############################################################################################################ #Direct effect + Adaptive Model ############################################################################################################ hl<-0.1 #0.1, 0.25, 0.75 - testing options a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl));  vX0<-0 vY0 <- 0  Z_direct<-1 Z_adaptive<-1 Z<-Z_direct+Z_adaptive sigma2_x<-matrix(1,1,1) #Variance of BM Process Xd<-rnorm(N,0,1) names(Xd)<-phy$tip.label phytools::phenogram(phy,Xd,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... Xa<-phytools::fastBM(phy,a=vX0,sig2=sigma2_x[1,1],internal=FALSE) #Simulate X BM variable on tree, with scaling 10 phytools::phenogram(phy,Xa,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... #sigma2_x<-ratematrix(phy,Xa) #Calculate evolutionary v/cv matrix Xs<-cbind(Xd,Xa) alpha<-2 #Intecept beta<-c(0.35,0.25) #Slopes dmX<-calc_mixed_dmX(phy,a,Xs,Z_direct,Z_adaptive) mu<-alpha+dmX%*%beta #Simulate mu for Y  V<-calc_adaptive_V(phy,a, sigma2_y, beta[(Z_direct+1):(Z_adaptive+Z_direct)],  sigma2_x) Y<-MASS::mvrnorm(n=1,mu,V)  df<-data.frame(Y=Y,X=Xs)  summary(lm(Y~Xs,df)) #>  #> Call: #> lm(formula = Y ~ Xs, data = df) #>  #> Residuals: #>       Min        1Q    Median        3Q       Max  #> -0.226807 -0.077535 -0.000499  0.055419  0.189201  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  1.98088    0.01400  141.51   <2e-16 *** #> XsXd         0.34453    0.01026   33.58   <2e-16 *** #> XsXa         0.23978    0.01598   15.00   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.09835 on 47 degrees of freedom #> Multiple R-squared:  0.9686, Adjusted R-squared:  0.9672  #> F-statistic:   724 on 2 and 47 DF,  p-value: < 2.2e-16  ggplot2::ggplot(data=df,ggplot2::aes(x=X.Xd,y=Y))+   ggplot2::geom_point() summary(lm(Y~X.Xd,df)) #>  #> Call: #> lm(formula = Y ~ X.Xd, data = df) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.56393 -0.12628  0.00925  0.17768  0.45689  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  1.99274    0.03327   59.90   <2e-16 *** #> X.Xd         0.35755    0.02434   14.69   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.2341 on 48 degrees of freedom #> Multiple R-squared:  0.8181, Adjusted R-squared:  0.8143  #> F-statistic: 215.8 on 1 and 48 DF,  p-value: < 2.2e-16  ggplot2::ggplot(data=df,ggplot2::aes(x=X.Xa,y=Y))+   ggplot2::geom_point() summary(lm(Y~X.Xa,df)) #>  #> Call: #> lm(formula = Y ~ X.Xa, data = df) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.96493 -0.30501 -0.07747  0.24245  1.26987  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  2.02455    0.06894   29.36  < 2e-16 *** #> X.Xa         0.28516    0.07879    3.62 0.000709 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.4865 on 48 degrees of freedom #> Multiple R-squared:  0.2144, Adjusted R-squared:  0.198  #> F-statistic:  13.1 on 1 and 48 DF,  p-value: 0.0007088 ######################################################################################################## #Simulate errors - for use with blouchOU_reg_direct_adaptive_ME Z_X_error<-2 #Number of X traits with error X_error<-matrix(0.01,nrow=N,ncol=Z_X_error) X_error<-data.frame(X_error) names(X_error)<-c(\"Xd_error\",\"Xa_error\") Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-apply(Xs,2,function(X){X+rnorm(N,0,0.01)})"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"data-setup-for-blouch-2","dir":"Articles","previous_headings":"","what":"Data setup for Blouch","title":"Basic Models-Examples","text":"Next use treeplyr package (Uyeda Harmon, 2014) make.treedata function combine data tree based taxa names. See https://github.com/uyedaj/treeplyr package. use helper function blouch.direct.adapt.prep setup dat file Stan. names direct effect adaptive columns Xd, Xa associated errors, Z_direct Z_adaptive number direct effect adaptive traits, respectively. Priors set , blouchOU_direct_adapt model run . results include, order, direct effect regression, optimal regression, finally beta_e, evolutionary regression, following Hansen et al. (2008) posteriors explored, compared priors, etc. See Simulation Example one example .","code":"############################################################################################################ #Make trdata file #trdata<-make.treedata(phy,trait.data) trait.data<-data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error)) trdata<-treeplyr::make.treedata(phy,trait.data) ############################################################################################################ #Test Blouch prep code - Direct effect + Adaptive Model dat<-blouch.direct.adapt.prep(trdata,\"Y_with_error\",\"Y_error\",c(\"Xd\",\"Xa\"),c(\"Xd_error\",\"Xa_error\"),Z_direct=1,Z_adaptive=1) fit.direct.adapt<- rstan::sampling(object = blouch:::stanmodels$blouchOU_direct_adapt,data = dat,chains = 1, cores=1,iter =400) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.direct.adapt,pars = c(\"hl\",\"vy\",\"alpha\",\"beta\")) #> Inference for Stan model: blouchOU_direct_adapt. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>         mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl      0.22       0 0.05 0.14 0.18 0.22 0.25  0.34   279 1.00 #> vy      0.01       0 0.00 0.00 0.00 0.01 0.01  0.02   141 1.00 #> alpha   1.99       0 0.04 1.92 1.96 1.99 2.01  2.06   179 1.00 #> beta[1] 0.34       0 0.01 0.33 0.34 0.34 0.35  0.36   287 1.00 #> beta[2] 0.34       0 0.04 0.27 0.31 0.34 0.36  0.42    84 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:01:12 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.direct.adapt,depth=2,pars = c(\"hl\",\"vy\",\"alpha\",\"beta\"))) post<-rstan::extract(fit.direct.adapt)"},{"path":"https://mark-grabowski.github.io/blouch/articles/Basic_Models-Examples.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Basic Models-Examples","text":"Grabowski M., Voje K.L., Hansen T.F. 2016. Evolutionary modeling correcting observation error support 3/5 brain-body allometry primates. J. Hum. Evol. 94:106–116. Grabowski M., Kopperud B.T., Tsuboi M., Hansen T.F. 2023. Diet Sociality Affect Primate Brain-Size Evolution. Systematic Biology.:syac075. Hansen T.F., Bartoszek K. 2012. Interpreting evolutionary regression: interplay observational biological errors phylogenetic comparative studies. Syst Biol. 61:413–425. McElreath R. 2020. Statistical rethinking: Bayesian course examples R Stan. CRC press. Revell L.J. 2011. phytools: R package phylogenetic comparative biology (things). Methods Ecol. Evol. 3:217–223. Uyeda J.C., Harmon L.J. 2014. Novel Bayesian Method Inferring Interpreting Dynamics Adaptive Landscapes Phylogenetic Comparative Data. Systematic Biology. 63:902–918.","code":""},{"path":"https://mark-grabowski.github.io/blouch/articles/Multi-optima_Models-Examples.html","id":"multi-optima-model","dir":"Articles","previous_headings":"","what":"Multi-optima Model","title":"Multi-optima Models-Examples","text":"Next run series models include categorical variables - regimes painted phylogeny following Hansen (1997) Hansen et al. (2008). article abbreviated versions Simulation Example article - steps analysis repeated . Note Stan runs also iterations use 1 chain 1 core. First set regime painting    Format tree Now simulate Y data based generative model  use helper function blouch.reg.prep() setup dat file Stan. “regimes” name regime column trdata$dat. run basic Multi-optima Model, look results, rstan::extract posterior Next code Multilevel Multi-optima Model Finally run non-centered version model, can used posterior hard explore centered version model produces divergences.","code":"############################################################################################################ #Regimes model ############################################################################################################ ######################################################################################################## #Create phylogeny ######################################################################################################## N<-50 #Number of species set.seed(10) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   tip.label<-phy$tip.label   #Set regimes - manually - 2 regimes #Locate nodes plot(phy,no.margin=TRUE,edge.width=2,cex=0.7) ape::nodelabels(frame=\"none\",adj=c(1.1,-0.4)) ape::tiplabels() #Paint Regimes on Tree #source(\"/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/blouch/Simulation Code/Functions/set.converge.regimes.R\") #Macbook Pro  shifts<-c(84) #Location of nodes with regime shifts trdata<-data.frame(phy$tip.label) trdata<-treeplyr::make.treedata(phy,trdata) trdata<-set.converge.regimes(trdata,shifts) #> [1] 1 #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2 #> [1] \"#E64B35FF\" \"#4DBBD5FF\" #Check if manual setting code worked shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label) edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]]) print(edge.regimes) #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2  reg.colors <- ggsci::pal_aaas(\"default\", alpha = 0.7)(2) print(reg.colors) #> [1] \"#3B4992B2\" \"#EE0000B2\" plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1, cex = 0.2) ############################################################################################################ #Simulate data n<-length(trdata$phy$tip.label) regimes_internal <-trdata$phy$node.label regimes_tip <- trdata$dat$regimes regimes <- concat.factor(regimes_tip, regimes_internal) anc_maps<-\"regimes\" lineages <- lapply(1:n, function(e) lineage.constructor(trdata$phy, e, anc_maps, regimes)) #Trace lineage from tips (n) to root and determine regimes of each node or branch ############################################################################################################ #Set true values for parameters hl<-0.1 #0.1, 0.25, 0.75 - testing options a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl)); optima<-c(0.5,0.25) #Optima for two regimes  dmX<-weight.matrix(trdata$phy, a, lineages) #Slouch approach mu<-dmX%*%optima #Simulate mu for Y V<-calc_direct_V(phy, sigma2_y, a) Y<-MASS::mvrnorm(n=1,mu,V)  ######################################################################################################## #Simulate errors Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01)  phytools::phenogram(phy,Y_with_error,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... ############################################################################################################ #Make trdata file trait.data<-data.frame(cbind(Y_with_error,Y_error)) trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error)))  ############################################################################################################ dat<-blouch.reg.prep(trdata,\"Y_with_error\",\"Y_error\",\"regimes\") fit.reg<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg,data = dat,chains = 1,iter =400,cores=1) #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg,pars = c(\"hl\",\"vy\",\"optima\")) #> Inference for Stan model: blouchOU_reg. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.20    0.01 0.06 0.12 0.16 0.19 0.22  0.35    36 1.01 #> vy        0.03    0.00 0.01 0.02 0.02 0.03 0.03  0.05    35 1.01 #> optima[1] 0.46    0.01 0.05 0.36 0.43 0.46 0.49  0.54    69 1.02 #> optima[2] 0.26    0.01 0.08 0.10 0.21 0.26 0.31  0.40   131 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:01:40 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ##plot(rethinking::precis(fit.reg,depth=2,pars = c(\"hl\",\"vy\",\"optima\")))  post<-rstan::extract(fit.reg) #rstan::extract posterior fit.mlm.vi.regimes<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_mlm_vi,data = dat,chains = 2,iter= 2000,cores=2) #> Warning: There were 195 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.mlm.vi.regimes,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"sigma\")) #> Inference for Stan model: blouchOU_reg_mlm_vi. #> 2 chains, each with iter=2000; warmup=1000; thin=1;  #> post-warmup draws per chain=1000, total post-warmup draws=2000. #>  #>            mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl         0.20    0.00 0.05  0.12 0.16 0.19 0.22  0.30  1168    1 #> vy         0.03    0.00 0.01  0.02 0.02 0.03 0.03  0.05   853    1 #> optima[1]  0.45    0.00 0.05  0.35 0.42 0.45 0.49  0.55  1315    1 #> optima[2]  0.30    0.01 0.09  0.12 0.24 0.30 0.35  0.47   215    1 #> optima_bar 0.36    0.01 0.16 -0.02 0.28 0.37 0.45  0.66   974    1 #> sigma      0.19    0.01 0.15  0.02 0.08 0.15 0.24  0.57   589    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:02:08 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ###plot(rethinking::precis(fit.mlm.vi.regimes,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"sigma\")))  post<-rstan::extract(fit.mlm.vi.regimes) fit.mlm.vi.regimes.nc<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_mlm_vi_nc,data = dat,chains = 1,iter =400,cores=1) #,control=list(adapt_delta=0.95)) #>  #> SAMPLING FOR MODEL 'blouchOU_reg_mlm_vi_nc' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.00105 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 10.5 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 400 [  0%]  (Warmup) #> Chain 1: Iteration:  40 / 400 [ 10%]  (Warmup) #> Chain 1: Iteration:  80 / 400 [ 20%]  (Warmup) #> Chain 1: Iteration: 120 / 400 [ 30%]  (Warmup) #> Chain 1: Iteration: 160 / 400 [ 40%]  (Warmup) #> Chain 1: Iteration: 200 / 400 [ 50%]  (Warmup) #> Chain 1: Iteration: 201 / 400 [ 50%]  (Sampling) #> Chain 1: Iteration: 240 / 400 [ 60%]  (Sampling) #> Chain 1: Iteration: 280 / 400 [ 70%]  (Sampling) #> Chain 1: Iteration: 320 / 400 [ 80%]  (Sampling) #> Chain 1: Iteration: 360 / 400 [ 90%]  (Sampling) #> Chain 1: Iteration: 400 / 400 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 3.524 seconds (Warm-up) #> Chain 1:                1.771 seconds (Sampling) #> Chain 1:                5.295 seconds (Total) #> Chain 1: #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.mlm.vi.regimes.nc,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"sigma\")) #> Inference for Stan model: blouchOU_reg_mlm_vi_nc. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>            mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl         0.20    0.00 0.05 0.13 0.16 0.19 0.23  0.31   133 1.01 #> vy         0.03    0.00 0.01 0.02 0.03 0.03 0.04  0.05    99 1.02 #> optima[1]  0.45    0.00 0.05 0.35 0.42 0.45 0.48  0.56   172 1.04 #> optima[2]  0.32    0.01 0.09 0.16 0.26 0.33 0.38  0.47    79 1.04 #> optima_bar 0.40    0.01 0.10 0.24 0.33 0.40 0.45  0.65    91 1.01 #> sigma      0.22    0.02 0.17 0.01 0.08 0.18 0.33  0.60    50 1.05 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:02:49 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ###plot(rethinking::precis(fit.mlm.vi.regimes.nc,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"sigma\"))) post<-rstan::extract(fit.mlm.vi.regimes.nc) rm(list=ls())"},{"path":"https://mark-grabowski.github.io/blouch/articles/Multi-optima_Models-Examples.html","id":"multi-optima-direct-effect-model","dir":"Articles","previous_headings":"","what":"Multi-optima Direct Effect Model","title":"Multi-optima Models-Examples","text":"now include regimes painted tree direct effect predictor    Now simulate X Y data   use helper function blouch.reg.direct.prep() setup dat file Stan. “Z_direct” number predictors, “regimes” name regime column trdata$dat. Now run basic Multi-optima Direct Effect Model, look results, rstan::extract posterior Multilevel version model finally non-centered version Multilevel model posteriors explored, compared priors, etc. See Simulation Example one example .","code":"############################################################################################################ #Regimes + Direct Effect Model ############################################################################################################ #Create phylogeny ######################################################################################################## N<-50 #Number of species set.seed(10) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   tip.label<-phy$tip.label  #Set regimes - manually - 2 regimes #Locate nodes plot(phy,no.margin=TRUE,edge.width=2,cex=0.7) ape::nodelabels(frame=\"none\",adj=c(1.1,-0.4)) ape::tiplabels() #Paint Regimes on Tree #source(\"/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/blouch/Simulation Code/Functions/set.converge.regimes.R\") #Macbook Pro shifts<-c(84) #Location of nodes with regime shifts trdata<-data.frame(phy$tip.label) trdata<-treeplyr::make.treedata(phy,trdata) trdata<-set.converge.regimes(trdata,shifts) #> [1] 1 #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2 #> [1] \"#E64B35FF\" \"#4DBBD5FF\" #Check if manual setting code worked shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label) edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]]) print(edge.regimes) #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2  reg.colors <- ggsci::pal_aaas(\"default\", alpha = 0.7)(2) print(reg.colors) #> [1] \"#3B4992B2\" \"#EE0000B2\" plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1, cex = 0.2) #Phylogeny info n<-length(trdata$phy$tip.label) mrca1 <- ape::mrca(trdata$phy) times <- ape::node.depth.edgelength(trdata$phy)  regimes_internal <-trdata$phy$node.label regimes_tip <- trdata$dat$regimes regimes <- concat.factor(regimes_tip, regimes_internal) anc_maps<-\"regimes\" lineages <- lapply(1:n, function(e) lineage.constructor(trdata$phy, e, anc_maps, regimes)) #Trace lineage from tips (n) to root and determine regimes of each node or branch ######################### hl<-0.1 #0.1, 0.25, 0.75 - testing options a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl));  vX0<-0 vY0 <- 0 Sxx<-10 #Look at effects  Z_direct<-1  V<-calc_direct_V(phy,sigma2_y,a) X<-phytools::fastBM(phy,a=vX0,sig2=Sxx,internal=FALSE) #Simulate X BM variable on tree, with scaling 10 #X<-rnorm(N,0,1) names(X)<-phy$tip.label  phytools::phenogram(phy,X,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... dmX<-weight.matrix(trdata$phy, a, lineages) #Slouch approach dmX<-cbind(dmX,X)  beta<-c(2,1,0.25) #Two Optima/One Slope mu<-dmX%*%beta #Simulate mu for Y  V<-calc_direct_V(phy,sigma2_y,a) Y<-MASS::mvrnorm(n=1,mu,V)  #Plot data df<-data.frame(Y=Y,X=X)  ggplot2::ggplot(data=df,ggplot2::aes(x=X,y=Y))+   ggplot2::geom_point() summary(lm(Y~X,df)) #>  #> Call: #> lm(formula = Y ~ X, data = df) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.01336  0.05757  0.18130  0.26934  0.44207  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  1.79846    0.07104   25.32   <2e-16 *** #> X            0.25197    0.02025   12.45   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.4464 on 48 degrees of freedom #> Multiple R-squared:  0.7634, Adjusted R-squared:  0.7585  #> F-statistic: 154.9 on 1 and 48 DF,  p-value: < 2.2e-16  #################################################################################################################Simulate errors Z_X_error<-1 #Number of X traits with error X_error<-rep(0.01,N) Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-X+rnorm(N,0,0.01)  ############################################################################################################ #Make trdata file trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error))) ############################################################################################################ #Test Blouch prep code - Regimes + Direct Efffect model dat<-blouch.reg.direct.prep(trdata,\"Y_with_error\",\"Y_error\",\"X_with_error\",\"X_error\",Z_direct=1,\"regimes\") fit.reg.direct<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct,data = dat,chains = 1,iter =400,cores=1) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.46    0.05 0.29  0.11 0.24 0.37 0.60  1.07    35 1.01 #> vy        0.03    0.00 0.02  0.01 0.02 0.02 0.04  0.06    41 1.00 #> optima[1] 1.98    0.00 0.07  1.83 1.94 1.99 2.03  2.10   185 1.00 #> optima[2] 0.50    0.08 0.44 -0.48 0.23 0.66 0.86  1.00    31 1.01 #> beta[1]   0.26    0.00 0.01  0.24 0.25 0.26 0.27  0.28   401 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:03:01 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ##plot(rethinking::precis(fit.reg.direct,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.direct) #rstan::extract posterior distribution fit.mli.regi.direct<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_mlm_vi,data = dat,chains = 1,iter =400,cores=1) #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.mli.regi.direct,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"beta\",\"sigma\")) #> Inference for Stan model: blouchOU_reg_direct_mlm_vi. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>             mean se_mean   sd  2.5%   25%   50%  75% 97.5% n_eff Rhat #> hl          0.30    0.03 0.26  0.09  0.15  0.23 0.36  0.79    61    1 #> vy          0.02    0.00 0.02  0.01  0.01  0.02 0.02  0.04    64    1 #> optima[1]   2.01    0.00 0.05  1.89  1.98  2.01 2.04  2.09   240    1 #> optima[2]   0.74    0.05 0.44 -0.18  0.72  0.87 0.95  1.04    65    1 #> optima_bar -0.45    0.12 0.73 -1.74 -0.98 -0.46 0.09  0.88    36    1 #> beta[1]     0.26    0.00 0.01  0.24  0.25  0.26 0.26  0.27   232    1 #> sigma       1.70    0.16 0.57  0.85  1.26  1.59 2.02  2.85    13    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:03:21 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ##plot(rethinking::precis(fit.mli.regi.direct,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"sigma\"))) post<-rstan::extract(fit.mli.regi.direct) #rstan::extract posterior distribution fit.mli.regi.direct<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_mlm_vi_nc,data = dat,chains = 1,iter =400,cores=1) #> Warning: There were 9 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.mli.regi.direct,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"beta\",\"sigma\")) #> Inference for Stan model: blouchOU_reg_direct_mlm_vi_nc. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>             mean se_mean   sd  2.5%   25%   50%  75% 97.5% n_eff Rhat #> hl          0.48    0.05 0.21  0.22  0.31  0.42 0.61  1.02    18 1.10 #> vy          0.03    0.00 0.01  0.02  0.02  0.03 0.04  0.05    18 1.09 #> optima[1]   1.99    0.01 0.08  1.83  1.94  2.00 2.04  2.11   229 1.00 #> optima[2]   0.50    0.08 0.36 -0.38  0.36  0.59 0.75  0.95    21 1.09 #> optima_bar -0.24    0.13 0.61 -1.34 -0.64 -0.22 0.10  1.00    21 1.00 #> beta[1]     0.26    0.00 0.01  0.24  0.25  0.26 0.26  0.28   460 1.00 #> sigma       1.40    0.11 0.42  0.77  1.11  1.30 1.64  2.32    15 1.09 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:03:35 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ###plot(rethinking::precis(fit.mli.regi.direct,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"sigma\"))) post<-rstan::extract(fit.mli.regi.direct) #rstan::extract posterior distribution rm(list=ls())"},{"path":"https://mark-grabowski.github.io/blouch/articles/Multi-optima_Models-Examples.html","id":"multi-optima-adaptive-model","dir":"Articles","previous_headings":"","what":"Multi-optima Adaptive Model","title":"Multi-optima Models-Examples","text":"now include regimes painted tree adaptive predictor    Simulate X Y data using generative model   use helper function blouch.reg.adapt.prep() setup dat file Stan. “Z_adapt” number predictors, “regimes” name regime column trdata$dat. Now run basic Multi-optima Adaptive Model, look results, rstan::extract posterior Multilevel version model non-centered version posteriors explored, compared priors, etc. See Simulation Example one example .","code":"############################################################################################################ #Regimes + Adaptive Model ############################################################################################################ #Create phylogeny ######################################################################################################## N<-50 #Number of species set.seed(10) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   tip.label<-phy$tip.label  #Set regimes - manually - 2 regimes #Locate nodes plot(phy,no.margin=TRUE,edge.width=2,cex=0.7) ape::nodelabels(frame=\"none\",adj=c(1.1,-0.4)) ape::tiplabels() #Paint Regimes on Tree shifts<-c(84) #Location of nodes with regime shifts trdata<-data.frame(phy$tip.label) trdata<-treeplyr::make.treedata(phy,trdata) trdata<-set.converge.regimes(trdata,shifts) #> [1] 1 #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2 #> [1] \"#E64B35FF\" \"#4DBBD5FF\" #Check if manual setting code worked shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label) edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]]) print(edge.regimes) #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2  reg.colors <- ggsci::pal_aaas(\"default\", alpha = 0.7)(2) print(reg.colors) #> [1] \"#3B4992B2\" \"#EE0000B2\" plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1, cex = 0.2) #Phylogeny info n<-length(trdata$phy$tip.label)  regimes_internal <-trdata$phy$node.label regimes_tip <- trdata$dat$regimes regimes <- concat.factor(regimes_tip, regimes_internal) anc_maps<-\"regimes\" lineages <- lapply(1:n, function(e) lineage.constructor(trdata$phy, e, anc_maps, regimes)) #Trace lineage from tips (n) to root and determine regimes of each node or branch ############################################################################################################ ######################### hl<-0.1 #0.1, 0.25, 0.75 - testing options a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl));  vX0<-0 vY0 <- 0  Z_adaptive<-1 sigma2_x<-matrix(1,1,1) #Variance of BM Process  X<-phytools::fastBM(phy,a=vX0,sig2=sigma2_x[1,1],internal=FALSE) #Simulate X BM variable on tree, with scaling 10 phytools::phenogram(phy,X,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... #sigma2_x<-ratematrix(phy,Xa) #Calculate evolutionary v/cv matrix  dmX<-weight.matrix(trdata$phy, a, lineages) #Slouch approach dmX<-cbind(dmX,calc_adaptive_dmX(phy,a,X))  beta<-c(2,1,0.25) #Two Optima/Two Slopes mu<-dmX%*%beta #Simulate mu for Y  V<-calc_adaptive_V(phy,a, sigma2_y, beta[3],  sigma2_x) Y<-MASS::mvrnorm(n=1,mu,V)  ################################################################################################################ #Plot data df<-data.frame(Y=Y,X=X)  ggplot2::ggplot(data=df,ggplot2::aes(x=X,y=Y))+   ggplot2::geom_point() summary(lm(Y~X,df)) #>  #> Call: #> lm(formula = Y ~ X, data = df) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.02038  0.01228  0.22055  0.29838  0.41456  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  1.75394    0.07481  23.445  < 2e-16 *** #> X            0.19673    0.06743   2.918  0.00535 **  #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.4701 on 48 degrees of freedom #> Multiple R-squared:  0.1506, Adjusted R-squared:  0.133  #> F-statistic: 8.513 on 1 and 48 DF,  p-value: 0.00535 ################################################################################################################ #Simulate errors Z_X_error<-1 #Number of X traits with error X_error<-rep(0.01,N) Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-X+rnorm(N,0,0.01)  ############################################################################################################ #Make trdata file trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error))) ############################################################################################################ dat<-blouch.reg.adapt.prep(trdata,\"Y_with_error\",\"Y_error\",\"X_with_error\",\"X_error\",Z_adaptive=1,\"regimes\") fit.reg.adapt<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt,data = dat,chains = 1,iter =400,cores=1) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.adapt,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_adapt. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.17    0.01 0.07 0.07 0.12 0.16 0.21  0.33    40 0.99 #> vy        0.01    0.00 0.00 0.01 0.01 0.01 0.02  0.03    97 1.00 #> optima[1] 2.01    0.01 0.04 1.93 1.98 2.01 2.04  2.10    66 1.02 #> optima[2] 0.92    0.01 0.07 0.76 0.88 0.93 0.96  1.07    58 1.01 #> beta[1]   0.25    0.01 0.04 0.18 0.22 0.25 0.27  0.34    60 1.01 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:03:50 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ##plot(rethinking::precis(fit.reg.adapt,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.adapt) #rstan::extract Posterior Distribution fit.reg.adapt<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_mlm_vi,data = dat,chains = 1,iter =400,cores=1) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.adapt,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_adapt_mlm_vi. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.23    0.02 0.11 0.08 0.16 0.21 0.28  0.47    42    1 #> vy        0.02    0.00 0.01 0.01 0.01 0.02 0.02  0.03    46    1 #> optima[1] 2.01    0.00 0.05 1.92 1.98 2.00 2.05  2.12   125    1 #> optima[2] 0.82    0.02 0.14 0.49 0.75 0.85 0.91  1.03    65    1 #> beta[1]   0.29    0.01 0.06 0.19 0.25 0.28 0.33  0.39    66    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:04:06 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ##plot(rethinking::precis(fit.reg.adapt,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.adapt) fit.reg.adapt<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_mlm_vi_nc,data = dat,chains = 1,iter =400,cores=1) #>  #> SAMPLING FOR MODEL 'blouchOU_reg_adapt_mlm_vi_nc' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.001158 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 11.58 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 400 [  0%]  (Warmup) #> Chain 1: Iteration:  40 / 400 [ 10%]  (Warmup) #> Chain 1: Iteration:  80 / 400 [ 20%]  (Warmup) #> Chain 1: Iteration: 120 / 400 [ 30%]  (Warmup) #> Chain 1: Iteration: 160 / 400 [ 40%]  (Warmup) #> Chain 1: Iteration: 200 / 400 [ 50%]  (Warmup) #> Chain 1: Iteration: 201 / 400 [ 50%]  (Sampling) #> Chain 1: Iteration: 240 / 400 [ 60%]  (Sampling) #> Chain 1: Iteration: 280 / 400 [ 70%]  (Sampling) #> Chain 1: Iteration: 320 / 400 [ 80%]  (Sampling) #> Chain 1: Iteration: 360 / 400 [ 90%]  (Sampling) #> Chain 1: Iteration: 400 / 400 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 12.77 seconds (Warm-up) #> Chain 1:                20.091 seconds (Sampling) #> Chain 1:                32.861 seconds (Total) #> Chain 1: #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.adapt,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_adapt_mlm_vi_nc. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.21    0.01 0.10 0.07 0.13 0.20 0.28  0.41    50 1.01 #> vy        0.02    0.00 0.01 0.01 0.01 0.01 0.02  0.03   182 1.00 #> optima[1] 2.01    0.00 0.05 1.91 1.98 2.01 2.04  2.12   178 1.00 #> optima[2] 0.84    0.01 0.12 0.52 0.79 0.86 0.92  0.99    69 1.00 #> beta[1]   0.28    0.01 0.06 0.19 0.23 0.27 0.31  0.40    60 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:04:47 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ##plot(rethinking::precis(fit.reg.adapt,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.adapt) rm(list=ls())"},{"path":"https://mark-grabowski.github.io/blouch/articles/Multi-optima_Models-Examples.html","id":"multi-optima-direct-effect-and-adaptive-model","dir":"Articles","previous_headings":"","what":"Multi-optima Direct Effect and Adaptive Model","title":"Multi-optima Models-Examples","text":"now include regimes painted tree direct effect adaptive predictor        use helper function blouch.reg.direct.adapt.prep() setup dat file Stan. names direct effect adaptive columns “Xd”, “Xa” associated errors, Z_direct Z_adaptive th number direct adaptive traits, respectively, “regimes” name regimes column data trdata$dat. First run basic Multi-optima Direct Effect Adaptive Model. Next run Multilevel version model Finally run non-centered version model posteriors explored, compared priors, etc. See Simulation Example one example .","code":"############################################################################################################ #Regimes + Adaptive + Direct Model ############################################################################################################ #Create phylogeny ######################################################################################################## N<-50 #Number of species set.seed(10) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   tip.label<-phy$tip.label  #Set regimes - manually - 2 regimes #Locate nodes plot(phy,no.margin=TRUE,edge.width=2,cex=0.7) ape::nodelabels(frame=\"none\",adj=c(1.1,-0.4)) ape::tiplabels() #Paint Regimes on Tree shifts<-c(84) #Location of nodes with regime shifts trdata<-data.frame(phy$tip.label) trdata<-treeplyr::make.treedata(phy,trdata) trdata<-set.converge.regimes(trdata,shifts) #> [1] 1 #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2 #> [1] \"#E64B35FF\" \"#4DBBD5FF\" #Check if manual setting code worked shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label) edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]]) print(edge.regimes) #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2  reg.colors <- ggsci::pal_aaas(\"default\", alpha = 0.7)(2) print(reg.colors) #> [1] \"#3B4992B2\" \"#EE0000B2\" plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1, cex = 0.2) #Phylogeny info n<-length(trdata$phy$tip.label)  regimes_internal <-trdata$phy$node.label regimes_tip <- trdata$dat$regimes regimes <- concat.factor(regimes_tip, regimes_internal) anc_maps<-\"regimes\" lineages <- lapply(1:n, function(e) lineage.constructor(trdata$phy, e, anc_maps, regimes)) #Trace lineage from tips (n) to root and determine regimes of each node or branch ############################################################################################################ hl<-0.1 #0.1, 0.25, 0.75 - testing options a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl));  vX0<-0 vY0 <- 0  Z_direct<-1 Z_adaptive<-1 Z<-Z_direct+Z_adaptive sigma2_x<-matrix(1,1,1) #Variance of BM Process  Xd<-rnorm(N,0,1) names(Xd)<-phy$tip.label phytools::phenogram(phy,Xd,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... Xa<-phytools::fastBM(phy,a=vX0,sig2=sigma2_x[1,1],internal=FALSE) #Simulate X BM variable on tree, with scaling 10 phytools::phenogram(phy,Xa,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... #sigma2_x<-ratematrix(phy,Xa) #Calculate evolutionary v/cv matrix Xs<-cbind(Xd,Xa)  dmX<-weight.matrix(trdata$phy, a, lineages) #Slouch approach dmX<-cbind(dmX,calc_mixed_dmX(phy,a,Xs,Z_direct,Z_adaptive))  beta<-c(2,1,0.35,0.25) #Two Optima/Two Slopes mu<-dmX%*%beta #Simulate mu for Y  V<-calc_adaptive_V(phy,a, sigma2_y,   beta[length(beta)],  sigma2_x) Y<-MASS::mvrnorm(n=1,mu,V)  ################################################################################################################ #Plot data df<-data.frame(Y=Y,Xd=Xs[,1],Xa=Xs[,2])  ggplot2::ggplot(data=df,ggplot2::aes(x=Xd,y=Y))+   ggplot2::geom_point() ggplot2::ggplot(data=df,ggplot2::aes(x=Xa,y=Y))+   ggplot2::geom_point() summary(lm(Y~Xs,df)) #>  #> Call: #> lm(formula = Y ~ Xs, data = df) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.84630 -0.12744  0.08797  0.24861  0.70528  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  1.78365    0.05491  32.483  < 2e-16 *** #> XsXd         0.22103    0.04025   5.492 1.57e-06 *** #> XsXa         0.14069    0.06270   2.244   0.0296 *   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.3858 on 47 degrees of freedom #> Multiple R-squared:  0.4441, Adjusted R-squared:  0.4204  #> F-statistic: 18.77 on 2 and 47 DF,  p-value: 1.018e-06  ######################################################################################################## #Simulate errors - for use with blouchOU_reg_direct_adaptive_ME Z_X_error<-2 #Number of X traits with error X_error<-matrix(0.01,nrow=N,ncol=Z_X_error) X_error<-data.frame(X_error) names(X_error)<-c(\"Xd_error\",\"Xa_error\") Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-apply(Xs,2,function(X){X+rnorm(N,0,0.01)})  ############################################################################################################ #Make trdata file trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error))) ############################################################################################################ #Test Blouch prep code - Regimes + Direct Effect + Adaptive Model dat<-blouch.reg.direct.adapt.prep(trdata,\"Y_with_error\",\"Y_error\",c(\"Xd\",\"Xa\"),c(\"Xd_error\",\"Xa_error\"),Z_direct=1,Z_adaptive=1,\"regimes\") fit.reg.direct.adapt<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_adapt,data = dat,chains = 1,iter =400,cores=1) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.adapt,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_adapt. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.21    0.00 0.05 0.13 0.17 0.21 0.24  0.33   247 1.00 #> vy        0.01    0.00 0.00 0.00 0.01 0.01 0.01  0.02   214 1.00 #> optima[1] 1.97    0.00 0.04 1.88 1.94 1.97 2.00  2.06   282 1.00 #> optima[2] 0.99    0.01 0.09 0.82 0.94 1.00 1.06  1.15   295 1.00 #> beta[1]   0.34    0.00 0.01 0.33 0.34 0.34 0.35  0.36   255 1.01 #> beta[2]   0.33    0.00 0.05 0.25 0.29 0.32 0.36  0.42   230 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:05:04 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ##plot(rethinking::precis(fit.adapt,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"beta\",\"sigma\"))) post<-rstan::extract(fit.reg.direct.adapt) #rstan::extract posterior fit.reg.direct.adapt<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_adapt_mlm_vi,data = dat,chains = 1,iter =400,cores=1) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.adapt,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_adapt_mlm_vi. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.22    0.01 0.06 0.13 0.18 0.21 0.25  0.35    35 1.03 #> vy        0.01    0.00 0.00 0.00 0.00 0.01 0.01  0.02    37 1.00 #> optima[1] 1.98    0.00 0.04 1.90 1.95 1.98 2.01  2.07   460 1.00 #> optima[2] 0.95    0.01 0.10 0.73 0.89 0.96 1.02  1.11    70 1.00 #> beta[1]   0.34    0.00 0.01 0.33 0.34 0.34 0.35  0.36   185 1.00 #> beta[2]   0.33    0.01 0.04 0.25 0.30 0.33 0.36  0.42    50 1.03 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:05:21 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ##plot(rethinking::precis(fit.adapt,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"beta\",\"sigma\"))) post<-rstan::extract(fit.reg.direct.adapt) fit.reg.direct.adapt<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_adapt_mlm_vi_nc,data = dat,chains = 1,iter =400,cores=1) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.adapt,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_adapt_mlm_vi_nc. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.21    0.00 0.05 0.13 0.17 0.21 0.24  0.34   142 1.00 #> vy        0.01    0.00 0.00 0.00 0.01 0.01 0.01  0.02   194 1.00 #> optima[1] 1.98    0.00 0.05 1.86 1.95 1.98 2.00  2.08   233 1.00 #> optima[2] 0.95    0.01 0.09 0.74 0.90 0.95 1.01  1.11   227 1.00 #> beta[1]   0.34    0.00 0.01 0.33 0.34 0.34 0.35  0.36   239 0.99 #> beta[2]   0.33    0.00 0.05 0.24 0.29 0.32 0.36  0.42   165 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:05:38 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ##plot(rethinking::precis(fit.adapt,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"optima_bar\",\"beta\",\"sigma\")))  post<-rstan::extract(fit.reg.direct.adapt)"},{"path":"https://mark-grabowski.github.io/blouch/articles/Multi-optima_Models-Examples.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Multi-optima Models-Examples","text":"Hansen T.F. 1997. Stabilizing Selection Comparative Analysis Adaptation. Evolution. 51:1341–1351. Hansen T.F., Pienaar J., Orzack S.H. 2008. comparative method studying adaptation randomly evolving environment. Evolution. 62:1965–1977.","code":""},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Simulation Example","text":"Blouch uses RStan implement Stan. following code enables compiler optimizations improve estimation speed model, taken : https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started Blouch package includes primate phylogeny 10KTrees Project (Arnold et al. 2010), used various simulations comes https://10ktrees.nunn-lab.org/. Version 3 primate phylogeny 301 tips. randomly reduce tip number 100 manageable tree using functions ape R package (Paradis et al. 2004) Lets plot tree nodes labeled - placing regime shifts next step. use nodes 164, 192, 104, results 4 regimes - shifts+root regime.","code":"rm(list=ls()) library(blouch) #For execution on a local, multicore CPU with excess RAM we recommend calling #options(mc.cores = parallel::detectCores()) #options(mc.cores = 2)  rstan::rstan_options(auto_write = TRUE)  dotR <- file.path(Sys.getenv(\"HOME\"), \".R\") if (!file.exists(dotR)) dir.create(dotR) M <- file.path(dotR, \"Makevars\") if (!file.exists(M)) file.create(M) arch <- ifelse(R.version$arch == \"aarch64\", \"arm64\", \"x86_64\") cat(paste(\"\\nCXX14FLAGS += -O3 -mtune=native -arch\", arch, \"-ftemplate-depth-256\"),     file = M, sep = \"\\n\", append = FALSE) ######################################################################################################## #Four regimes with one adaptive trait and multiple slopes per optima but single alpha parameter set.seed(10) #Set sequence of random numbers for replicability N<-100 #Number of species  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy) #Collapse or resolve multichotomies in phylogenetic trees.  l.tree<-max(ape::branching.times(phy)) ## Rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree #Set regimes - manually - 4 regimes #Locate nodes plot(phy,no.margin=TRUE,edge.width=2,cex=0.7) ape::nodelabels(frame=\"none\",adj=c(1.1,-0.4)) ape::tiplabels()"},{"path":[]},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"combine-data-and-tree-and-paint-regimes-on-tree-","dir":"Articles","previous_headings":"","what":"Combine data and tree and paint regimes on tree.","title":"Simulation Example","text":"Next use treeplyr package (Uyeda Harmon, 2014) make.treedata function combine data tree based taxa names. See https://github.com/uyedaj/treeplyr package. step basically make dummy trdata object containing tree blank “dat” dataset object. place regime shifts tree identified earlier using Blouch’s set.converge.regimes R function. function also produces plot tree colored regimes. addition, manually plot tree shifts colored make sure done everything correctly.","code":"trdata<-data.frame(phy$tip.label) trdata<-treeplyr::make.treedata(phy,trdata)  shifts<-c(164,192,104) #Location of nodes with regime shifts #100 species trdata<-set.converge.regimes(trdata,shifts) #> [1] 1 #> [1] 2 #> [1] 3 #>   [1] OU1 OU1 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 #>  [19] OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 #>  [37] OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 #>  [55] OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 #>  [73] OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU4 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #>  [91] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [109] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 #> [127] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [145] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [163] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [181] OU2 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 OU3 #> Levels: OU1 OU2 OU3 OU4 #> [1] \"#E64B35FF\" \"#4DBBD5FF\" \"#00A087FF\" \"#3C5488FF\" #Check if code worked shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label) edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]])  reg.colors<-ggsci::pal_npg(palette=c(\"nrc\"),alpha=1)(4)  print(reg.colors) #> [1] \"#E64B35FF\" \"#4DBBD5FF\" \"#00A087FF\" \"#3C5488FF\" plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1,show.tip.label=FALSE) reg_tips<-trdata$dat$regimes reg_tips<-as.numeric(as.factor(reg_tips))"},{"path":[]},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"get-info-on-phylogeny","dir":"Articles","previous_headings":"","what":"Get info on phylogeny","title":"Simulation Example","text":"Next build regimes object include internal node tip regimes, use Blouch’s lineage.constructor R function trace lineages tips root determine regime node - R function built Blouch uses internally given empirical dataset, use function part data simulation.","code":"regimes_internal <-trdata$phy$node.label #Get internal regimes at nodes regimes_tip <- trdata$dat$regimes #Get regimes at tips regimes <- concat.factor(regimes_tip, regimes_internal) #Combine these into a list anc_maps<-\"regimes\" #Type of regime placement - currently only at nodes lineages <- lapply(1:N, function(e) lineage.constructor(trdata$phy, e, anc_maps, regimes)) #Trace lineage from tips (n) to root and determine regimes of each node or branch"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"set-trueknown-parameter-values","dir":"Articles","previous_headings":"","what":"Set true/known parameter values","title":"Simulation Example","text":"Next set true/known parameter values. half-life (hl), stationary variance (vy), simulation translate \\(\\alpha\\) () \\(\\sigma^2_y\\) (sigma2_y). set ancestral value root (vX0) 0, instantaneous variance BM process (Sxx) 10.","code":"######################### hl<-0.1 #Half life a<-log(2)/hl #hl expressed as alpha parameter vy<-0.01 #Stationary Variance sigma2_y<-vy*(2*(log(2)/hl)); #Vy expressed as random fluctuations of Y  vX0<-0 #Ancestral value at root sigma2_x<-matrix(1,1,1) #Variance of BM Process"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"simulate-x-data","dir":"Articles","previous_headings":"","what":"Simulate X data","title":"Simulation Example","text":"first simulate X data following Brownian-Motion Process using fastBM function phytools package (Revell 2011) parameter values set . plot values using phenogram function package make sure things look .","code":"X<-phytools::fastBM(phy,a=vX0,sig2=sigma2_x[1,1],internal=FALSE) #Simulate X BM variable on tree, with BM scaling 10 names(X)<-phy$tip.label phytools::phenogram(phy,X,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels..."},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"simulate-y-data","dir":"Articles","previous_headings":"","what":"Simulate Y data","title":"Simulation Example","text":"Next need simulate Y data - using four different optima (intercepts) four different slopes. use R function weight.matrix, Blouch includes produce optima_matrix object, weighting lineage based amount time spent regime (see Hansen 1997 derivation). followed using R function calc_adaptive_dmX Blouch, calculates design matrix observed predictor X variables species multiplied phylogenetic correction factor, following Hansen et al. (2008), values stored object pred_X. set values optima/intercepts (optima) slopes (beta), use linear model construct deterministic relationship set parameter values mu, vector mean values species analysis.","code":"optima_matrix<-weight.matrix(trdata$phy, a, lineages) #Calculate optima/intercepts matrix pred_X<-calc_adaptive_dmX(phy,a,X) #Calculate design matrix  optima<-c(1,2,3,4) #Simulated optima/intercepts beta<-c(0.75,0.5,0.35,0.25) #Simulated slopes  mu<-matrix(NA,N,1) for(i in 1:N){ #Generative function to produce average Y values for each combination of optima/intercepts and slopes following Blouch approach   mu[i] = optima_matrix[i,]%*%optima+beta[reg_tips[i]]%*%pred_X[i] }"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"calculating-v","dir":"Articles","previous_headings":"","what":"Calculating V","title":"Simulation Example","text":"construct variance/covariance matrix (V) based previously set parameter values Blouch R function calc_adaptive_V, following Hansen et al. (2008). Finally sill simulate Y values based mean vector mu covariance matrix V. Let’s make simple plot data, look simple ordinary least squares regression Y X. intercept slope values give us idea center priors .","code":"n_reg<-length(unique(regimes)) #Count number of regimes Z_adaptive<-1 #Number of adaptive X traits V<-calc_adaptive_V(phy,a, sigma2_y,  beta,  sigma2_x, Z_adaptive) #Calculate V based on set values Y<-MASS::mvrnorm(n=1,mu,V) #Simulate Y variables centered on mu with covariariance matrix V df<-data.frame(Y=Y,X=X)  ggplot2::ggplot(data=df,ggplot2::aes(x=X,y=Y))+   ggplot2::geom_point() summary(lm(Y~X,df)) #>  #> Call: #> lm(formula = Y ~ X, data = df) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -2.6769 -0.9146 -0.3293  1.1421  1.7937  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)   2.8002     0.1254  22.324   <2e-16 *** #> X             0.1551     0.1102   1.408    0.162     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 1.1 on 98 degrees of freedom #> Multiple R-squared:  0.01982,    Adjusted R-squared:  0.009823  #> F-statistic: 1.982 on 1 and 98 DF,  p-value: 0.1623"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"simulating-measurement-error","dir":"Articles","previous_headings":"","what":"Simulating measurement error","title":"Simulation Example","text":"Next simulate measurement error - use standard deviation measurement error 0.01, provide Blouch vector (X_error Y_error), use rnorm function add error X Y variables. words, telling Blouch estimated error X Y 0.01, providing X Y variables offset random amount error standard deviation.","code":"################################################################################################################## #Simulate errors Z_X_error<-1 #Number of X traits with error X_error<-matrix(0.01,nrow=N,ncol=Z_X_error) X_error<-data.frame(X_error) Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) #Add ME to Y X_with_error<-X+rnorm(N,0,0.01) #Add ME to X"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"data-setup-for-blouch","dir":"Articles","previous_headings":"","what":"Data setup for Blouch","title":"Simulation Example","text":"first line combines existing trdata file make.trdata regime info tips X Y values errors. use helper function blouch.reg.adapt.prep() setup dat object Stan. function helper functions included Blouch require trdata files, names columns contain Y (sometimes depending model) X data error data. “Z_adaptive” number predictors, “regimes” name column tip regime data located. See help info function articles github.com functionality.","code":"############################################################################################################ #Make trdata file trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error))) dat<-blouch.reg.adapt.prep(trdata,\"Y_with_error\",\"Y_error\",\"X_with_error\",\"X_error\",Z_adaptive=1,\"regimes\")"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"exploring-priors","dir":"Articles","previous_headings":"","what":"Exploring Priors","title":"Simulation Example","text":"Lets check simulated data reasonable values priors shown light grey lines. “.sims” values - priors based intercept slope OLS regression , standard deviations set visualizing priors versus data. See Grabowski (revision) setting priors.","code":"############################################################################################################ #Prior Exploration Plot lm.allometric<-summary(lm(dat$Y_obs~dat$X_obs)) #Calculate regression of Y on X lm.allometric$coefficients #>              Estimate Std. Error   t value     Pr(>|t|) #> (Intercept) 2.7980722  0.1253109 22.329035 3.202140e-40 #> dat$X_obs   0.1559651  0.1101167  1.416363 1.598402e-01  optima.sims<-rnorm(100,lm.allometric$coefficients[1],1) #Set priors on alpha/ beta.sims<-rnorm(n=100,lm.allometric$coefficients[2],0.25)  df<-data.frame(Y=dat$Y_obs,X=dat$X_obs[,1]) names(df)<-c(\"Y\",\"X\")  slope.plot<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=regimes_tip))+   ggplot2::geom_abline(intercept=optima.sims,slope=beta.sims,alpha=0.1)+   ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      #ggtitle(\"Prior vs. Posterior for Intercept and Slope\")+   ggplot2::ylab(\"Y\") + ggplot2::xlab(\"Adaptive Predictor\")+   ggsci::scale_color_npg()  slope.plot"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"running-models","dir":"Articles","previous_headings":"","what":"Running models","title":"Simulation Example","text":"First run multilevel multi-optima adaptive model varying effects. allow intercepts (optima) slopes vary regimes. multilevel model, information can shared across regimes, can produce accurate parameter estimates. priors used simulation. See Grabowski (revision) setting priors. change values requires open Stan function, case blouchOU_reg_adapt_mlm_ve, manually edit . Unfortunately way around present, trust - worth . example, four important priors models - values explored Grabowski (revision), show priors standard easy read format. Remember, always prior predictive simulations first - words, look distributions values see actually biologically possible - see exploring priors step . lines Stan code setting priors - written slightly different readily understandable change values make appropriate analyses, just need change numbers . Stan programs Blouch/inst/stan folder named according model run. See Table S1 Grabowski (revision) models. Remember, priors based know biological processes underlying research question prior predictive simulations (see McElreath 2020) Now let’s run multi-level adaptive model varying effects (blouchOU_reg_adapt_mlm_ve ). Stan prints lot info, lets just look parameter estimates store posterior distribution later use. can also print compare parameter estimates values set earlier. Now let’s run non-multilevel version model. compare two models terms predictive performance . can also compare parameter estimates values set earlier.","code":"######################################################################################################## #Priors #hl ~ lognormal(log(0.25),0.75); #vy ~ exponential(20); #optima_bar ~ normal(2.88,1); #beta_bar ~ normal(0.16,0.25); #Stan Code target += lognormal_lpdf(hl|log(0.25),0.75); target += exponential_lpdf(vy|20); target += normal_lpdf(optima_bar|2.8,1); target += normal_lpdf(beta_bar|0.16,0.25); ######################################################################################################## #Complete Priors #hl ~ lognormal(log(0.25),0.75); #vy ~ exponential(20); #optima_bar ~ normal(2.8,1); #beta_bar ~ normal(0.16,0.25); #Rho ~ lkj_corr(4);  fit.reg.adapt.mlm.ve<- rstan::sampling(blouch:::stanmodels$blouchOU_reg_adapt_mlm_ve,data = dat,chains = 2,cores=2,iter =4000, control = list(adapt_delta = 0.95)) print(fit.reg.adapt.mlm.ve,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\",\"beta_e\")) #> Inference for Stan model: blouchOU_reg_adapt_mlm_ve. #> 2 chains, each with iter=4000; warmup=2000; thin=1;  #> post-warmup draws per chain=2000, total post-warmup draws=4000. #>  #>              mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat #> hl           0.09    0.00 0.04  0.04  0.06  0.08  0.10  0.20   903    1 #> vy           0.01    0.00 0.01  0.00  0.00  0.01  0.01  0.02  5456    1 #> optima_bar   2.55    0.01 0.52  1.51  2.21  2.55  2.89  3.58  6137    1 #> beta_bar[1]  0.33    0.00 0.16 -0.03  0.23  0.34  0.44  0.60  4898    1 #> Rho[1,1]     1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN #> Rho[1,2]    -0.22    0.00 0.29 -0.73 -0.44 -0.23 -0.02  0.39  6561    1 #> Rho[2,1]    -0.22    0.00 0.29 -0.73 -0.44 -0.23 -0.02  0.39  6561    1 #> Rho[2,2]     1.00    0.00 0.00  1.00  1.00  1.00  1.00  1.00  3807    1 #> sigma[1]     1.24    0.00 0.39  0.68  0.96  1.18  1.46  2.16  6834    1 #> sigma[2]     0.39    0.00 0.23  0.13  0.24  0.33  0.48  0.98  3328    1 #> optima[1]    1.02    0.00 0.11  0.80  0.95  1.02  1.09  1.25  6665    1 #> optima[2]    1.88    0.00 0.12  1.64  1.80  1.87  1.95  2.12  4863    1 #> optima[3]    2.71    0.00 0.27  2.13  2.54  2.72  2.90  3.23  4300    1 #> optima[4]    3.98    0.00 0.15  3.76  3.90  3.97  4.04  4.31  1067    1 #> beta[1,1]    0.75    0.00 0.07  0.62  0.70  0.75  0.80  0.89  4003    1 #> beta[2,1]    0.45    0.00 0.08  0.29  0.40  0.45  0.50  0.61  7186    1 #> beta[3,1]    0.18    0.00 0.19 -0.23  0.06  0.20  0.31  0.52  4032    1 #> beta[4,1]    0.26    0.00 0.06  0.15  0.22  0.26  0.30  0.38  6296    1 #> beta_e[1,1]  0.66    0.00 0.07  0.52  0.61  0.66  0.70  0.79  4204    1 #> beta_e[2,1]  0.39    0.00 0.07  0.25  0.35  0.39  0.44  0.54  5583    1 #> beta_e[3,1]  0.16    0.00 0.17 -0.20  0.05  0.17  0.28  0.46  4007    1 #> beta_e[4,1]  0.23    0.00 0.05  0.13  0.20  0.23  0.26  0.32  7030    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:15:35 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.adapt.mlm.ve,depth=3,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\",\"beta_e\"))) #For use with rethinking package post.mlm.ve<-rstan::extract(fit.reg.adapt.mlm.ve) #Extract posterior distribution print(fit.reg.adapt.mlm.ve,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_adapt_mlm_ve. #> 2 chains, each with iter=4000; warmup=2000; thin=1;  #> post-warmup draws per chain=2000, total post-warmup draws=4000. #>  #>           mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.09       0 0.04  0.04 0.06 0.08 0.10  0.20   903    1 #> vy        0.01       0 0.01  0.00 0.00 0.01 0.01  0.02  5456    1 #> optima[1] 1.02       0 0.11  0.80 0.95 1.02 1.09  1.25  6665    1 #> optima[2] 1.88       0 0.12  1.64 1.80 1.87 1.95  2.12  4863    1 #> optima[3] 2.71       0 0.27  2.13 2.54 2.72 2.90  3.23  4300    1 #> optima[4] 3.98       0 0.15  3.76 3.90 3.97 4.04  4.31  1067    1 #> beta[1,1] 0.75       0 0.07  0.62 0.70 0.75 0.80  0.89  4003    1 #> beta[2,1] 0.45       0 0.08  0.29 0.40 0.45 0.50  0.61  7186    1 #> beta[3,1] 0.18       0 0.19 -0.23 0.06 0.20 0.31  0.52  4032    1 #> beta[4,1] 0.26       0 0.06  0.15 0.22 0.26 0.30  0.38  6296    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:15:35 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). ######################################################################################################## #Priors #hl ~ lognormal(log(0.25),0.75); #vy ~ exponential(20); #optima ~ normal(2.8,1); #beta ~ normal(0.16,0.25);  fit.reg.adapt.ve<- rstan::sampling(blouch:::stanmodels$blouchOU_reg_adapt_ve,data = dat,chains = 2,cores=2,iter =4000) print(fit.reg.adapt.ve,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #plot(rethinking::precis(fit.reg.adapt.ve,depth=3,pars = c(\"hl\",\"vy\",\"optima\",\"beta\",\"beta_e\")))#For use with rethinking package post.ve<-rstan::extract(fit.reg.adapt.ve)#Extract posterior distribution"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"plotting-posterior-versus-prior-distributions","dir":"Articles","previous_headings":"","what":"Plotting posterior versus prior distributions","title":"Simulation Example","text":"Great. can see marginal likelihood tables Blouch fairly accurate recovering known parameter values. effective way look full estimated posterior distribution compare prior plot results. Lets use multi-optima adaptive model varying effects - model’s posterior looks quite similar. plots dotted line true values parameter. First half-life (hl):  Now stationary variance parameter (Vy):  Now lets plot covariance function distance tips - gives idea decay covariance OU process. use Blouch’s R helper function, calc_multiadaptive_cov_plot.R make plots:  Finally lets plot regression results - posterior compared prior true values (dotted lines).","code":"######################################################################################################## #Hl Plot prior vs. posterior - assume posterior has been extracted using extract(model) and stored in post  hl.sims<-data.frame(rlnorm(n=1000,meanlog=log(0.25),sdlog=0.75)) names(hl.sims)<-\"prior.hl.sims\"  hl.post<-data.frame(post.ve$hl) #Using this model's posterior names(hl.post)<-\"post.hl.sims\"  hl.plot<-ggplot2::ggplot()+   ggplot2::geom_density(ggplot2::aes(prior.hl.sims,fill=\"prior.hl.sims\"),alpha=0.2,data=hl.sims)+   ggplot2::geom_density(ggplot2::aes(post.hl.sims,fill=\"post.hl.sims\"),alpha=0.2,data=hl.post)+   ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      #labs(title=\"Prior vs. Posterior Distribution \",x=\"Half-life\", y = \"Density\")+   ggplot2::labs(title=\"\",x=\"Half-life\", y = \"Density\")+      #scale_fill_manual(labels=c(\"Posterior\",\"Prior\"))+   ggplot2::geom_vline(xintercept=c(hl),linetype=2)+   ggsci::scale_fill_npg(name=\"\",labels=c(\"Posterior\",\"Prior\"))  hl.plot vy.sims<-rexp(n=1000,rate=20) vy.sims<-data.frame(vy.sims) names(vy.sims)<-\"prior.vy.sims\"   vy.post<-data.frame(post.mlm.ve$vy) names(vy.post)<-\"post.vy.sims\"   vy.plot<-ggplot2::ggplot()+   ggplot2::geom_density(ggplot2::aes(prior.vy.sims,fill=\"prior.vy.sims\"),alpha=0.2,data=vy.sims)+   ggplot2::geom_density(ggplot2::aes(post.vy.sims,fill=\"post.vy.sims\"),alpha=0.2,data=vy.post)+   ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      #labs(title=\"Prior vs. Posterior Distribution \",x=\"vy\", y = \"Density\")+   ggplot2::labs(title=\"\",x=\"vy\", y = \"Density\")+   ggplot2::geom_vline(xintercept=c(vy),linetype=2)+      #scale_fill_manual(labels=c(\"Posterior\",\"Prior\"))+   ggsci::scale_fill_npg(name=\"\",labels=c(\"Posterior\",\"Prior\"))  vy.plot ######################################################################################################## #Adaptation model - multiple regimes a.sims<-log(2)/hl.sims; sigma2_y.sims<-vy.sims*(2*(log(2)/hl.sims)); beta.sims<-replicate(length(beta),rnorm(n=1000,0,0.25))  mypal <- ggsci::pal_npg(\"nrc\", alpha = 0.4)(2)  plot( NULL , xlim=c(0,1) , ylim=c(0,0.3) , xlab=\"Time since MRCA\" , ylab=\"Covariance\" ,cex.axis=0.75, mgp=c(1.25,0.25,0),tcl=-0.25) for (i in 1:30){   curve(calc_multiadaptive_cov_plot(a.sims[i,],sigma2_y.sims[i,],beta.sims[i,],x,Z_adaptive,n_reg) , add=TRUE , lwd=4 ,col=mypal[2]) #Prior - blue }  for (i in 1:30){   curve(calc_multiadaptive_cov_plot(post.ve$a[i],post.ve$sigma2_y[i],as.numeric(data.frame(post.ve$beta)[i,]),x,Z_adaptive,n_reg) , add=TRUE , lwd=4 , col=mypal[1]) #Posterior - red } #par(mar=c(3,3,0.25,0.25))  #covariance.plot <- recordPlot() #dev.off() #covariance.plot ######################################################################################################## X<-X_with_error Y<-Y_with_error  optima.sims<-rnorm(100,2.88,1) beta.sims<-rnorm(100, 0.16,0.25)  optima.post<-post.ve$optima beta.post<-data.frame(post.ve$beta) names(beta.post)<-c(\"post.beta.1\",\"post.beta.2\",\"post.beta.3\",\"post.beta.4\")   mu.link.11<-function(x.seq){optima.post[,1]+x.seq*beta.post[,1]} mu.link.12<-function(x.seq){optima.post[,2]+x.seq*beta.post[,2]}  mu.link.21<-function(x.seq){optima.post[,3]+x.seq*beta.post[,3]} mu.link.22<-function(x.seq){optima.post[,4]+x.seq*beta.post[,4]}  x.seq <- seq(from=min(X), to=max(X) , length.out=100) mu.11 <- sapply(x.seq , mu.link.11 ) mu.12 <- sapply(x.seq , mu.link.12 ) mu.21 <- sapply(x.seq , mu.link.21 ) mu.22 <- sapply(x.seq , mu.link.22 )  mu.mean.11<-colMeans(mu.11) mu.mean.12<-colMeans(mu.12) mu.mean.21<-colMeans(mu.21) mu.mean.22<-colMeans(mu.22)  mu.mean.11<-data.frame(as.numeric(mu.mean.11)) mu.mean.12<-data.frame(as.numeric(mu.mean.12)) names(mu.mean.11)<-\"mu.mean.11\" names(mu.mean.12)<-\"mu.mean.12\"  mu.mean.21<-data.frame(as.numeric(mu.mean.21)) mu.mean.22<-data.frame(as.numeric(mu.mean.22)) names(mu.mean.21)<-\"mu.mean.21\" names(mu.mean.22)<-\"mu.mean.22\"    mu.CI.11 <- apply( mu.11 , MARGIN=2, FUN=rethinking::PI , prob=0.89 ) mu.CI.12 <- apply( mu.12 , MARGIN=2, FUN=rethinking::PI , prob=0.89 )   mu.CI.11<-data.frame(t(data.frame(mu.CI.11)),x.seq) mu.CI.12<-data.frame(t(data.frame(mu.CI.12)),x.seq)  mu.CI.21 <- apply( mu.21 , MARGIN=2, FUN=rethinking::PI , prob=0.89 ) mu.CI.22 <- apply( mu.22 , MARGIN=2, FUN=rethinking::PI , prob=0.89 )  mu.CI.21<-data.frame(t(data.frame(mu.CI.21)),x.seq) mu.CI.22<-data.frame(t(data.frame(mu.CI.22)),x.seq)   names(mu.CI.11)<-c(\"min.5.5\",\"max.94.5\",\"x.seq\") names(mu.CI.12)<-c(\"min.5.5\",\"max.94.5\",\"x.seq\") names(mu.CI.21)<-c(\"min.5.5\",\"max.94.5\",\"x.seq\") names(mu.CI.22)<-c(\"min.5.5\",\"max.94.5\",\"x.seq\")  df<-data.frame(Y=dat$Y_obs,X=dat$X_obs,Regimes=regimes_tip) df11<-data.frame(x.seq,mu.mean.11) df12<-data.frame(x.seq,mu.mean.12) df21<-data.frame(x.seq,mu.mean.21) df22<-data.frame(x.seq,mu.mean.22)  mypal <- ggsci::pal_npg(\"nrc\", alpha = 0.7)(length(beta))  slope.plot.1<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=Regimes))+   ggplot2::geom_abline(intercept=optima.sims,slope=beta.sims,alpha=0.1)+      ggplot2::geom_abline(intercept=optima[1],slope=beta[1],alpha=0.5,linetype=2)+   ggplot2::geom_abline(intercept=optima[2],slope=beta[2],alpha=0.5,linetype=2)+   ggplot2::geom_abline(intercept=optima[3],slope=beta[3],alpha=0.5,linetype=2)+   ggplot2::geom_abline(intercept=optima[4],slope=beta[4],alpha=0.5,linetype=2)+      ggplot2::geom_line(data=df11,ggplot2::aes(x=x.seq,y=mu.mean.11),linetype=1)+   ggplot2::geom_ribbon(data=mu.CI.11,ggplot2::aes(x=x.seq,ymin=min.5.5,ymax=max.94.5),linetype=2,alpha=0.2)+   ggplot2::geom_line(data=df12,ggplot2::aes(x=x.seq,y=mu.mean.12),linetype=1)+   ggplot2::geom_ribbon(data=mu.CI.12,ggplot2::aes(x=x.seq,ymin=min.5.5,ymax=max.94.5),linetype=2,alpha=0.2)+      ggplot2::geom_line(data=df21,ggplot2::aes(x=x.seq,y=mu.mean.21),linetype=1)+   ggplot2::geom_ribbon(data=mu.CI.21,ggplot2::aes(x=x.seq,ymin=min.5.5,ymax=max.94.5),linetype=2,alpha=0.2)+   ggplot2::geom_line(data=df22,ggplot2::aes(x=x.seq,y=mu.mean.22),linetype=1)+   ggplot2::geom_ribbon(data=mu.CI.22,ggplot2::aes(x=x.seq,ymin=min.5.5,ymax=max.94.5),linetype=2,alpha=0.2)+         ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      # Right -> inside the plot area   ggplot2::theme(     legend.position = c(.8, .3),     legend.justification = c(\"left\", \"top\"),     legend.box.just = \"left\",     legend.margin = ggplot2::margin(6, 6, 6, 6)   )+      #ggtitle(\"Prior vs. Posterior for Intercept and Slope\")+   ggplot2::ylab(\"Y\") + ggplot2::xlab(\"Adaptive trait\")+   ggsci::scale_color_npg()  slope.plot.1"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"model-comparison-using-psis","dir":"Articles","previous_headings":"","what":"Model Comparison using PSIS","title":"Simulation Example","text":"Lets model comparison using Pareto-Smoothed Importance Sampling (PSIS) R Package loo (Vehtari et al. 2023). loo estimates leave-one-cross validation Bayesian analyses. looking Pareto k values ~0.7, suggest results accurate. two species consistently high Pareto shape values across models Daubentonia madagascariensis, sole member distinct lemur family, Tarsius bancanus, tarsier included phylogeny – distinct due long period independent evolution (.e. long single branch phylogeny). leads hard predict based species tree. PSIS also provides way look outliers analysis. compare two models using loo_compare function package.     results suggest two models indistinguishable - standard error difference expected log pointwise predictive density (elpd) two models larger difference.","code":"#Mlm varying effects model loo_mlm_ve <- loo::loo(fit.reg.adapt.mlm.ve, save_psis = TRUE) #> Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details. print(loo_mlm_ve) #>  #> Computed from 4000 by 100 log-likelihood matrix #>  #>          Estimate   SE #> elpd_loo     30.9  7.0 #> p_loo         5.4  1.5 #> looic       -61.8 13.9 #> ------ #> Monte Carlo SE of elpd_loo is NA. #>  #> Pareto k diagnostic values: #>                          Count Pct.    Min. n_eff #> (-Inf, 0.5]   (good)     98    98.0%   1474       #>  (0.5, 0.7]   (ok)        1     1.0%   656        #>    (0.7, 1]   (bad)       1     1.0%   202        #>    (1, Inf)   (very bad)  0     0.0%   <NA>       #> See help('pareto-k-diagnostic') for details. plot(loo_mlm_ve) #4X6 plot(loo_mlm_ve,label_points=TRUE) #Label outliers #Varying effects model loo_ve <- loo::loo(fit.reg.adapt.ve, save_psis = TRUE) #> Warning: Some Pareto k diagnostic values are slightly high. See help('pareto-k-diagnostic') for details. print(loo_ve) #>  #> Computed from 4000 by 100 log-likelihood matrix #>  #>          Estimate   SE #> elpd_loo     31.2  7.2 #> p_loo         5.4  1.5 #> looic       -62.4 14.3 #> ------ #> Monte Carlo SE of elpd_loo is 0.1. #>  #> Pareto k diagnostic values: #>                          Count Pct.    Min. n_eff #> (-Inf, 0.5]   (good)     98    98.0%   1894       #>  (0.5, 0.7]   (ok)        2     2.0%   461        #>    (0.7, 1]   (bad)       0     0.0%   <NA>       #>    (1, Inf)   (very bad)  0     0.0%   <NA>       #>  #> All Pareto k estimates are ok (k < 0.7). #> See help('pareto-k-diagnostic') for details. plot(loo_ve) #4X6 plot(loo_ve,label_points=TRUE) #Label outliers loo::loo_compare(loo_mlm_ve, loo_ve) #>        elpd_diff se_diff #> model2  0.0       0.0    #> model1 -0.3       0.4"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"model-comparison-using-bayes-factors","dir":"Articles","previous_headings":"","what":"Model Comparison using Bayes Factors","title":"Simulation Example","text":"Now lets compare two models using Bayes Factors. use bridgesampling R package (Gronau et al. 2020). Looking , can read results data X times likely model assumes first mode rather second model. results suggest non-multilevel model preferred multilevel version model.","code":"######################################################################################################## #Bayes Factors lml.fit.reg.adapt.mlm.ve<-bridgesampling::bridge_sampler(fit.reg.adapt.mlm.ve,silent=TRUE,maxiter=5000) lml.fit.reg.adapt.ve<-bridgesampling::bridge_sampler(fit.reg.adapt.ve,silent=TRUE,maxiter=5000)  bridgesampling::bf(lml.fit.reg.adapt.ve,lml.fit.reg.adapt.mlm.ve) #> Estimated Bayes factor in favor of lml.fit.reg.adapt.ve over lml.fit.reg.adapt.mlm.ve: 2.21075"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"trace-for-estimated-parameters","dir":"Articles","previous_headings":"Model Comparison using Bayes Factors","what":"Trace for estimated parameters","title":"Simulation Example","text":"Let’s look traceplots two models, give visualization degree convergence.","code":"######################################################################################################## #Traceplots #4X10 rstan::traceplot(fit.reg.adapt.mlm.ve,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\")) rstan::traceplot(fit.reg.adapt.ve,pars = c(c(\"hl\",\"vy\",\"optima\",\"beta\",\"beta_e\")))"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"predictive-checks","dir":"Articles","previous_headings":"","what":"Predictive Checks","title":"Simulation Example","text":"Now lets run prior predictive checks posterior predictive checks two models. Prior predictive checks generate predictions model using prior distributions order assess whether priors appropriate – equivalent running model without data (Gabry et al. 2019). Posterior predictive checks generate data according posterior predictive distribution compare observed data assess fit model (Gabry et al. 2019). Blouch includes Stan functions run prior posterior predictive checks included models use demonstrated simulation empirical examples.","code":""},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"prior-predictive-checks","dir":"Articles","previous_headings":"Predictive Checks","what":"Prior predictive checks","title":"Simulation Example","text":"Prior predictive checks show generally reasonable fit data data generated priors, though larger true values suggest using larger scale priors may warranted","code":"fit.reg.adapt.mlm.ve.priorpc<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_mlm_ve_priorpc,data = dat,chains = 1,cores=1,iter =2000, algorithm=c(\"Fixed_param\")) #>  #> SAMPLING FOR MODEL 'blouchOU_reg_adapt_mlm_ve_priorpc' NOW (CHAIN 1). #> Chain 1: Iteration:    1 / 2000 [  0%]  (Sampling) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Sampling) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Sampling) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Sampling) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Sampling) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0 seconds (Warm-up) #> Chain 1:                4.74 seconds (Sampling) #> Chain 1:                4.74 seconds (Total) #> Chain 1: post<-rstan::extract(fit.reg.adapt.mlm.ve.priorpc) mypal <- ggsci::pal_aaas(\"default\", alpha = 1)(4)  df<-data.frame(Y=post$Y_sim_obs[3,],X=dat$Y_obs,Regimes=regimes_tip) #Sample from the posterior - in this case the third sample  priorpc.plot<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=as.factor(Regimes)))+   ggplot2::geom_abline(intercept=0,slope=1,alpha=1)+ #Prior      ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      ggplot2::ggtitle(\"Prior Predictive Check\")+   ggplot2::ylab(\"Simulated Y\") + ggplot2::xlab(\"True Y\")+   ggplot2::scale_color_manual(name=\"Regimes\",values=mypal,labels=c('OU1', 'OU2', 'OU3', 'OU4'))   priorpc.plot"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"posterior-predictive-checks","dir":"Articles","previous_headings":"Predictive Checks","what":"Posterior predictive checks","title":"Simulation Example","text":"Posterior predictive checks suggest model reasonably reproducing true values - pattern evident residuals.","code":"######################################################################################################## fit.reg.adapt.mlm.ve.postpc<-rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_mlm_ve_postpc,data = dat,chains = 1,cores=1,iter =4000)#, algorithm=c(\"Fixed_param\")) #>  #> SAMPLING FOR MODEL 'blouchOU_reg_adapt_mlm_ve_postpc' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.00456 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 45.6 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 4000 [  0%]  (Warmup) #> Chain 1: Iteration:  400 / 4000 [ 10%]  (Warmup) #> Chain 1: Iteration:  800 / 4000 [ 20%]  (Warmup) #> Chain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup) #> Chain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup) #> Chain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup) #> Chain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling) #> Chain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling) #> Chain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling) #> Chain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling) #> Chain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling) #> Chain 1: Iteration: 4000 / 4000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 162.88 seconds (Warm-up) #> Chain 1:                147.19 seconds (Sampling) #> Chain 1:                310.07 seconds (Total) #> Chain 1: post<-rstan::extract(fit.reg.adapt.mlm.ve.postpc) mypal <- ggsci::pal_aaas(\"default\", alpha = 1)(4)  df<-data.frame(Y=post$Y_sim_obs[3,],X=dat$Y_obs,Regimes=regimes_tip) #Sample from the posterior - in this case the third sample  postpc.plot<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=as.factor(Regimes)))+   ggplot2::geom_abline(intercept=0,slope=1,alpha=1)+ #Prior      ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      ggplot2::ggtitle(\"Posterior Predictive Check\")+   ggplot2::ylab(\"Simulated Y\") + ggplot2::xlab(\"True Y\")+   ggplot2::scale_color_manual(name=\"Regimes\",values=mypal,labels=c('OU1', 'OU2', 'OU3', 'OU4'))   postpc.plot"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"prior-predictive-checks-1","dir":"Articles","previous_headings":"Predictive Checks","what":"Prior predictive checks","title":"Simulation Example","text":"Now lets non-multilevel model.  , prior predictive checks show generally reasonable fit data data generated priors, though larger true values suggest using larger scale priors may warranted","code":"fit.reg.adapt.ve.priorpc<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_ve_priorpc,data = dat,chains = 1,cores=1,iter =2000, algorithm=c(\"Fixed_param\")) #>  #> SAMPLING FOR MODEL 'blouchOU_reg_adapt_ve_priorpc' NOW (CHAIN 1). #> Chain 1: Iteration:    1 / 2000 [  0%]  (Sampling) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Sampling) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Sampling) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Sampling) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Sampling) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0 seconds (Warm-up) #> Chain 1:                4.844 seconds (Sampling) #> Chain 1:                4.844 seconds (Total) #> Chain 1: post<-rstan::extract(fit.reg.adapt.ve.priorpc) mypal <- ggsci::pal_aaas(\"default\", alpha = 1)(4)  df<-data.frame(Y=post$Y_sim_obs[3,],X=dat$Y_obs,Regimes=regimes_tip) #Sample from the posterior - in this case the third sample  priorpc.plot<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=as.factor(Regimes)))+   ggplot2::geom_abline(intercept=0,slope=1,alpha=1)+ #Prior      ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      ggplot2::ggtitle(\"Prior Predictive Check\")+   ggplot2::ylab(\"Simulated Y\") + ggplot2::xlab(\"True Y\")+   ggplot2::scale_color_manual(name=\"Regimes\",values=mypal,labels=c('OU1', 'OU2', 'OU3', 'OU4'))   priorpc.plot"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"posterior-predictive-checks-1","dir":"Articles","previous_headings":"Predictive Checks","what":"Posterior predictive checks","title":"Simulation Example","text":"Posterior predictive checks show model well fit generates data close approximation true dataset. real data analysis, comparison distribution differences true values predicted values might warranted, rather single simulation.","code":"######################################################################################################## fit.reg.adapt.ve.postpc<-rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_ve_postpc,data = dat,chains = 1,cores=1,iter =2000)#, algorithm=c(\"Fixed_param\")) #>  #> SAMPLING FOR MODEL 'blouchOU_reg_adapt_ve_postpc' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.004523 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 45.23 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 85.981 seconds (Warm-up) #> Chain 1:                73.211 seconds (Sampling) #> Chain 1:                159.192 seconds (Total) #> Chain 1: post<-rstan::extract(fit.reg.adapt.ve.postpc) mypal <- ggsci::pal_aaas(\"default\", alpha = 1)(4)  df<-data.frame(Y=post$Y_sim_obs[3,],X=dat$Y_obs,Regimes=regimes_tip) #Sample from the posterior - in this case the third sample  postpc.plot<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=as.factor(Regimes)))+   ggplot2::geom_abline(intercept=0,slope=1,alpha=1)+ #Prior      ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      ggplot2::ggtitle(\"Posterior Predictive Check\")+   ggplot2::ylab(\"Simulated Y\") + ggplot2::xlab(\"True Y\")+   ggplot2::scale_color_manual(name=\"Regimes\",values=mypal,labels=c('OU1', 'OU2', 'OU3', 'OU4'))   postpc.plot"},{"path":"https://mark-grabowski.github.io/blouch/articles/Simulation-Example.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Simulation Example","text":"Arnold, C., L. J. Matthews, C. L. Nunn. 2010. 10kTrees Website: New Online Resource Primate Phylogeny. Evolutionary Anthropology 19:114-118. Gabry J., Simpson D., Vehtari ., Betancourt M., Gelman . 2019. Visualization Bayesian workflow. Journal Royal Statistical Society: Series (Statistics Society). 182:389–402. Gronau Q.F., Singmann H., Wagenmakers E.-J. 2020. bridgesampling: R Package Estimating Normalizing Constants. Journal Statistical Software. 92:1–29. Hansen T.F. 1997. Stabilizing Selection Comparative Analysis Adaptation. Evolution. 51:1341–1351. McElreath R. 2020. Statistical rethinking: Bayesian course examples R Stan. CRC press. Paradis E., Claude J., Strimmer K. 2004. APE: Analyses Phylogenetics Evolution R language. Bioinformatics. 20:289–290. Revell L.J. 2011. phytools: R package phylogenetic comparative biology (things). Methods Ecol. Evol. 3:217–223. Uyeda J.C., Harmon L.J. 2014. Novel Bayesian Method Inferring Interpreting Dynamics Adaptive Landscapes Phylogenetic Comparative Data. Systematic Biology. 63:902–918. Vehtari ., Gabry J., Magnusson M., Yao Y., Bürkner P.-C., Paananen T., Gelman . 2023. loo: Efficient leave-one-cross-validation WAIC Bayesian models.","code":""},{"path":"https://mark-grabowski.github.io/blouch/articles/Varying_Effects_Models-Examples.html","id":"multi-optima-direct-effect-model-with-varying-effects---single-predictor","dir":"Articles","previous_headings":"","what":"Multi-optima Direct Effect Model with Varying Effects - Single Predictor","title":"Varying Effects Models-Examples","text":"First create phylogeny randomly sampling 10K Trees phylogeny   Simulate X Y data   use helper function blouch.reg.direct.prep() setup dat file Stan. “Z_direct” number predictors, “regimes” name regime column trdata$dat.  Multilevel Multi-optima Direct Effect Model Varying Effects Multilevel Multi-optima Direct Effect Model Varying Effects - Non centered Multi-optima Direct Effect Model Varying Effects","code":"########################################################################################################  set.seed(10)  N<-50 #Number of species #set.seed(1) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   #Set regimes - manually - 2 regimes #Locate nodes plot(phy,no.margin=TRUE,edge.width=2,cex=0.7) ape::nodelabels(frame=\"none\",adj=c(1.1,-0.4)) ape::tiplabels() #Paint Regimes on Tree  shifts<-c(84) #Location of nodes with regime shifts trdata<-data.frame(phy$tip.label) trdata<-treeplyr::make.treedata(phy,trdata) trdata<-set.converge.regimes(trdata,shifts) #> [1] 1 #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2 #> [1] \"#E64B35FF\" \"#4DBBD5FF\"   #Check if manual setting code worked shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label) edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]]) print(edge.regimes) #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2  reg_tips<-trdata$dat$regimes reg_tips<-as.numeric(as.factor(reg_tips))  reg.colors<-ggsci::pal_npg(palette=c(\"nrc\"),alpha=1)(2) plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1, cex = 0.2) #Phylogeny info n<-length(trdata$phy$tip.label)  regimes_internal <-trdata$phy$node.label regimes_tip <- trdata$dat$regimes regimes <- concat.factor(regimes_tip, regimes_internal)   anc_maps<-\"regimes\" lineages <- lapply(1:n, function(e) lineage.constructor(trdata$phy, e, anc_maps, regimes)) #Trace lineage from tips (n) to root and determine regimes of each node or branch ######################### hl<-0.1 #0.1, 0.25, 0.75 - testing options a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl));  vX0<-0 vY0 <- 0 Sxx<-10 #Look at effects  X<-phytools::fastBM(phy,a=vX0,sig2=Sxx,internal=FALSE) #Simulate X BM variable on tree, with scaling 10 Z_direct<-1 names(X)<-phy$tip.label phytools::phenogram(phy,X,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... dmX<-weight.matrix(trdata$phy, a, lineages) #Slouch approach optima<-c(2,1) beta<-c(0.25,0.15) #Two Optima/Two Slopes mu<-matrix(NA,N,1) for(i in 1:N){   mu[i]<-dmX[i,]%*%optima+beta[reg_tips[i]]%*%X[i]; }  V<-calc_direct_V(phy,sigma2_y,a) Y<-MASS::mvrnorm(n=1,mu,V)  ############################################################################################################### df<-data.frame(Y=Y,X=X)  ggplot2::ggplot(data=df,ggplot2::aes(x=X,y=Y))+   ggplot2::geom_point() summary(lm(Y~X,df)) #>  #> Call: #> lm(formula = Y ~ X, data = df) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.40479  0.08649  0.21983  0.31704  0.49311  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  1.76546    0.08319   21.22  < 2e-16 *** #> X            0.24859    0.02371   10.48 5.25e-14 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.5227 on 48 degrees of freedom #> Multiple R-squared:  0.6961, Adjusted R-squared:  0.6897  #> F-statistic: 109.9 on 1 and 48 DF,  p-value: 5.254e-14  ################################################################################################################ #Simulate errors  Z_X_error<-1 #Number of X traits with error X_error<-rep(0.01,N) Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-X+rnorm(N,0,0.01)  ############################################################################################################ #Make trdata file trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error))) ############################################################################################################ #Test Blouch prep code - Regimes + Direct Efffect model #source(\"/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/blouch/R Setup Code/blouch.prep.R\") dat<-blouch.reg.direct.prep(trdata,\"Y_with_error\",\"Y_error\",\"X_with_error\",\"X_error\",Z_direct=1,\"regimes\") ################################################################################################################## #Plot of data df<-data.frame(Y=dat$Y_obs,X=dat$X_obs,Regimes=regimes_tip)  #slope.prior.plot<-ggplot(data=reg.trdata$dat,aes(y=Sim1,x=X))+ slope.plot.1<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=Regimes))+      ggplot2::geom_abline(intercept=optima[1],slope=beta[1],alpha=0.5,linetype=2)+   ggplot2::geom_abline(intercept=optima[2],slope=beta[2],alpha=0.5,linetype=2)+    ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      ggplot2::ylab(\"Y\") + ggplot2::xlab(\"Direct Effect Trait\")+   ggsci::scale_color_npg()  slope.plot.1 fit.reg.direct.mlm.ve<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_mlm_ve,data = dat,chains = 1,cores=1,iter=400) #>  #> SAMPLING FOR MODEL 'blouchOU_reg_direct_mlm_ve' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.001021 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 10.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 400 [  0%]  (Warmup) #> Chain 1: Iteration:  40 / 400 [ 10%]  (Warmup) #> Chain 1: Iteration:  80 / 400 [ 20%]  (Warmup) #> Chain 1: Iteration: 120 / 400 [ 30%]  (Warmup) #> Chain 1: Iteration: 160 / 400 [ 40%]  (Warmup) #> Chain 1: Iteration: 200 / 400 [ 50%]  (Warmup) #> Chain 1: Iteration: 201 / 400 [ 50%]  (Sampling) #> Chain 1: Iteration: 240 / 400 [ 60%]  (Sampling) #> Chain 1: Iteration: 280 / 400 [ 70%]  (Sampling) #> Chain 1: Iteration: 320 / 400 [ 80%]  (Sampling) #> Chain 1: Iteration: 360 / 400 [ 90%]  (Sampling) #> Chain 1: Iteration: 400 / 400 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 5.595 seconds (Warm-up) #> Chain 1:                2.237 seconds (Sampling) #> Chain 1:                7.832 seconds (Total) #> Chain 1: #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.mlm.ve,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_mlm_ve. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>              mean se_mean   sd  2.5%   25%   50%  75% 97.5% n_eff Rhat #> hl           0.28    0.08 0.28  0.06  0.14  0.20 0.29  1.26    14 1.09 #> vy           0.02    0.00 0.01  0.01  0.01  0.02 0.02  0.07    15 1.08 #> optima_bar  -0.27    0.23 0.70 -1.77 -0.66 -0.24 0.25  0.98     9 1.30 #> beta_bar[1]  0.95    0.22 0.91 -0.10  0.23  0.66 1.54  3.20    18 1.14 #> Rho[1,1]     1.00     NaN 0.00  1.00  1.00  1.00 1.00  1.00   NaN  NaN #> Rho[1,2]    -0.21    0.04 0.31 -0.74 -0.44 -0.23 0.00  0.37    59 1.02 #> Rho[2,1]    -0.21    0.04 0.31 -0.74 -0.44 -0.23 0.00  0.37    59 1.02 #> Rho[2,2]     1.00    0.00 0.00  1.00  1.00  1.00 1.00  1.00   212 0.99 #> sigma[1]     1.47    0.13 0.47  0.71  1.13  1.44 1.76  2.45    13 1.14 #> sigma[2]     0.79    0.13 0.63  0.07  0.22  0.61 1.26  2.17    23 1.11 #> optima[1]    2.00    0.00 0.05  1.90  1.98  2.00 2.03  2.08   161 1.00 #> optima[2]    0.81    0.11 0.43 -0.67  0.80  0.94 1.01  1.13    15 1.09 #> beta[1,1]    0.26    0.00 0.01  0.24  0.25  0.26 0.26  0.27   292 1.00 #> beta[2,1]    0.14    0.00 0.03  0.07  0.12  0.13 0.16  0.20   126 1.02 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:40:20 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.direct.mlm.ve,depth=3,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.direct.mlm.ve) fit.reg.direct.mlm.ve.nc<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_mlm_ve_nc,data = dat,chains = 1,cores=1,iter =400) #>  #> SAMPLING FOR MODEL 'blouchOU_reg_direct_mlm_ve_nc' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000678 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 6.78 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 400 [  0%]  (Warmup) #> Chain 1: Iteration:  40 / 400 [ 10%]  (Warmup) #> Chain 1: Iteration:  80 / 400 [ 20%]  (Warmup) #> Chain 1: Iteration: 120 / 400 [ 30%]  (Warmup) #> Chain 1: Iteration: 160 / 400 [ 40%]  (Warmup) #> Chain 1: Iteration: 200 / 400 [ 50%]  (Warmup) #> Chain 1: Iteration: 201 / 400 [ 50%]  (Sampling) #> Chain 1: Iteration: 240 / 400 [ 60%]  (Sampling) #> Chain 1: Iteration: 280 / 400 [ 70%]  (Sampling) #> Chain 1: Iteration: 320 / 400 [ 80%]  (Sampling) #> Chain 1: Iteration: 360 / 400 [ 90%]  (Sampling) #> Chain 1: Iteration: 400 / 400 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 26.41 seconds (Warm-up) #> Chain 1:                47.813 seconds (Sampling) #> Chain 1:                74.223 seconds (Total) #> Chain 1: #> Warning: There were 21 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.mlm.ve.nc,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_mlm_ve_nc. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>             mean se_mean   sd  2.5%   25%   50%  75% 97.5% n_eff Rhat #> hl          0.30    0.03 0.26  0.08  0.16  0.22 0.33  1.17    69 1.00 #> vy          0.02    0.00 0.01  0.01  0.01  0.02 0.02  0.06    83 1.00 #> optima_bar -0.18    0.12 0.70 -1.45 -0.68 -0.10 0.36  1.08    35 1.00 #> beta_bar    0.56    0.07 0.52 -0.45  0.22  0.37 0.90  1.73    50 1.00 #> Rho[1,1]    1.00     NaN 0.00  1.00  1.00  1.00 1.00  1.00   NaN  NaN #> Rho[1,2]   -0.06    0.03 0.31 -0.64 -0.30 -0.09 0.16  0.55   146 1.01 #> Rho[2,1]   -0.06    0.03 0.31 -0.64 -0.30 -0.09 0.16  0.55   146 1.01 #> Rho[2,2]    1.00    0.00 0.00  1.00  1.00  1.00 1.00  1.00   183 0.99 #> sigma[1]    1.36    0.10 0.56  0.53  0.92  1.28 1.79  2.50    31 1.00 #> sigma[2]    0.49    0.03 0.35  0.08  0.20  0.41 0.67  1.33   109 1.00 #> optima[1]   2.00    0.00 0.05  1.90  1.96  2.00 2.03  2.10   196 1.01 #> optima[2]   0.79    0.05 0.43 -0.57  0.76  0.91 0.98  1.10    69 1.00 #> beta[1,1]   0.26    0.00 0.01  0.24  0.25  0.26 0.27  0.28   147 1.00 #> beta[2,1]   0.14    0.00 0.03  0.08  0.11  0.13 0.16  0.20   206 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:41:43 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.direct.mlm.ve.nc,depth=3,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.direct.mlm.ve.nc) fit.reg.direct.ve<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_ve,data = dat,chains = 1,cores=1,iter =400) #>  #> SAMPLING FOR MODEL 'blouchOU_reg_direct_ve' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000822 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 8.22 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 400 [  0%]  (Warmup) #> Chain 1: Iteration:  40 / 400 [ 10%]  (Warmup) #> Chain 1: Iteration:  80 / 400 [ 20%]  (Warmup) #> Chain 1: Iteration: 120 / 400 [ 30%]  (Warmup) #> Chain 1: Iteration: 160 / 400 [ 40%]  (Warmup) #> Chain 1: Iteration: 200 / 400 [ 50%]  (Warmup) #> Chain 1: Iteration: 201 / 400 [ 50%]  (Sampling) #> Chain 1: Iteration: 240 / 400 [ 60%]  (Sampling) #> Chain 1: Iteration: 280 / 400 [ 70%]  (Sampling) #> Chain 1: Iteration: 320 / 400 [ 80%]  (Sampling) #> Chain 1: Iteration: 360 / 400 [ 90%]  (Sampling) #> Chain 1: Iteration: 400 / 400 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 2.327 seconds (Warm-up) #> Chain 1:                1.824 seconds (Sampling) #> Chain 1:                4.151 seconds (Total) #> Chain 1: #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.ve,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_ve. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.45    0.11 0.41  0.12 0.19 0.30 0.55  1.54    13    1 #> vy        0.03    0.01 0.02  0.01 0.02 0.02 0.03  0.09    14    1 #> optima[1] 1.98    0.01 0.08  1.80 1.95 1.99 2.02  2.10    91    1 #> optima[2] 0.52    0.17 0.65 -1.39 0.46 0.80 0.91  1.06    14    1 #> beta[1,1] 0.26    0.00 0.01  0.24 0.25 0.26 0.26  0.28   307    1 #> beta[2,1] 0.15    0.00 0.03  0.09 0.13 0.15 0.17  0.21   236    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:41:56 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.direct.ve,depth=3,pars = c(\"hl\",\"vy\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.direct.ve) rm(list=ls())"},{"path":"https://mark-grabowski.github.io/blouch/articles/Varying_Effects_Models-Examples.html","id":"multlevel-multi-optima-direct-effect-model-with-varying-effects---multiple-predictors","dir":"Articles","previous_headings":"","what":"Multlevel Multi-optima Direct Effect Model with Varying Effects - Multiple Predictors","title":"Varying Effects Models-Examples","text":"Two regimes two direct effect predictors multiple slopes per optima single alpha parameter    Format tree Simulate two direct effect traits   use helper function blouch.reg.direct.prep() setup dat file Stan. “Z_direct” number predictors, “regimes” name regime column trdata$dat. Multilevel Multi-optima Direct Efect Model Varying Effects Multilevel Multi-optima Direct Efect Model Varying Effects - non-centered Multi-optima Direct Efect Model Varying Effects posteriors explored, compared priors, etc. See Simulation Example one example .","code":"############################################################################################################ #Regimes model ############################################################################################################ ######################################################################################################## #Create phylogeny ######################################################################################################## N<-50 #Number of species set.seed(10) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   tip.label<-phy$tip.label   #Set regimes - manually - 2 regimes #Locate nodes plot(phy,no.margin=TRUE,edge.width=2,cex=0.7) ape::nodelabels(frame=\"none\",adj=c(1.1,-0.4)) ape::tiplabels() #Paint Regimes on Tree #source(\"/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/blouch/Simulation Code/Functions/set.converge.regimes.R\") #Macbook Pro  shifts<-c(84) #Location of nodes with regime shifts trdata<-data.frame(phy$tip.label) trdata<-treeplyr::make.treedata(phy,trdata) trdata<-set.converge.regimes(trdata,shifts) #> [1] 1 #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2 #> [1] \"#E64B35FF\" \"#4DBBD5FF\" #Check if manual setting code worked shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label) edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]]) print(edge.regimes) #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2  reg_tips<-trdata$dat$regimes reg_tips<-as.numeric(as.factor(reg_tips))  reg.colors <- ggsci::pal_aaas(\"default\", alpha = 0.7)(2) print(reg.colors) #> [1] \"#3B4992B2\" \"#EE0000B2\" plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1, cex = 0.2) ############################################################################################################ #Simulate data n<-length(trdata$phy$tip.label) regimes_internal <-trdata$phy$node.label regimes_tip <- trdata$dat$regimes regimes <- concat.factor(regimes_tip, regimes_internal) anc_maps<-\"regimes\" lineages <- lapply(1:n, function(e) lineage.constructor(trdata$phy, e, anc_maps, regimes)) #Trace lineage from tips (n) to root and determine regimes of each node or branch ######################### hl<-0.1 #0.1, 0.25, 0.75 - testing options a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl));  vX0<-0 vY0 <- 0 Sxx<-10 #Look at effects  Z_direct<-2 vcv<-matrix(c(1,0,0,1),2,2) #No correlation between traits Xs<-phytools::sim.corrs(phy,vcv) #Simulated correlated BM Xs  phytools::phenogram(phy,Xs[,1],spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... phytools::phenogram(phy,Xs[,2],spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... dmX<-weight.matrix(trdata$phy, a, lineages) #Slouch approach optima<-c(2,1) beta<-data.frame(matrix(c(0.25,0.15,0.35,0.1),ncol=2,nrow=2)) #Two traits on columns, two regimes on vertical  mu<-matrix(NA,N,1) for(i in 1:N){   mu[i]<-dmX[i,]%*%optima+Xs[i,]%*%t(beta[reg_tips[i],]); }  V<-calc_direct_V(phy,sigma2_y,a) Y<-MASS::mvrnorm(n=1,mu,V)   ###############################################################################################################  summary(lm(Y~Xs)) #>  #> Call: #> lm(formula = Y ~ Xs) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -0.6152 -0.1345  0.0522  0.1855  0.6367  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  2.08836    0.06612  31.586  < 2e-16 *** #> Xs1          0.14271    0.04411   3.235  0.00223 **  #> Xs2          0.57905    0.05554  10.426  8.2e-14 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.2864 on 47 degrees of freedom #> Multiple R-squared:  0.7791, Adjusted R-squared:  0.7697  #> F-statistic:  82.9 on 2 and 47 DF,  p-value: 3.866e-16  ################################################################################################################   ################################################################################################################ #Simulate errors  Z_X_error<-2 #Number of X traits with error X_error<-matrix(0.01,nrow=N,ncol=Z_X_error) X_error<-data.frame(X_error) names(X_error)<-c(\"X1_error\",\"X2_error\") Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-Xs+rnorm(N,0,0.01) X_with_error<-data.frame(X_with_error) names(X_with_error)<-c(\"X1\",\"X2\") ############################################################################################################ #Make trdata file trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error))) ############################################################################################################ #Test Blouch prep code - Regimes + Direct Efffect model dat<-blouch.reg.direct.prep(trdata,\"Y_with_error\",\"Y_error\",c(\"X1\",\"X2\"),c(\"X1_error\",\"X2_error\"),Z_direct=2,\"regimes\") fit.reg.direct.mlm.ve<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_mlm_ve,data = dat,chains = 1,cores=1,iter =400) #> Warning: There were 47 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.mlm.ve,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_mlm_ve. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>              mean se_mean   sd  2.5%   25%   50%  75% 97.5% n_eff Rhat #> hl           0.13    0.02 0.09  0.05  0.06  0.12 0.16  0.41    12 1.13 #> vy           0.01    0.00 0.00  0.01  0.01  0.01 0.01  0.02    16 1.09 #> optima_bar  -0.24    0.09 0.60 -1.49 -0.54 -0.30 0.09  1.03    40 1.05 #> beta_bar[1]  0.56    0.14 0.65  0.01  0.18  0.32 0.69  2.82    23 1.00 #> beta_bar[2]  3.50    1.57 2.54  0.11  0.71  4.33 6.01  6.72     3 3.86 #> Rho[1,1]     1.00     NaN 0.00  1.00  1.00  1.00 1.00  1.00   NaN  NaN #> Rho[1,2]    -0.06    0.10 0.35 -0.63 -0.36 -0.11 0.31  0.44    12 1.06 #> Rho[1,3]    -0.14    0.08 0.33 -0.72 -0.40 -0.13 0.06  0.52    19 1.03 #> Rho[2,1]    -0.06    0.10 0.35 -0.63 -0.36 -0.11 0.31  0.44    12 1.06 #> Rho[2,2]     1.00    0.00 0.00  1.00  1.00  1.00 1.00  1.00   124 0.99 #> Rho[2,3]     0.13    0.05 0.32 -0.55 -0.01  0.11 0.34  0.80    42 1.02 #> Rho[3,1]    -0.14    0.08 0.33 -0.72 -0.40 -0.13 0.06  0.52    19 1.03 #> Rho[3,2]     0.13    0.05 0.32 -0.55 -0.01  0.11 0.34  0.80    42 1.02 #> Rho[3,3]     1.00    0.00 0.00  1.00  1.00  1.00 1.00  1.00    71 0.99 #> sigma[1]     1.34    0.08 0.46  0.76  0.96  1.24 1.62  2.36    33 1.04 #> sigma[2]     0.41    0.09 0.48  0.03  0.08  0.22 0.59  1.71    27 1.04 #> sigma[3]     1.76    0.64 1.09  0.07  0.61  1.96 2.68  3.31     3 2.56 #> optima[1]    2.05    0.01 0.03  2.00  2.02  2.04 2.06  2.13    39 1.11 #> optima[2]    1.15    0.02 0.12  0.92  1.08  1.17 1.22  1.39    37 1.03 #> beta[1,1]    0.21    0.00 0.02  0.18  0.20  0.21 0.23  0.26    35 1.00 #> beta[1,2]    0.34    0.00 0.03  0.29  0.32  0.33 0.35  0.39    71 1.04 #> beta[2,1]    0.22    0.01 0.07  0.10  0.17  0.21 0.26  0.34    40 1.04 #> beta[2,2]    0.26    0.01 0.07  0.14  0.22  0.24 0.30  0.40    48 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:42:14 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.direct.mlm.ve,depth=3,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.direct.mlm.ve) fit.reg.direct.mlm.ve.nc<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_mlm_ve_nc,data = dat,chains = 1,cores=1,iter =400) #> Warning: There were 7 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.mlm.ve.nc,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_mlm_ve_nc. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>             mean se_mean   sd  2.5%   25%   50%  75% 97.5% n_eff Rhat #> hl          0.17    0.01 0.09  0.07  0.11  0.15 0.21  0.46    84 1.00 #> vy          0.01    0.00 0.00  0.01  0.01  0.01 0.01  0.02   104 1.00 #> optima_bar -0.06    0.07 0.71 -1.38 -0.50 -0.04 0.33  1.30   112 1.00 #> beta_bar    0.42    0.10 0.23  0.11  0.25  0.36 0.57  0.90     5 1.09 #> Rho[1,1]    1.00     NaN 0.00  1.00  1.00  1.00 1.00  1.00   NaN  NaN #> Rho[1,2]   -0.15    0.04 0.32 -0.72 -0.37 -0.20 0.05  0.47    53 1.02 #> Rho[1,3]   -0.06    0.04 0.30 -0.59 -0.27 -0.04 0.15  0.47    57 1.02 #> Rho[2,1]   -0.15    0.04 0.32 -0.72 -0.37 -0.20 0.05  0.47    53 1.02 #> Rho[2,2]    1.00    0.00 0.00  1.00  1.00  1.00 1.00  1.00   148 0.99 #> Rho[2,3]    0.04    0.03 0.30 -0.53 -0.19  0.07 0.26  0.56   114 1.01 #> Rho[3,1]   -0.06    0.04 0.30 -0.59 -0.27 -0.04 0.15  0.47    57 1.02 #> Rho[3,2]    0.04    0.03 0.30 -0.53 -0.19  0.07 0.26  0.56   114 1.01 #> Rho[3,3]    1.00    0.00 0.00  1.00  1.00  1.00 1.00  1.00   186 0.99 #> sigma[1]    1.51    0.05 0.50  0.65  1.14  1.49 1.87  2.51   102 1.00 #> sigma[2]    0.43    0.09 0.37  0.01  0.14  0.31 0.61  1.31    16 1.02 #> sigma[3]    0.38    0.08 0.37  0.01  0.11  0.26 0.50  1.33    20 1.08 #> optima[1]   2.05    0.00 0.04  1.98  2.02  2.04 2.07  2.12   163 1.00 #> optima[2]   1.14    0.01 0.14  0.77  1.08  1.16 1.22  1.37   111 1.00 #> beta[1,1]   0.22    0.00 0.02  0.17  0.21  0.22 0.23  0.26   190 1.00 #> beta[1,2]   0.33    0.00 0.03  0.28  0.31  0.34 0.35  0.39   144 1.01 #> beta[2,1]   0.22    0.01 0.07  0.07  0.18  0.23 0.26  0.34    92 1.00 #> beta[2,2]   0.27    0.01 0.06  0.15  0.22  0.27 0.31  0.39   141 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:43:10 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.direct.mlm.ve.nc,depth=3,pars = c(\"hl\",\"vy\",\"optima_bar\",\"beta_bar\",\"Rho\",\"sigma\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.direct.mlm.ve.nc) fit.reg.direct.ve<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_ve,data = dat,chains = 1,cores=1,iter =400) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.ve,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_ve. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd  2.5%   25%  50%  75% 97.5% n_eff Rhat #> hl        0.70    0.30 0.55  0.10  0.18 0.66 1.01  1.93     3 1.96 #> vy        0.03    0.01 0.02  0.01  0.01 0.03 0.05  0.08     4 1.84 #> optima[1] 2.04    0.00 0.08  1.87  2.00 2.04 2.08  2.21   407 1.00 #> optima[2] 0.32    0.44 0.80 -1.25 -0.31 0.44 1.07  1.24     3 2.04 #> beta[1,1] 0.22    0.00 0.03  0.16  0.20 0.22 0.23  0.28   443 1.01 #> beta[1,2] 0.34    0.00 0.03  0.27  0.32 0.34 0.36  0.40   460 1.00 #> beta[2,1] 0.23    0.01 0.09  0.05  0.16 0.22 0.28  0.43   169 1.01 #> beta[2,2] 0.22    0.01 0.07  0.07  0.17 0.22 0.27  0.35   168 1.02 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:43:22 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.direct.ve,depth=3,pars = c(\"hl\",\"vy\",\"optima\",\"beta\"))) post<-rstan::extract(fit.reg.direct.ve) rm(list=ls())"},{"path":"https://mark-grabowski.github.io/blouch/articles/Varying_Effects_Models-Examples.html","id":"multlevel-multi-optima-adaptive-model-with-varying-effects---single-predictor","dir":"Articles","previous_headings":"","what":"Multlevel Multi-optima Adaptive Model with Varying Effects - Single Predictor","title":"Varying Effects Models-Examples","text":"Simulate X Y data   use helper function blouch.reg.adapt.prep() setup dat file Stan. “Z_adaptive” number predictors, “regimes” name regime column trdata$dat.  Now run Multilevel Multi-optima Adaptive Model Varying Effects, look results, rstan::extract posterior Now run non-centered version Multilevel Multi-optima Adaptive Model Varying Effects Finally run Multi-optima Adaptive Model Varying Effects posteriors explored, compared priors, etc. See Simulation Example one example .","code":"######################################################################################################## #Two regimes with adaptive trait and multiple slopes per optima but single alpha parameter set.seed(10) N<-50 #Number of species #set.seed(1) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   #Set regimes - manually - 2 regimes #Locate nodes plot(phy,no.margin=TRUE,edge.width=2,cex=0.7) ape::nodelabels(frame=\"none\",adj=c(1.1,-0.4)) ape::tiplabels() #Paint Regimes on Tree shifts<-c(84) #Location of nodes with regime shifts trdata<-data.frame(phy$tip.label) trdata<-treeplyr::make.treedata(phy,trdata) trdata<-set.converge.regimes(trdata,shifts) #> [1] 1 #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2 #> [1] \"#E64B35FF\" \"#4DBBD5FF\" #Check if manual setting code worked shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label) edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]]) #print(edge.regimes)  reg_tips<-trdata$dat$regimes reg_tips<-as.numeric(as.factor(reg_tips))  reg.colors <- ggsci::pal_aaas(\"default\", alpha = 0.7)(2)  print(reg.colors) #> [1] \"#3B4992B2\" \"#EE0000B2\" plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1, cex = 0.2) #Phylogeny info n<-length(trdata$phy$tip.label)  regimes_internal <-trdata$phy$node.label regimes_tip <- trdata$dat$regimes regimes <- concat.factor(regimes_tip, regimes_internal) anc_maps<-\"regimes\" lineages <- lapply(1:n, function(e) lineage.constructor(trdata$phy, e, anc_maps, regimes)) #Trace lineage from tips (n) to root and determine regimes of each node or branch ############################################################################################################################################################################### hl<-0.1 #0.1, 0.25, 0.75 - testing options a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl));  vX0<-0 vY0 <- 0 sigma2_x<-matrix(1,1,1) #Variance of BM Process   X<-phytools::fastBM(phy,a=vX0,sig2=sigma2_x[1,1],internal=FALSE) #Simulate X BM variable on tree, with scaling 10 Z_adaptive<-1 names(X)<-phy$tip.label phytools::phenogram(phy,X,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... optima_matrix<-weight.matrix(trdata$phy, a, lineages) #Slouch approach pred_X<-calc_adaptive_dmX(phy,a,X) optima<-c(2,1) beta<-c(0.25,0.15) #Two Optima/Two Slopes  mu<-matrix(NA,N,1) for(i in 1:N){   mu[i] = optima_matrix[i,]%*%optima+beta[reg_tips[i]]%*%pred_X[i] }  n_reg<-length(unique(regimes)) V<-calc_adaptive_V(phy,a, sigma2_y, beta,  sigma2_x, Z_adaptive) Y<-MASS::mvrnorm(n=1,mu,V)   ############################################################################################################### df<-data.frame(Y=Y,X=X)  ggplot2::ggplot(data=df,ggplot2::aes(x=X,y=Y))+   ggplot2::geom_point() summary(lm(Y~X,df)) #>  #> Call: #> lm(formula = Y ~ X, data = df) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.04977  0.02018  0.19840  0.31943  0.43449  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  1.73207    0.07814  22.167  < 2e-16 *** #> X            0.19695    0.07042   2.797  0.00741 **  #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.491 on 48 degrees of freedom #> Multiple R-squared:  0.1401, Adjusted R-squared:  0.1222  #> F-statistic: 7.821 on 1 and 48 DF,  p-value: 0.007408  ################################################################################################################  ################################################################################################################ #Simulate errors  Z_X_error<-1 #Number of X traits with error X_error<-rep(0.01,N) Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-X+rnorm(N,0,0.01)   ############################################################################################################ #Make trdata file trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error))) ############################################################################################################ #Test Blouch prep code - Regimes + Direct Efffect model dat<-blouch.reg.adapt.prep(trdata,\"Y_with_error\",\"Y_error\",\"X_with_error\",\"X_error\",Z_adaptive=1,\"regimes\") ########################################################################################################  #Plot of data df<-data.frame(Y=dat$Y_obs,X=dat$X_obs,Regimes=regimes_tip)   #slope.prior.plot<-ggplot(data=reg.trdata$dat,aes(y=Sim1,x=X))+ slope.plot.1<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=X,color=Regimes))+      ggplot2::geom_abline(intercept=optima[1],slope=beta[1],alpha=0.5,linetype=2)+   ggplot2::geom_abline(intercept=optima[2],slope=beta[2],alpha=0.5,linetype=2)+      ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      #ggtitle(\"Prior vs. Posterior for Intercept and Slope\")+   ggplot2::ylab(\"Y\") + ggplot2::xlab(\"Adaptive trait\")+   ggsci::scale_color_npg()  slope.plot.1 fit.reg.adapt.mlm.ve<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_mlm_ve,data = dat,chains = 1,cores=1,iter=400) #> Warning: There were 8 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.adapt.mlm.ve,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_adapt_mlm_ve. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.23    0.01 0.13  0.07 0.14 0.21 0.31  0.57   128    1 #> vy        0.01    0.00 0.01  0.00 0.01 0.01 0.02  0.03   224    1 #> optima[1] 1.98    0.00 0.06  1.86 1.94 1.98 2.03  2.11   248    1 #> optima[2] 0.79    0.02 0.20  0.25 0.69 0.83 0.92  1.07   123    1 #> beta[1,1] 0.30    0.01 0.08  0.19 0.24 0.29 0.34  0.49   181    1 #> beta[2,1] 0.15    0.01 0.17 -0.16 0.04 0.15 0.27  0.46   177    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:43:55 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.adapt.mlm.ve,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")))  post<-rstan::extract(fit.reg.adapt.mlm.ve) #rstan::extract posterior distribution fit.reg.adapt.mlm.ve.nc<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_mlm_ve_nc,data = dat,chains = 1,cores=1,iter=400) #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.adapt.mlm.ve.nc,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_adapt_mlm_ve_nc. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.25    0.02 0.15  0.07 0.14 0.21 0.30  0.66    97 1.01 #> vy        0.01    0.00 0.01  0.00 0.01 0.01 0.02  0.03    83 1.01 #> optima[1] 1.99    0.00 0.07  1.87 1.95 1.98 2.02  2.12   177 1.00 #> optima[2] 0.75    0.03 0.26  0.00 0.66 0.82 0.90  1.04   105 1.01 #> beta[1,1] 0.31    0.01 0.10  0.19 0.25 0.29 0.34  0.58   107 1.02 #> beta[2,1] 0.19    0.02 0.18 -0.13 0.07 0.18 0.30  0.47    93 1.03 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:44:35 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.adapt.mlm.ve.nc,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")))  post<-rstan::extract(fit.reg.adapt.mlm.ve.nc) #rstan::extract posterior distribution fit.reg.adapt.ve<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_adapt_ve,data = dat,chains = 1,cores=1,iter=400) #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.adapt.ve,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_adapt_ve. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.19    0.01 0.09  0.08 0.12 0.17 0.24  0.43    59    1 #> vy        0.01    0.00 0.01  0.00 0.01 0.01 0.02  0.03   134    1 #> optima[1] 1.98    0.00 0.06  1.89 1.94 1.98 2.02  2.10   228    1 #> optima[2] 0.86    0.01 0.14  0.47 0.81 0.88 0.95  1.07   103    1 #> beta[1,1] 0.28    0.01 0.06  0.19 0.24 0.27 0.32  0.42    77    1 #> beta[2,1] 0.11    0.01 0.14 -0.14 0.02 0.10 0.21  0.39   138    1 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:44:54 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.adapt.ve,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")))  post<-rstan::extract(fit.reg.adapt.ve) #rstan::extract posterior distribution rm(list=ls())"},{"path":"https://mark-grabowski.github.io/blouch/articles/Varying_Effects_Models-Examples.html","id":"multi-optima-direct-effect-and-adaptive-models-with-varying-effects---multiple-predictors","dir":"Articles","previous_headings":"","what":"Multi-optima Direct Effect and Adaptive models with Varying Effects - Multiple predictors","title":"Varying Effects Models-Examples","text":"Two regimes 1 direct 1 adaptive trait two slopes per regime    Simulate X Y data using generative model   use helper function blouch.reg.adapt.prep() setup dat file Stan. “Z_adaptive” number predictors, “regimes” name regime column trdata$dat.   Now run Multilevel Multi-optima Direct Effect Adaptive Model Varying Effects, look results, rstan::extract posterior Now run non-centered version Multilevel Multi-optima Direct Effect Adaptive Model Varying Effects Finally run Multi-optima Direct Effect Adaptive Model Varying Effects posteriors explored, compared priors, etc. See Simulation Example one example .","code":"######################################################################################################## set.seed(10)  N<-50 #Number of species #set.seed(1) #Set seed to get same random species each time  phy <- ape::keep.tip(tree.10K,sample(tree.10K$tip.label)[1:N])  phy<-ape::multi2di(phy)  l.tree<-max(ape::branching.times(phy)) ## rescale tree to height 1 phy$edge.length<-phy$edge.length/l.tree   #Set regimes - manually - 2 regimes #Locate nodes plot(phy,no.margin=TRUE,edge.width=2,cex=0.7) ape::nodelabels(frame=\"none\",adj=c(1.1,-0.4)) ape::tiplabels() #Paint Regimes on Tree shifts<-c(84) #Location of nodes with regime shifts trdata<-data.frame(phy$tip.label) trdata<-treeplyr::make.treedata(phy,trdata) trdata<-set.converge.regimes(trdata,shifts) #> [1] 1 #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2 #> [1] \"#E64B35FF\" \"#4DBBD5FF\" #Check if manual setting code worked shifts.total<-c(trdata$dat$regimes,trdata$phy$node.label) edge.regimes <- factor(shifts.total[trdata$phy$edge[,2]]) print(edge.regimes) #>  [1] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [20] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [39] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [58] OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 #> [77] OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU2 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 OU1 #> [96] OU1 OU1 OU1 #> Levels: OU1 OU2  reg_tips<-trdata$dat$regimes reg_tips<-as.numeric(as.factor(reg_tips))  reg.colors <- ggsci::pal_aaas(\"default\", alpha = 0.7)(2) print(reg.colors) #> [1] \"#3B4992B2\" \"#EE0000B2\" plot(trdata$phy,edge.color = reg.colors[edge.regimes], edge.width = 1, cex = 0.2) #Phylogeny info n<-length(trdata$phy$tip.label)  regimes_internal <-trdata$phy$node.label regimes_tip <- trdata$dat$regimes regimes <- concat.factor(regimes_tip, regimes_internal) anc_maps<-\"regimes\" lineages <- lapply(1:n, function(e) lineage.constructor(phy, e, anc_maps, regimes)) #Trace lineage from tips (n) to root and determine regimes of each node or branch ################################################################################################################ hl<-0.1 #0.1, 0.25, 0.75 - testing options a<-log(2)/hl vy<-0.01 #0.25,0.5 - testing options sigma2_y<-vy*(2*(log(2)/hl));  vX0<-0 vY0 <- 0 sigma2_x<-matrix(1,1,1) #Variance of BM Process  Xa<-phytools::fastBM(phy,a=vX0,sig2=sigma2_x[1,1],internal=FALSE) #Simulate X BM variable on tree, with scaling 10 Xd<-phytools::fastBM(phy,a=vX0,sig2=sigma2_x[1,1],internal=FALSE) #Simulate X BM variable on tree, with scaling 10  names(Xa)<-phy$tip.label names(Xd)<-phy$tip.label phytools::phenogram(phy,Xd,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... phytools::phenogram(phy,Xa,spread.labels=TRUE,spread.cost=c(1,0)) #Plot X data #> Optimizing the positions of the tip labels... Xs<-cbind(Xd,Xa) sigma2_x<-matrix(1,1,1) #Variance of BM Process  Z_adaptive<-1 Z_direct<-1  optima_matrix<-weight.matrix(phy, a, lineages) #Slouch approach pred_X<-calc_mixed_dmX(phy,a,Xs,Z_direct,Z_adaptive) optima<-c(2,1) beta<-data.frame(matrix(c(0.25,0.15,0.35,0.1),ncol=2,nrow=2)) #Two traits on columns, two regimes on vertical  mu<-matrix(NA,N,1) for(i in 1:N){   mu[i] = optima_matrix[i,]%*%optima+pred_X[i,]%*%t(beta[reg_tips[i],])   }  n_reg<-length(unique(regimes)) V<-calc_adaptive_V(phy,a, sigma2_y, beta[,2],  sigma2_x, Z_adaptive) Y<-MASS::mvrnorm(n=1,mu,V)   ###############################################################################################################  summary(lm(Y~Xs)) #>  #> Call: #> lm(formula = Y ~ Xs) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -0.87644 -0.23115  0.07543  0.29025  0.48469  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  2.14016    0.08049  26.589  < 2e-16 *** #> XsXd         0.61536    0.06761   9.101 6.11e-12 *** #> XsXa         0.21118    0.05370   3.933 0.000275 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.3486 on 47 degrees of freedom #> Multiple R-squared:  0.7532, Adjusted R-squared:  0.7427  #> F-statistic: 71.73 on 2 and 47 DF,  p-value: 5.234e-15  ################################################################################################################ ############################################################################################################### #Simulate errors - original Hansen setup Z_X_error<-2 #Number of X traits with error X_error<-matrix(0.01,nrow=N,ncol=Z_X_error) X_error<-data.frame(X_error) names(X_error)<-c(\"Xd_error\",\"Xa_error\") Y_error<-rep(0.01,N) Y_with_error<-Y+rnorm(N,0,0.01) X_with_error<-Xs+rnorm(N,0,0.01) X_with_error<-data.frame(X_with_error) names(X_with_error)<-c(\"Xd\",\"Xa\") ############################################################################################################ #Make trdata file trdata$dat<-cbind(trdata$dat,data.frame(cbind(Y_with_error,Y_error,X_with_error,X_error))) #names(trdata$dat)[6:7]<-c(\"Xd_error\",\"Xa_error\") ############################################################################################################ #Test Blouch prep code - Regimes + Direct Effect model dat<-blouch.reg.direct.adapt.prep(trdata,\"Y_with_error\",\"Y_error\",c(\"Xd\",\"Xa\"),c(\"Xd_error\",\"Xa_error\"),Z_direct=1,Z_adaptive=1,\"regimes\") ######################################################################################################## #Plot of data df<-data.frame(Y=dat$Y_obs,X=dat$X_obs,Regimes=regimes_tip)   #slope.prior.plot<-ggplot(data=reg.trdata$dat,aes(y=Sim1,x=X))+ slope.plot.1<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=Xd,color=Regimes))+      ggplot2::geom_abline(intercept=optima[1],slope=beta[1,1],alpha=0.5,linetype=2)+   ggplot2::geom_abline(intercept=optima[2],slope=beta[2,1],alpha=0.5,linetype=2)+         ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      #ggtitle(\"Prior vs. Posterior for Intercept and Slope\")+   ggplot2::ylab(\"Y\") + ggplot2::xlab(\"Direct effect trait\")+   ggsci::scale_color_npg()  slope.plot.1 #slope.prior.plot<-ggplot(data=reg.trdata$dat,aes(y=Sim1,x=X))+ slope.plot.2<-ggplot2::ggplot()+     ggplot2::geom_point(data=df,ggplot2::aes(y=Y,x=Xa,color=Regimes))+      ggplot2::geom_abline(intercept=optima[1],slope=beta[1,2],alpha=0.5,linetype=2)+   ggplot2::geom_abline(intercept=optima[2],slope=beta[2,2],alpha=0.5,linetype=2)+      ggplot2::theme_bw()+   ggplot2::theme(     panel.grid.major = ggplot2::element_blank(),     panel.grid.minor = ggplot2::element_blank())+      #ggtitle(\"Prior vs. Posterior for Intercept and Slope\")+   ggplot2::ylab(\"Y\") + ggplot2::xlab(\"Adaptive trait\")+   ggsci::scale_color_npg()  slope.plot.2 fit.reg.direct.adapt.mlm.ve<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_adapt_mlm_ve,data = dat,chains = 1,cores=1,iter=400) #> Warning: There were 3 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.adapt.mlm.ve,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_adapt_mlm_ve. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.26    0.01 0.08  0.14 0.20 0.25 0.29  0.43    43 1.00 #> vy        0.01    0.00 0.01  0.00 0.00 0.00 0.01  0.02   143 1.00 #> optima[1] 2.04    0.02 0.08  1.88 2.00 2.04 2.10  2.22    25 1.10 #> optima[2] 1.10    0.03 0.21  0.62 0.98 1.09 1.22  1.48    36 1.00 #> beta[1,1] 0.28    0.01 0.04  0.21 0.26 0.28 0.31  0.37    36 1.08 #> beta[1,2] 0.48    0.01 0.09  0.37 0.42 0.47 0.51  0.72    37 1.00 #> beta[2,1] 0.27    0.02 0.09  0.10 0.21 0.26 0.33  0.49    33 1.00 #> beta[2,2] 0.19    0.02 0.14 -0.12 0.11 0.20 0.29  0.44    61 1.00 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:45:26 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.direct.adapt.mlm.ve,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")))  post<-rstan::extract(fit.reg.direct.adapt.mlm.ve) fit.reg.direct.adapt.mlm.ve.nc<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_adapt_mlm_ve_nc,data = dat,chains = 1,cores=1,iter=400) #> Warning: There were 10 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.adapt.mlm.ve.nc,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_adapt_mlm_ve_nc. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.23    0.00 0.05  0.15 0.20 0.23 0.26  0.37   138 1.00 #> vy        0.01    0.00 0.01  0.00 0.00 0.01 0.01  0.02    83 1.00 #> optima[1] 2.05    0.01 0.08  1.88 2.00 2.05 2.10  2.17   171 1.00 #> optima[2] 1.20    0.02 0.15  0.92 1.12 1.20 1.28  1.48    78 1.00 #> beta[1,1] 0.28    0.00 0.04  0.21 0.26 0.28 0.30  0.37   147 1.00 #> beta[1,2] 0.46    0.01 0.07  0.36 0.42 0.46 0.51  0.59   116 1.01 #> beta[2,1] 0.31    0.01 0.06  0.19 0.28 0.32 0.35  0.43    67 1.00 #> beta[2,2] 0.15    0.02 0.14 -0.19 0.08 0.17 0.25  0.35    70 1.02 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:46:18 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.direct.adapt.mlm.ve.nc,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")))  post<-rstan::extract(fit.reg.direct.adapt.mlm.ve.nc) fit.reg.direct.adapt.ve<- rstan::sampling(object = blouch:::stanmodels$blouchOU_reg_direct_adapt_ve,data = dat,chains = 1,cores=1,iter=400) #> Warning in validityMethod(object): The following variables have undefined #> values: dmX[1,1],The following variables have undefined values: dmX[2,1],The #> following variables have undefined values: dmX[3,1],The following variables #> have undefined values: dmX[4,1],The following variables have undefined values: #> dmX[5,1],The following variables have undefined values: dmX[6,1],The following #> variables have undefined values: dmX[7,1],The following variables have #> undefined values: dmX[8,1],The following variables have undefined values: #> dmX[9,1],The following variables have undefined values: dmX[10,1],The following #> variables have undefined values: dmX[11,1],The following variables have #> undefined values: dmX[12,1],The following variables have undefined values: #> dmX[13,1],The following variables have undefined values: dmX[14,1],The #> following variables have undefined values: dmX[15,1],The following variables #> have undefined values: dmX[16,1],The following variables have undefined values: #> dmX[17,1],The following variables have undefined values: dmX[18,1],The #> following variables have undefined values: dmX[19,1],The following variables #> have undefined values: dmX[20,1],The following variables have undefined values: #> dmX[21,1],The following variables have undefined values: dmX[22,1],The #> following variables have undefined values: dmX[23,1],The following variables #> have undefined values: dmX[24,1],The following variables have undefined values: #> dmX[25,1],The following variables have undefined values: dmX[26,1],The #> following variables have undefined values: dmX[27,1],The following variables #> have undefined values: dmX[28,1],The following variables have undefined values: #> dmX[29,1],The following variables have undefined values: dmX[30,1],The #> following variables have undefined values: dmX[31,1],The following variables #> have undefined values: dmX[32,1],The following variables have undefined values: #> dmX[33,1],The following variables have undefined values: dmX[34,1],The #> following variables have undefined values: dmX[35,1],The following variables #> have undefined values: dmX[36,1],The following variables have undefined values: #> dmX[37,1],The following variables have undefined values: dmX[38,1],The #> following variables have undefined values: dmX[39,1],The following variables #> have undefined values: dmX[40,1],The following variables have undefined values: #> dmX[41,1],The following variables have undefined values: dmX[42,1],The #> following variables have undefined values: dmX[43,1],The following variables #> have undefined values: dmX[44,1],The following variables have undefined values: #> dmX[45,1],The following variables have undefined values: dmX[46,1],The #> following variables have undefined values: dmX[47,1],The following variables #> have undefined values: dmX[48,1],The following variables have undefined values: #> dmX[49,1],The following variables have undefined values: dmX[50,1],The #> following variables have undefined values: dmX[1,2],The following variables #> have undefined values: dmX[2,2],The following variables have undefined values: #> dmX[3,2],The following variables have undefined values: dmX[4,2],The following #> variables have undefined values: dmX[5,2],The following variables have #> undefined values: dmX[6,2],The following variables have undefined values: #> dmX[7,2],The following variables have undefined values: dmX[8,2],The following #> variables have undefined values: dmX[9,2],The following variables have #> undefined values: dmX[10,2],The following variables have undefined values: #> dmX[11,2],The following variables have undefined values: dmX[12,2],The #> following variables have undefined values: dmX[13,2],The following variables #> have undefined values: dmX[14,2],The following variables have undefined values: #> dmX[15,2],The following variables have undefined values: dmX[16,2],The #> following variables have undefined values: dmX[17,2],The following variables #> have undefined values: dmX[18,2],The following variables have undefined values: #> dmX[19,2],The following variables have undefined values: dmX[20,2],The #> following variables have undefined values: dmX[21,2],The following variables #> have undefined values: dmX[22,2],The following variables have undefined values: #> dmX[23,2],The following variables have undefined values: dmX[24,2],The #> following variables have undefined values: dmX[25,2],The following variables #> have undefined values: dmX[26,2],The following variables have undefined values: #> dmX[27,2],The following variables have undefined values: dmX[28,2],The #> following variables have undefined values: dmX[29,2],The following variables #> have undefined values: dmX[30,2],The following variables have undefined values: #> dmX[31,2],The following variables have undefined values: dmX[32,2],The #> following variables have undefined values: dmX[33,2],The following variables #> have undefined values: dmX[34,2],The following variables have undefined values: #> dmX[35,2],The following variables have undefined values: dmX[36,2],The #> following variables have undefined values: dmX[37,2],The following variables #> have undefined values: dmX[38,2],The following variables have undefined values: #> dmX[39,2],The following variables have undefined values: dmX[40,2],The #> following variables have undefined values: dmX[41,2],The following variables #> have undefined values: dmX[42,2],The following variables have undefined values: #> dmX[43,2],The following variables have undefined values: dmX[44,2],The #> following variables have undefined values: dmX[45,2],The following variables #> have undefined values: dmX[46,2],The following variables have undefined values: #> dmX[47,2],The following variables have undefined values: dmX[48,2],The #> following variables have undefined values: dmX[49,2],The following variables #> have undefined values: dmX[50,2],The following variables have undefined values: #> dmX[1,3],The following variables have undefined values: dmX[2,3],The following #> variables have undefined values: dmX[3,3],The following variables have #> undefined values: dmX[4,3],The following variables have undefined values: #> dmX[5,3],The following variables have undefined values: dmX[6,3],The following #> variables have undefined values: dmX[7,3],The following variables have #> undefined values: dmX[8,3],The following variables have undefined values: #> dmX[9,3],The following variables have undefined values: dmX[10,3],The following #> variables have undefined values: dmX[11,3],The following variables have #> undefined values: dmX[12,3],The following variables have undefined values: #> dmX[13,3],The following variables have undefined values: dmX[14,3],The #> following variables have undefined values: dmX[15,3],The following variables #> have undefined values: dmX[16,3],The following variables have undefined values: #> dmX[17,3],The following variables have undefined values: dmX[18,3],The #> following variables have undefined values: dmX[19,3],The following variables #> have undefined values: dmX[20,3],The following variables have undefined values: #> dmX[21,3],The following variables have undefined values: dmX[22,3],The #> following variables have undefined values: dmX[23,3],The following variables #> have undefined values: dmX[24,3],The following variables have undefined values: #> dmX[25,3],The following variables have undefined values: dmX[26,3],The #> following variables have undefined values: dmX[27,3],The following variables #> have undefined values: dmX[28,3],The following variables have undefined values: #> dmX[29,3],The following variables have undefined values: dmX[30,3],The #> following variables have undefined values: dmX[31,3],The following variables #> have undefined values: dmX[32,3],The following variables have undefined values: #> dmX[33,3],The following variables have undefined values: dmX[34,3],The #> following variables have undefined values: dmX[35,3],The following variables #> have undefined values: dmX[36,3],The following variables have undefined values: #> dmX[37,3],The following variables have undefined values: dmX[38,3],The #> following variables have undefined values: dmX[39,3],The following variables #> have undefined values: dmX[40,3],The following variables have undefined values: #> dmX[41,3],The following variables have undefined #> Warning: There were 3 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is NA, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess print(fit.reg.direct.adapt.ve,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")) #> Inference for Stan model: blouchOU_reg_direct_adapt_ve. #> 1 chains, each with iter=400; warmup=200; thin=1;  #> post-warmup draws per chain=200, total post-warmup draws=200. #>  #>           mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat #> hl        0.24    0.03 0.16  0.08 0.13 0.19 0.29  0.58    25 1.00 #> vy        0.01    0.00 0.01  0.00 0.00 0.01 0.01  0.02    52 1.05 #> optima[1] 2.06    0.01 0.07  1.90 2.01 2.05 2.11  2.19   108 1.00 #> optima[2] 1.06    0.05 0.24  0.44 0.95 1.10 1.20  1.40    24 1.00 #> beta[1,1] 0.29    0.00 0.04  0.21 0.26 0.29 0.31  0.36   126 1.00 #> beta[1,2] 0.47    0.02 0.13  0.32 0.38 0.43 0.51  0.75    28 1.00 #> beta[2,1] 0.25    0.01 0.09  0.06 0.20 0.26 0.31  0.40    54 1.03 #> beta[2,2] 0.19    0.01 0.12 -0.08 0.12 0.20 0.28  0.39    68 1.04 #>  #> Samples were drawn using NUTS(diag_e) at Sun Sep 24 19:46:44 2023. #> For each parameter, n_eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor on split chains (at  #> convergence, Rhat=1). #plot(rethinking::precis(fit.reg.direct.adapt.ve,depth=2,pars = c(\"hl\",\"vy\",\"optima\",\"beta\")))  post<-rstan::extract(fit.reg.direct.adapt.ve)"},{"path":"https://mark-grabowski.github.io/blouch/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mark Grabowski. Author, maintainer.","code":""},{"path":"https://mark-grabowski.github.io/blouch/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Grabowski M (2023). blouch: Bayesian Linear Ornstein-Uhlenbeck models Comparative Hypotheses. https://github.com/mark-grabowski/blouch, https://mark-grabowski.github.io/blouch/.","code":"@Manual{,   title = {blouch: Bayesian Linear Ornstein-Uhlenbeck models for Comparative Hypotheses},   author = {Mark Grabowski},   year = {2023},   note = {https://github.com/mark-grabowski/blouch, https://mark-grabowski.github.io/blouch/}, }"},{"path":"https://mark-grabowski.github.io/blouch/index.html","id":"blouch","dir":"","previous_headings":"","what":"Bayesian Linear Ornstein-Uhlenbeck models for Comparative Hypotheses","title":"Bayesian Linear Ornstein-Uhlenbeck models for Comparative Hypotheses","text":"Blouch: Bayesian Linear Ornstein-Uhlenbeck models Comparative Hypotheses fits allometric adaptive models continuous trait evolution Bayesian framework based fixed continuous predictors incorporates measurement error. addition assigning biologically meaningful priors compared non-Bayesian approaches, Blouch includes new implementations Ornstein-Ulenbeck models including allowing varying effects (varying intercepts varying slopes), multilevel modeling, non-centered models. front-end component Blouch written R (R Core Team, 2023), nuts bolts written language Stan (Carpenter et al., 2017), allows estimation Bayesian models using Markov chain Monte Carlo (MCMC) methods based Hamilton Monte Carlo sampler.","code":""},{"path":"https://mark-grabowski.github.io/blouch/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Bayesian Linear Ornstein-Uhlenbeck models for Comparative Hypotheses","text":"just getting started Blouch recommend starting Simulation Example article available package website. articles abbreviated versions example showing various models implemented Blouch - steps preliminary analysis . Blouch based article currently review: Grabowski, M (revision). Blouch: Bayesian Linear Ornstein-Uhlenbeck models Comparative Hypotheses","code":""},{"path":"https://mark-grabowski.github.io/blouch/index.html","id":"instalation-instructions","dir":"","previous_headings":"","what":"Instalation Instructions","title":"Bayesian Linear Ornstein-Uhlenbeck models for Comparative Hypotheses","text":"install R Stan functions associated Blouch github, first install package devtools: install Blouch","code":"install.packages(\"devtools\", repos = \"https://cran.ma.imperial.ac.uk/\") library(devtools) devtools::install_github(\"mark-grabowski/blouch\") library(blouch)"},{"path":"https://mark-grabowski.github.io/blouch/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Bayesian Linear Ornstein-Uhlenbeck models for Comparative Hypotheses","text":"Please visit package website .","code":""},{"path":"https://mark-grabowski.github.io/blouch/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Bayesian Linear Ornstein-Uhlenbeck models for Comparative Hypotheses","text":"Carpenter, B., . Gelman, M. D. Hoffman, D. Lee, B. Goodrich, M. Betancourt, M. Brubaker, J. Guo, P. Li, . Riddell. 2017. Stan: Probabilistic Programming Language. Journal Statistical Software 76:1–32. R Core Team. 2023. R: language environment statistical computing.","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch-package.html","id":null,"dir":"Reference","previous_headings":"","what":"The 'blouch' package. — blouch-package","title":"The 'blouch' package. — blouch-package","text":"Bayesian Linear Ornstein-Uhlenbeck models Comparative Hypotheses (BLOUCH) fits adaptive models continuous trait evolution Bayesian framework based categorical continuous predictors, incorporates measurement error.","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The 'blouch' package. — blouch-package","text":"Stan Development Team (2023). RStan: R interface Stan. R package version 2.26.22. https://mc-stan.org","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.adapt.prep.html","id":null,"dir":"Reference","previous_headings":"","what":"blouch.adapt.prep - Setup dat file to run adaptive model — blouch.adapt.prep","title":"blouch.adapt.prep - Setup dat file to run adaptive model — blouch.adapt.prep","text":"blouch.adapt.prep - Setup dat file run adaptive model","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.adapt.prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blouch.adapt.prep - Setup dat file to run adaptive model — blouch.adapt.prep","text":"","code":"blouch.adapt.prep(trdata, Y, Y_error, X, X_error, Z_adaptive)"},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.adapt.prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"blouch.adapt.prep - Setup dat file to run adaptive model — blouch.adapt.prep","text":"trdata object class treedata function treeplyr Y Vector containing name column treedata containing response variable Y_error Vector containing name column treedata containing error response variable X Vector containing name(s) column treedata containing predictor variable(s) X_error Vector containing name(s) column treedata containing error predictor variable(s) Z_adaptive Number adaptive traits","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.adapt.prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"blouch.adapt.prep - Setup dat file to run adaptive model — blouch.adapt.prep","text":"dat - list file containing objecs setup Blouch","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.direct.adapt.prep.html","id":null,"dir":"Reference","previous_headings":"","what":"blouch.direct.adapt.prep - Setup dat file to run direct effect and adpative model — blouch.direct.adapt.prep","title":"blouch.direct.adapt.prep - Setup dat file to run direct effect and adpative model — blouch.direct.adapt.prep","text":"blouch.direct.adapt.prep - Setup dat file run direct effect adpative model","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.direct.adapt.prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blouch.direct.adapt.prep - Setup dat file to run direct effect and adpative model — blouch.direct.adapt.prep","text":"","code":"blouch.direct.adapt.prep(trdata, Y, Y_error, X, X_error, Z_direct, Z_adaptive)"},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.direct.adapt.prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"blouch.direct.adapt.prep - Setup dat file to run direct effect and adpative model — blouch.direct.adapt.prep","text":"trdata object class treedata function treeplyr Y Vector containing name column treedata containing response variable Y_error Vector containing name column treedata containing error response variable X Vector containing name(s) column treedata containing predictor variable(s) X_error Vector containing name(s) column treedata containing error predictor variable(s) Z_direct Vector containing number direct effect predictor traits Z_adaptive Vector containing number adaptive predictor traits","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.direct.adapt.prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"blouch.direct.adapt.prep - Setup dat file to run direct effect and adpative model — blouch.direct.adapt.prep","text":"dat - list file containing objecs setup Blouch","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.direct.prep.html","id":null,"dir":"Reference","previous_headings":"","what":"blouch.direct.prep - Setup dat file to run direct effect model — blouch.direct.prep","title":"blouch.direct.prep - Setup dat file to run direct effect model — blouch.direct.prep","text":"blouch.direct.prep - Setup dat file run direct effect model","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.direct.prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blouch.direct.prep - Setup dat file to run direct effect model — blouch.direct.prep","text":"","code":"blouch.direct.prep(trdata, Y, Y_error, X, X_error, Z_direct)"},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.direct.prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"blouch.direct.prep - Setup dat file to run direct effect model — blouch.direct.prep","text":"trdata object class treedata function treeplyr Y Vector containing name column treedata containing response variable Y_error Vector containing name column treedata containing error response variable X Vector containing name(s) column treedata containing predictor variable(s) X_error Vector containing name(s) column treedata containing error predictor variable(s) Z_direct Number direct effect traits","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.direct.prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"blouch.direct.prep - Setup dat file to run direct effect model — blouch.direct.prep","text":"dat - list file containing objecs setup Blouch","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.adapt.prep.html","id":null,"dir":"Reference","previous_headings":"","what":"blouch.reg.adapt.prep - Setup dat file to run multi-optima adaptive model — blouch.reg.adapt.prep","title":"blouch.reg.adapt.prep - Setup dat file to run multi-optima adaptive model — blouch.reg.adapt.prep","text":"blouch.reg.adapt.prep - Setup dat file run multi-optima adaptive model","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.adapt.prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blouch.reg.adapt.prep - Setup dat file to run multi-optima adaptive model — blouch.reg.adapt.prep","text":"","code":"blouch.reg.adapt.prep(trdata, Y, Y_error, X, X_error, Z_adaptive, reg.column)"},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.adapt.prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"blouch.reg.adapt.prep - Setup dat file to run multi-optima adaptive model — blouch.reg.adapt.prep","text":"trdata object class treedata function treeplyr Y Vector containing name column treedata containing response variable Y_error Vector containing name column treedata containing error response variable X Vector containing name(s) column treedata containing predictor variable(s) X_error Vector containing name(s) column treedata containing error predictor variable(s) Z_adaptive Vector containing number adaptive predictor traits reg.column Vector containing name regime column treedata$dat","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.adapt.prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"blouch.reg.adapt.prep - Setup dat file to run multi-optima adaptive model — blouch.reg.adapt.prep","text":"dat - list file containing objecs setup Blouch","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.direct.adapt.prep.html","id":null,"dir":"Reference","previous_headings":"","what":"blouch.reg.direct.adapt.prep - Setup dat file to run multi-optima direct effect adaptive model — blouch.reg.direct.adapt.prep","title":"blouch.reg.direct.adapt.prep - Setup dat file to run multi-optima direct effect adaptive model — blouch.reg.direct.adapt.prep","text":"blouch.reg.direct.adapt.prep - Setup dat file run multi-optima direct effect adaptive model","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.direct.adapt.prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blouch.reg.direct.adapt.prep - Setup dat file to run multi-optima direct effect adaptive model — blouch.reg.direct.adapt.prep","text":"","code":"blouch.reg.direct.adapt.prep(   trdata,   Y,   Y_error,   X,   X_error,   Z_direct,   Z_adaptive,   reg.column )"},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.direct.adapt.prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"blouch.reg.direct.adapt.prep - Setup dat file to run multi-optima direct effect adaptive model — blouch.reg.direct.adapt.prep","text":"trdata object class treedata function treeplyr Y Vector containing name column treedata containing response variable Y_error Vector containing name column treedata containing error response variable X Vector containing name(s) column treedata containing predictor variable(s) X_error Vector containing name(s) column treedata containing error predictor variable(s) Z_direct Vector containing number direct effect predictor traits Z_adaptive Vector containing number adaptive predictor traits reg.column Vector containing name regime column treedata$dat","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.direct.adapt.prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"blouch.reg.direct.adapt.prep - Setup dat file to run multi-optima direct effect adaptive model — blouch.reg.direct.adapt.prep","text":"dat - list file containing objecs setup Blouch","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.direct.prep.html","id":null,"dir":"Reference","previous_headings":"","what":"blouch.reg.direct.prep - Setup dat file to run multi-optima direct effect model — blouch.reg.direct.prep","title":"blouch.reg.direct.prep - Setup dat file to run multi-optima direct effect model — blouch.reg.direct.prep","text":"blouch.reg.direct.prep - Setup dat file run multi-optima direct effect model","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.direct.prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blouch.reg.direct.prep - Setup dat file to run multi-optima direct effect model — blouch.reg.direct.prep","text":"","code":"blouch.reg.direct.prep(trdata, Y, Y_error, X, X_error, Z_direct, reg.column)"},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.direct.prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"blouch.reg.direct.prep - Setup dat file to run multi-optima direct effect model — blouch.reg.direct.prep","text":"trdata object class treedata function treeplyr Y Vector containing name column treedata containing response variable Y_error Vector containing name column treedata containing error response variable X Vector containing name(s) column treedata containing predictor variable(s) X_error Vector containing name(s) column treedata containing error predictor variable(s) Z_direct Vector containing number direct effect predictor traits reg.column Vector containing name regime column treedata$dat","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.direct.prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"blouch.reg.direct.prep - Setup dat file to run multi-optima direct effect model — blouch.reg.direct.prep","text":"dat - list file containing objecs setup Blouch","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.prep.html","id":null,"dir":"Reference","previous_headings":"","what":"blouch.reg.prep - Setup dat file to run multi-optima model — blouch.reg.prep","title":"blouch.reg.prep - Setup dat file to run multi-optima model — blouch.reg.prep","text":"blouch.reg.prep - Setup dat file run multi-optima model","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blouch.reg.prep - Setup dat file to run multi-optima model — blouch.reg.prep","text":"","code":"blouch.reg.prep(trdata, Y, Y_error, reg.column, anc_maps = \"regimes\")"},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"blouch.reg.prep - Setup dat file to run multi-optima model — blouch.reg.prep","text":"trdata object class treedata function treeplyr Y Vector containing name column treedata containing response variable Y_error Vector containing name column treedata containing error response variable reg.column Vector containing name regime column treedata$dat anc_maps Vector containing name regime type - nodes \"regimes\" SIMMAP","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/blouch.reg.prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"blouch.reg.prep - Setup dat file to run multi-optima model — blouch.reg.prep","text":"dat - list file containing objecs setup Blouch","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_adaptive_V.html","id":null,"dir":"Reference","previous_headings":"","what":"calc_adaptive_V - Calculate adaptive variance/covariance matrix — calc_adaptive_V","title":"calc_adaptive_V - Calculate adaptive variance/covariance matrix — calc_adaptive_V","text":"calc_adaptive_V - Calculate adaptive variance/covariance matrix","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_adaptive_V.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calc_adaptive_V - Calculate adaptive variance/covariance matrix — calc_adaptive_V","text":"","code":"calc_adaptive_V(phy, a, sigma2_y, beta, sigma2_x, Z_adaptive)"},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_adaptive_V.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calc_adaptive_V - Calculate adaptive variance/covariance matrix — calc_adaptive_V","text":"phy phylogney NEXUS format Rate parameter OU model sigma2_y Variance Y beta slope sigma2_x Brownian-motion parameter X Z_adaptive Number adaptive predictors","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_adaptive_V.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calc_adaptive_V - Calculate adaptive variance/covariance matrix — calc_adaptive_V","text":"Variance/covariance matrix","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_adaptive_dmX.html","id":null,"dir":"Reference","previous_headings":"","what":"calc_adaptive_dmX - Calculate adaptive predictor matrix for Blouch — calc_adaptive_dmX","title":"calc_adaptive_dmX - Calculate adaptive predictor matrix for Blouch — calc_adaptive_dmX","text":"calc_adaptive_dmX - Calculate adaptive predictor matrix Blouch","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_adaptive_dmX.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calc_adaptive_dmX - Calculate adaptive predictor matrix for Blouch — calc_adaptive_dmX","text":"","code":"calc_adaptive_dmX(phy, a, X)"},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_adaptive_dmX.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calc_adaptive_dmX - Calculate adaptive predictor matrix for Blouch — calc_adaptive_dmX","text":"phy Phylogeny NEXUS format Rate parameter OU model X Predictor","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_adaptive_dmX.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calc_adaptive_dmX - Calculate adaptive predictor matrix for Blouch — calc_adaptive_dmX","text":"Adaptive predictor matrix","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_direct_V.html","id":null,"dir":"Reference","previous_headings":"","what":"calc_direct_V - Calculate direct effect model V/CV matrix — calc_direct_V","title":"calc_direct_V - Calculate direct effect model V/CV matrix — calc_direct_V","text":"calc_direct_V - Calculate direct effect model V/CV matrix","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_direct_V.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calc_direct_V - Calculate direct effect model V/CV matrix — calc_direct_V","text":"","code":"calc_direct_V(phy, sigma2_y, a)"},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_direct_V.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calc_direct_V - Calculate direct effect model V/CV matrix — calc_direct_V","text":"phy Phylogeny NEXUS format sigma2_y Variance Y Rate parameter OU model","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_direct_V.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calc_direct_V - Calculate direct effect model V/CV matrix — calc_direct_V","text":"Variance/Covariance marix","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_mixed_dmX.html","id":null,"dir":"Reference","previous_headings":"","what":"calc_mixed_dmX - Calculate mixed direct effect and adaptive predictor matrix for Blouch — calc_mixed_dmX","title":"calc_mixed_dmX - Calculate mixed direct effect and adaptive predictor matrix for Blouch — calc_mixed_dmX","text":"calc_mixed_dmX - Calculate mixed direct effect adaptive predictor matrix Blouch","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_mixed_dmX.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calc_mixed_dmX - Calculate mixed direct effect and adaptive predictor matrix for Blouch — calc_mixed_dmX","text":"","code":"calc_mixed_dmX(phy, a, X, Z_direct, Z_adaptive)"},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_mixed_dmX.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calc_mixed_dmX - Calculate mixed direct effect and adaptive predictor matrix for Blouch — calc_mixed_dmX","text":"phy Phylogeny NEXUS format Rate parameter OU model X Predictor Z_direct Number direct effect predictor traits Z_adaptive Number adaptive predictor traits","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_mixed_dmX.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calc_mixed_dmX - Calculate mixed direct effect and adaptive predictor matrix for Blouch — calc_mixed_dmX","text":"Predictor matrix","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_multiadaptive_cov_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"calc_multiadaptive_cov_plot - Calcualte covariance matrix for mult-adaptive covariance plot — calc_multiadaptive_cov_plot","title":"calc_multiadaptive_cov_plot - Calcualte covariance matrix for mult-adaptive covariance plot — calc_multiadaptive_cov_plot","text":"calc_multiadaptive_cov_plot - Calcualte covariance matrix mult-adaptive covariance plot","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_multiadaptive_cov_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calc_multiadaptive_cov_plot - Calcualte covariance matrix for mult-adaptive covariance plot — calc_multiadaptive_cov_plot","text":"","code":"calc_multiadaptive_cov_plot(a, sigma2_y, beta, x, Z_adaptive, n_reg)"},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_multiadaptive_cov_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calc_multiadaptive_cov_plot - Calcualte covariance matrix for mult-adaptive covariance plot — calc_multiadaptive_cov_plot","text":"Rate parameter OU model sigma2_y Variance Y beta Slope parameter x X axis value Z_adaptive Number adaptive predictors n_reg Number regimes","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/calc_multiadaptive_cov_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calc_multiadaptive_cov_plot - Calcualte covariance matrix for mult-adaptive covariance plot — calc_multiadaptive_cov_plot","text":"Variance/covariance matrix","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/concat.factor.html","id":null,"dir":"Reference","previous_headings":"","what":"concat.factor - For internal Blouch use Thanks to user ","title":"concat.factor - For internal Blouch use Thanks to user ","text":"concat.factor - internal Blouch use Thanks user \"snaut\" stackoverflow, http://stackoverflow.com/users/1999873/snaut","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/concat.factor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"concat.factor - For internal Blouch use Thanks to user ","text":"","code":"concat.factor(...)"},{"path":"https://mark-grabowski.github.io/blouch/reference/concat.factor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"concat.factor - For internal Blouch use Thanks to user ","text":"... vector factors","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/concat.factor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"concat.factor - For internal Blouch use Thanks to user ","text":"factor","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/lineage.constructor.html","id":null,"dir":"Reference","previous_headings":"","what":"lineage.constructor function - Construct a list with variables based on regime timing and placement — lineage.constructor","title":"lineage.constructor function - Construct a list with variables based on regime timing and placement — lineage.constructor","text":"lineage.constructor function - Construct list variables based regime timing placement","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/lineage.constructor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"lineage.constructor function - Construct a list with variables based on regime timing and placement — lineage.constructor","text":"","code":"lineage.constructor(phy, e, anc_maps = \"regimes\", regimes)"},{"path":"https://mark-grabowski.github.io/blouch/reference/lineage.constructor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"lineage.constructor function - Construct a list with variables based on regime timing and placement — lineage.constructor","text":"phy phylogeny NEXUS format e Lineage number anc_maps Vector name regime placement type regimes Regimes factor format","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/lineage.constructor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"lineage.constructor function - Construct a list with variables based on regime timing and placement — lineage.constructor","text":"list information individual regime lineages","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/lineage.nodes.html","id":null,"dir":"Reference","previous_headings":"","what":"lineage.nodes - Function for internal Blouch use Given a certain node, return the list of all parent nodes back to the root of the tree — lineage.nodes","title":"lineage.nodes - Function for internal Blouch use Given a certain node, return the list of all parent nodes back to the root of the tree — lineage.nodes","text":"lineage.nodes - Function internal Blouch use Given certain node, return list parent nodes back root tree","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/lineage.nodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"lineage.nodes - Function for internal Blouch use Given a certain node, return the list of all parent nodes back to the root of the tree — lineage.nodes","text":"","code":"lineage.nodes(phy, x)"},{"path":"https://mark-grabowski.github.io/blouch/reference/lineage.nodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"lineage.nodes - Function for internal Blouch use Given a certain node, return the list of all parent nodes back to the root of the tree — lineage.nodes","text":"phy phylogeny NEXUS format x node interest","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/lineage.nodes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"lineage.nodes - Function for internal Blouch use Given a certain node, return the list of all parent nodes back to the root of the tree — lineage.nodes","text":"list Given certain node, return list parent nodes back root tree","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/parent.html","id":null,"dir":"Reference","previous_headings":"","what":"parent function - Returns parent node of offspring node given node number — parent","title":"parent function - Returns parent node of offspring node given node number — parent","text":"parent function - Returns parent node offspring node given node number","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/parent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"parent function - Returns parent node of offspring node given node number — parent","text":"","code":"parent(phy, x)"},{"path":"https://mark-grabowski.github.io/blouch/reference/parent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"parent function - Returns parent node of offspring node given node number — parent","text":"phy phylogeny phytools format x node number","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/parent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"parent function - Returns parent node of offspring node given node number — parent","text":"value Returns parent node offspring node given node number","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/set.converge.regimes.html","id":null,"dir":"Reference","previous_headings":"","what":"set.converge.regimes - function to assign regimes on a phylogeny — set.converge.regimes","title":"set.converge.regimes - function to assign regimes on a phylogeny — set.converge.regimes","text":"set.converge.regimes - function assign regimes phylogeny","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/set.converge.regimes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"set.converge.regimes - function to assign regimes on a phylogeny — set.converge.regimes","text":"","code":"set.converge.regimes(trdata, regimes)"},{"path":"https://mark-grabowski.github.io/blouch/reference/set.converge.regimes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"set.converge.regimes - function to assign regimes on a phylogeny — set.converge.regimes","text":"trdata treeplyr format file regimes node numbers regimes shift","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/set.converge.regimes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"set.converge.regimes - function to assign regimes on a phylogeny — set.converge.regimes","text":"treeplyr format file new column dat tip regimes internal regime assignments node.labels","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/tree.10K.html","id":null,"dir":"Reference","previous_headings":"","what":"Primate tree with 301 tip species This is the primate phylogeny for Version 3 of 10K trees — tree.10K","title":"Primate tree with 301 tip species This is the primate phylogeny for Version 3 of 10K trees — tree.10K","text":"Primate tree 301 tip species primate phylogeny Version 3 10K trees","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/tree.10K.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Primate tree with 301 tip species This is the primate phylogeny for Version 3 of 10K trees — tree.10K","text":"","code":"tree.10K"},{"path":"https://mark-grabowski.github.io/blouch/reference/tree.10K.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Primate tree with 301 tip species This is the primate phylogeny for Version 3 of 10K trees — tree.10K","text":"NEXUS Format dataset","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/tree.10K.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Primate tree with 301 tip species This is the primate phylogeny for Version 3 of 10K trees — tree.10K","text":"https://10ktrees.nunn-lab.org/","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/ts_fxn.html","id":null,"dir":"Reference","previous_headings":"","what":"ts_fxn function - Internal Blouch function to return tree data — ts_fxn","title":"ts_fxn function - Internal Blouch function to return tree data — ts_fxn","text":"ts_fxn function - Internal Blouch function return tree data","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/ts_fxn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ts_fxn function - Internal Blouch function to return tree data — ts_fxn","text":"","code":"ts_fxn(phy)"},{"path":"https://mark-grabowski.github.io/blouch/reference/ts_fxn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ts_fxn function - Internal Blouch function to return tree data — ts_fxn","text":"phy Phylogeny NEXUS format","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/ts_fxn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ts_fxn function - Internal Blouch function to return tree data — ts_fxn","text":"list object tree data","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/weight.matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"weight.matrix - For internal Blouch use - wrapper to apply weights_regimes to each lineage — weight.matrix","title":"weight.matrix - For internal Blouch use - wrapper to apply weights_regimes to each lineage — weight.matrix","text":"weight.matrix - internal Blouch use - wrapper apply weights_regimes lineage","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/weight.matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"weight.matrix - For internal Blouch use - wrapper to apply weights_regimes to each lineage — weight.matrix","text":"","code":"weight.matrix(phy, a, lineages)"},{"path":"https://mark-grabowski.github.io/blouch/reference/weight.matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"weight.matrix - For internal Blouch use - wrapper to apply weights_regimes to each lineage — weight.matrix","text":"phy phylogeny NEXUS format OU rate parameter lineages Vector regime values","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/weight.matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"weight.matrix - For internal Blouch use - wrapper to apply weights_regimes to each lineage — weight.matrix","text":"weights lineage","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/weights_regimes.html","id":null,"dir":"Reference","previous_headings":"","what":"weights_regimes - For internal Blouch use For individual lineage, sum up the segments in each regimes — weights_regimes","title":"weights_regimes - For internal Blouch use For individual lineage, sum up the segments in each regimes — weights_regimes","text":"weights_regimes - internal Blouch use individual lineage, sum segments regimes","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/weights_regimes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"weights_regimes - For internal Blouch use For individual lineage, sum up the segments in each regimes — weights_regimes","text":"","code":"weights_regimes(a, lineage)"},{"path":"https://mark-grabowski.github.io/blouch/reference/weights_regimes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"weights_regimes - For internal Blouch use For individual lineage, sum up the segments in each regimes — weights_regimes","text":"Rate parameter OU model lineage Individual regime values lineage","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/weights_regimes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"weights_regimes - For internal Blouch use For individual lineage, sum up the segments in each regimes — weights_regimes","text":"Return named vector regimes weights individual lineage","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/weights_segments.html","id":null,"dir":"Reference","previous_headings":"","what":"weights_segments - For internal Blouch use For individual lineage, determine the weighting of each segment — weights_segments","title":"weights_segments - For internal Blouch use For individual lineage, determine the weighting of each segment — weights_segments","text":"weights_segments - internal Blouch use individual lineage, determine weighting segment","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/weights_segments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"weights_segments - For internal Blouch use For individual lineage, determine the weighting of each segment — weights_segments","text":"","code":"weights_segments(a, lineage)"},{"path":"https://mark-grabowski.github.io/blouch/reference/weights_segments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"weights_segments - For internal Blouch use For individual lineage, determine the weighting of each segment — weights_segments","text":"Rate parameter OU model lineage Individual lineage regime values","code":""},{"path":"https://mark-grabowski.github.io/blouch/reference/weights_segments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"weights_segments - For internal Blouch use For individual lineage, determine the weighting of each segment — weights_segments","text":"individual lineage, determine weighting segment","code":""}]
